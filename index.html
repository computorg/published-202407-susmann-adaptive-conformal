<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.1">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Herbert Susmann">
<meta name="author" content="Antoine Chambaz">
<meta name="author" content="Julie Josse">
<meta name="dcterms.date" content="2024-07-18">
<meta name="keywords" content="Conformal inference, Adaptive conformal inference, time series, R">
<meta name="description" content="Conformal Inference (CI) is a popular approach for generating finite sample prediction intervals based on the output of any point prediction method when data are exchangeable. Adaptive Conformal Inference (ACI) algorithms extend CI to the case of sequentially observed data, such as time series, and exhibit strong theoretical guarantees without having to assume exchangeability of the observed data. The common thread that unites algorithms in the ACI family is that they adaptively adjust the width of the generated prediction intervals in response to the observed data. We provide a detailed description of five ACI algorithms and their theoretical guarantees, and test their performance in simulation studies. We then present a case study of producing prediction intervals for influenza incidence in the United States based on black-box point forecasts. Implementations of all the algorithms are released as an open-source R package, AdaptiveConformal, which also includes tools for visualizing and summarizing conformal prediction intervals.">

<title>AdaptiveConformal: An R Package for Adaptive Conformal Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="published-202407-susmann-adaptive-conformal_files/libs/clipboard/clipboard.min.js"></script>
<script src="published-202407-susmann-adaptive-conformal_files/libs/quarto-html/quarto.js"></script>
<script src="published-202407-susmann-adaptive-conformal_files/libs/quarto-html/popper.min.js"></script>
<script src="published-202407-susmann-adaptive-conformal_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="published-202407-susmann-adaptive-conformal_files/libs/quarto-html/anchor.min.js"></script>
<link href="published-202407-susmann-adaptive-conformal_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="published-202407-susmann-adaptive-conformal_files/libs/quarto-html/quarto-syntax-highlighting-40a97741d360803f1a66e8f017dcaab6.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="published-202407-susmann-adaptive-conformal_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="published-202407-susmann-adaptive-conformal_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="published-202407-susmann-adaptive-conformal_files/libs/bootstrap/bootstrap-e35c0e35dfd6bcb003f02fe20022d222.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="published-202407-susmann-adaptive-conformal_files/libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="published-202407-susmann-adaptive-conformal_files/libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: #FFFFFF;
      }

      .quarto-title-block .quarto-title-banner {
        color: #FFFFFF;
background: #034E79;
      }
</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="AdaptiveConformal: An `R` Package for Adaptive Conformal Inference">
<meta name="citation_abstract" content="Conformal Inference (CI) is a popular approach for generating finite sample prediction intervals based on the output of any point prediction method when data are exchangeable. Adaptive Conformal Inference (ACI) algorithms extend CI to the case of sequentially observed data, such as time series, and exhibit strong theoretical guarantees without having to assume exchangeability of the observed data. The common thread that unites algorithms in the ACI family is that they adaptively adjust the width of the generated prediction intervals in response to the observed data. We provide a detailed description of five ACI algorithms and their theoretical guarantees, and test their performance in simulation studies. We then present a case study of producing prediction intervals for influenza incidence in the United States based on black-box point forecasts. Implementations of all the algorithms are released as an open-source `R` package, `AdaptiveConformal`, which also includes tools for visualizing and summarizing conformal prediction intervals.
">
<meta name="citation_keywords" content="Conformal inference,Adaptive conformal inference,time series,R">
<meta name="citation_author" content="Herbert Susmann">
<meta name="citation_author" content="Antoine Chambaz">
<meta name="citation_author" content="Julie Josse">
<meta name="citation_publication_date" content="2024-07-18">
<meta name="citation_cover_date" content="2024-07-18">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-07-18">
<meta name="citation_fulltext_html_url" content="https://computo.sfds.asso.fr/template-computo-quarto">
<meta name="citation_doi" content="10.57750/edan-5f53">
<meta name="citation_issn" content="2824-7795">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Computo">
<meta name="citation_publisher" content="Société Française de Statistique">
<meta name="citation_reference" content="citation_title=Adaptive conformal inference under distribution shift;,citation_author=Isaac Gibbs;,citation_author=Emmanuel Candes;,citation_editor=M. Ranzato;,citation_editor=A. Beygelzimer;,citation_editor=Y. Dauphin;,citation_editor=P. S. Liang;,citation_editor=J. Wortman Vaughan;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://proceedings.neurips.cc/paper_files/paper/2021/file/0d441de75945e5acbc865406fc9a2559-Paper.pdf;,citation_volume=34;,citation_conference_title=Advances in neural information processing systems;,citation_conference=Curran Associates, Inc.;">
<meta name="citation_reference" content="citation_title=Adaptive conformal predictions for time series;,citation_abstract=Uncertainty quantification of predictive models is crucial in decision-making problems. Conformal prediction is a general and theoretically sound answer. However, it requires exchangeable data, excluding time series. While recent works tackled this issue, we argue that Adaptive Conformal Inference (ACI, Gibbs &amp;amp;amp;amp; Candès, 2021), developed for distribution-shift time series, is a good procedure for time series with general dependency. We theoretically analyse the impact of the learning rate on its efficiency in the exchangeable and auto-regressive case. We propose a parameter-free method, AgACI, that adaptively builds upon ACI based on online expert aggregation. We lead extensive fair simulations against competing methods that advocate for ACI’s use in time series. We conduct a real case study: electricity price forecasting. The proposed aggregation algorithm provides efficient prediction intervals for day-ahead forecasting. All the code and data to reproduce the experiments are made available on GitHub.;,citation_author=Margaux Zaffran;,citation_author=Olivier Feron;,citation_author=Yannig Goude;,citation_author=Julie Josse;,citation_author=Aymeric Dieuleveut;,citation_editor=Kamalika Chaudhuri;,citation_editor=Stefanie Jegelka;,citation_editor=Le Song;,citation_editor=Csaba Szepesvari;,citation_editor=Gang Niu;,citation_editor=Sivan Sabato;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://proceedings.mlr.press/v162/zaffran22a.html;,citation_volume=162;,citation_conference_title=Proceedings of the 39th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Conformal inference for online prediction with arbitrary distribution shifts;,citation_author=Isaac Gibbs;,citation_author=Emmanuel Candès;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2208.08401;">
<meta name="citation_reference" content="citation_title=Improved online conformal prediction via strongly adaptive online learning;,citation_abstract=We study the problem of uncertainty quantification via prediction sets, in an online setting where the data distribution may vary arbitrarily over time. Recent work develops online conformal prediction techniques that leverage regret minimization algorithms from the online learning literature to learn prediction sets with approximately valid coverage and small regret. However, standard regret minimization could be insufficient for handling changing environments, where performance guarantees may be desired not only over the full time horizon but also in all (sub-)intervals of time. We develop new online conformal prediction methods that minimize the strongly adaptive regret, which measures the worst-case regret over all intervals of a fixed length. We prove that our methods achieve near-optimal strongly adaptive regret for all interval lengths simultaneously, and approximately valid coverage. Experiments show that our methods consistently obtain better coverage and smaller prediction sets than existing methods on real-world tasks, such as time series forecasting and image classification under distribution shift.;,citation_author=Aadyot Bhatnagar;,citation_author=Huan Wang;,citation_author=Caiming Xiong;,citation_author=Yu Bai;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=Proceedings of the 40th international conference on machine learning;,citation_conference=JMLR.org;,citation_series_title=ICML’23;">
<meta name="citation_reference" content="citation_title=Conformal prediction: A gentle introduction;,citation_abstract=Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction (a.k.a. conformal inference) is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions. One can use conformal prediction with any pre-trained model, such as a neural network, to produce sets that are guaranteed to contain the ground truth with a user-specified probability, such as 90%. It is easy-to-understand, easy-to-use, and general, applying naturally to problems arising in the fields of computer vision, natural language processing, deep reinforcement learning, and so on.This hands-on introduction is aimed to provide the reader a working understanding of conformal prediction and related distribution-free uncertainty quantification techniques with one self-contained document. We lead the reader through practical theory for and examples of conformal prediction and describe its extensions to complex machine learning tasks involving structured outputs, distribution shift, timeseries, outliers, models that abstain, and more. Throughout, there are many explanatory illustrations, examples, and code samples in Python. With each code sample comes a Jupyter notebook implementing the method on a real-data example; the notebooks can be accessed and easily run by following the code footnotes.;,citation_author=Anastasios N. Angelopoulos;,citation_author=Stephen Bates;,citation_publication_date=2023-03;,citation_cover_date=2023-03;,citation_year=2023;,citation_fulltext_html_url=https://doi.org/10.1561/2200000101;,citation_issue=4;,citation_doi=10.1561/2200000101;,citation_issn=1935-8237;,citation_volume=16;,citation_journal_title=Found. Trends Mach. Learn.;,citation_publisher=Now Publishers Inc.;">
<meta name="citation_reference" content="citation_title=Conformal prediction beyond exchangeability;,citation_author=Rina Foygel Barber;,citation_author=Emmanuel J. Candès;,citation_author=Aaditya Ramdas;,citation_author=Ryan J. Tibshirani;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://doi.org/10.1214/23-AOS2276;,citation_issue=2;,citation_doi=10.1214/23-AOS2276;,citation_volume=51;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Batch multivalid conformal prediction;,citation_author=Christopher Jung;,citation_author=Georgy Noarov;,citation_author=Ramya Ramalingam;,citation_author=Aaron Roth;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=11th International Conference on Learning Representations (ICLR);">
<meta name="citation_reference" content="citation_title=Practical adversarial multivalid conformal prediction;,citation_author=Osbert Bastani;,citation_author=Varun Gupta;,citation_author=Christopher Jung;,citation_author=Georgy Noarov;,citation_author=Ramya Ramalingam;,citation_author=Aaron Roth;,citation_editor=S. Koyejo;,citation_editor=S. Mohamed;,citation_editor=A. Agarwal;,citation_editor=D. Belgrave;,citation_editor=K. Cho;,citation_editor=A. Oh;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://proceedings.neurips.cc/paper_files/paper/2022/file/bcdaaa1aec3ae2aa39542acefdec4e4b-Paper-Conference.pdf;,citation_volume=35;,citation_conference_title=Advances in neural information processing systems;,citation_conference=Curran Associates, Inc.;">
<meta name="citation_reference" content="citation_title=Algorithmic learning in a random world;,citation_author=Vladimir Vovk;,citation_author=Alex Gammerman;,citation_author=Glenn Shafer;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_isbn=0387001522;">
<meta name="citation_reference" content="citation_title=Opera: Online prediction by expert aggregation;,citation_author=Pierre Gaillard;,citation_author=Yannig Goude;,citation_author=Laurent Plagne;,citation_author=Thibaut Dubois;,citation_author=Benoit Thieurmel;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=http://pierre.gaillard.me/opera.html;">
<meta name="citation_reference" content="citation_title=Optimal learning with bernstein online aggregation;,citation_abstract=We introduce a new recursive aggregation procedure called Bernstein Online Aggregation (BOA). Its exponential weights include a second order refinement. The procedure is optimal for the model selection aggregation problem in the bounded iid setting for the square loss: the excess of risk of its batch version achieves the fast rate of convergence $$\log (M)/n$$in deviation. The BOA procedure is the first online algorithm that satisfies this optimal fast rate. The second order refinement is required to achieve the optimality in deviation as the classical exponential weights cannot be optimal, see Audibert (Advances in neural information processing systems. MIT Press, Cambridge, MA, 2007). This refinement is settled thanks to a new stochastic conversion that estimates the cumulative predictive risk in any stochastic environment with observable second order terms. The observable second order term is shown to be sufficiently small to assert the fast rate in the iid setting when the loss is Lipschitz and strongly convex. We also introduce a multiple learning rates version of BOA. This fully adaptive BOA procedure is also optimal, up to a $$\log \log (n)$$factor.;,citation_author=Olivier Wintenberger;,citation_publication_date=2017-01-01;,citation_cover_date=2017-01-01;,citation_year=2017;,citation_fulltext_html_url=https://doi.org/10.1007/s10994-016-5592-6;,citation_issue=1;,citation_doi=10.1007/s10994-016-5592-6;,citation_issn=1573-0565;,citation_volume=106;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Scale-free online learning;,citation_abstract=We design and analyze algorithms for online linear optimization that have optimal regret and at the same time do not need to know any upper or lower bounds on the norm of the loss vectors. Our algorithms are instances of the Follow the Regularized Leader (FTRL) and Mirror Descent (MD) meta-algorithms. We achieve adaptiveness to the norms of the loss vectors by scale invariance, i.e., our algorithms make exactly the same decisions if the sequence of loss vectors is multiplied by any positive constant. The algorithm based on FTRL works for any decision set, bounded or unbounded. For unbounded decisions sets, this is the first adaptive algorithm for online linear optimization with a non-vacuous regret bound. In contrast, we show lower bounds on scale-free algorithms based on MD on unbounded domains.;,citation_author=Francesco Orabona;,citation_author=Dávid Pál;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0304397517308514;,citation_doi=https://doi.org/10.1016/j.tcs.2017.11.021;,citation_issn=0304-3975;,citation_volume=716;,citation_journal_title=Theoretical Computer Science;">
<meta name="citation_reference" content="citation_title=Adaptive regret for control of time-varying dynamics;,citation_abstract=We consider the problem of online control of systems with time-varying linear dynamics. To state meaningful guarantees over changing environments, we introduce the metric of &amp;amp;amp;lt;i&amp;gt;adaptive regret&amp;lt;/i&amp;gt; to the field of control. This metric, originally studied in online learning, measures performance in terms of regret against the best policy in hindsight on <i>any interval in time</i>, and thus captures the adaptation of the controller to changing dynamics. Our main contribution is a novel efficient meta-algorithm: it converts a controller with sublinear regret bounds into one with sublinear <i>adaptive regret</i> bounds in the setting of time-varying linear dynamical systems. The underlying technical innovation is the first adaptive regret bound for the more general framework of online convex optimization with memory. Furthermore, we give a lower bound showing that our attained adaptive regret bound is nearly tight for this general framework.;,citation_author=Paula Gradu;,citation_author=Elad Hazan;,citation_author=Edgar Minasyan;,citation_editor=Nikolai Matni;,citation_editor=Manfred Morari;,citation_editor=George J. Pappas;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://proceedings.mlr.press/v211/gradu23a.html;,citation_volume=211;,citation_conference_title=Proceedings of the 5th annual learning for dynamics and control conference;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Prediction, learning, and games;,citation_author=Nicolo Cesa-Bianchi;,citation_author=Gabor Lugosi;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_doi=10.1017/CBO9780511546921;">
<meta name="citation_reference" content="citation_title=A collaborative multiyear, multimodel assessment of seasonal influenza forecasting in the united states;,citation_abstract=Influenza infects an estimated 9-35 million individuals each year in the United States and is a contributing cause for between 12,000 and 56,000 deaths annually. Seasonal outbreaks of influenza are common in temperate regions of the world, with highest incidence typically occurring in colder and drier months of the year. Real-time forecasts of influenza transmission can inform public health response to outbreaks. We present the results of a multiinstitution collaborative effort to standardize the collection and evaluation of forecasting models for influenza in the United States for the 2010/2011 through 2016/2017 influenza seasons. For these seven seasons, we assembled weekly real-time forecasts of seven targets of public health interest from 22 different models. We compared forecast accuracy of each model relative to a historical baseline seasonal average. Across all regions of the United States, over half of the models showed consistently better performance than the historical baseline when forecasting incidence of influenza-like illness 1 wk, 2 wk, and 3 wk ahead of available data and when forecasting the timing and magnitude of the seasonal peak. In some regions, delays in data reporting were strongly and negatively associated with forecast accuracy. More timely reporting and an improved overall accessibility to novel and traditional data sources are needed to improve forecasting accuracy and its integration with real-time public health decision making.;,citation_author=Nicholas G Reich;,citation_author=Logan C Brooks;,citation_author=Spencer J Fox;,citation_author=Sasikiran Kandula;,citation_author=Craig J McGowan;,citation_author=Evan Moore;,citation_author=Dave Osthus;,citation_author=Evan L Ray;,citation_author=Abhinav Tushar;,citation_author=Teresa K Yamana;,citation_author=Matthew Biggerstaff;,citation_author=Michael A Johansson;,citation_author=Roni Rosenfeld;,citation_author=Jeffrey Shaman;,citation_publication_date=2019-02;,citation_cover_date=2019-02;,citation_year=2019;,citation_issue=8;,citation_volume=116;,citation_journal_title=Proc. Natl. Acad. Sci. U. S. A.;">
<meta name="citation_reference" content="citation_title=Multidimensional additive spline approximation;,citation_abstract=We describe an adaptive procedure that approximates a function of many variables by a sum of (univariate) spline functions $s_m $ of selected linear combinations $a_m x$ of the coordinates $$\phi (x) = \sum\_{1 \leqq m \leqq M} {s\_m ( a\_m \cdot x)}.$$ The procedure is nonlinear in that not only the spline coefficients but also the linear combinations are optimized for the particular problem. The sample need not lie on a regular grid, and the approximation is affine invariant, smooth, and lends itself to graphical interpretation. Function values, derivatives, and integrals are inexpensive to evaluate.;,citation_author=Jerome H. Friedman;,citation_author=Eric Grosse;,citation_author=Werner Stuetzle;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_fulltext_html_url=https://doi.org/10.1137/0904023;,citation_issue=2;,citation_doi=10.1137/0904023;,citation_volume=4;,citation_journal_title=SIAM Journal on Scientific and Statistical Computing;">
<meta name="citation_reference" content="citation_title=A tutorial on conformal prediction;,citation_abstract=Conformal prediction uses past experience to determine precise levels of confidence in new predictions. Given an error probability ε, together with a method that makes a prediction undefined of a label y, it produces a set of labels, typically containing undefined, that also contains y with probability 1 – ε. Conformal prediction can be applied to any method for producing undefined: a nearest-neighbor method, a support-vector machine, ridge regression, etc.Conformal prediction is designed for an on-line setting in which labels are predicted successively, each one being revealed before the next is predicted. The most novel and valuable feature of conformal prediction is that if the successive examples are sampled independently from the same distribution, then the successive predictions will be right 1 – ε of the time, even though they are based on an accumulating data set rather than on independent data sets.In addition to the model under which successive examples are sampled independently, other on-line compression models can also use conformal prediction. The widely used Gaussian linear model is one of these.This tutorial presents a self-contained account of the theory of conformal prediction and works through several numerical examples. A more comprehensive treatment of the topic is provided in Algorithmic Learning in a Random World, by Vladimir Vovk, Alex Gammerman, and Glenn Shafer (Springer, 2005).;,citation_author=Glenn Shafer;,citation_author=Vladimir Vovk;,citation_publication_date=2008-06;,citation_cover_date=2008-06;,citation_year=2008;,citation_issn=1532-4435;,citation_volume=9;,citation_journal_title=J. Mach. Learn. Res.;,citation_publisher=JMLR.org;">
<meta name="citation_reference" content="citation_title=Improved Strongly Adaptive Online Learning using Coin Betting;,citation_abstract=This paper describes a new parameter-free online learning algorithm for changing environments. In comparing against algorithms with the same time complexity as ours, we obtain a strongly adaptive regret bound that is a factor of at least $\sqrt\log(T)$ better, where $T$ is the time horizon. Empirical results show that our algorithm outperforms state-of-the-art methods in learning with expert advice and metric learning scenarios.;,citation_author=Kwang-Sung Jun;,citation_author=Francesco Orabona;,citation_author=Stephen Wright;,citation_author=Rebecca Willett;,citation_editor=Aarti Singh;,citation_editor=Jerry Zhu;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://proceedings.mlr.press/v54/jun17a.html;,citation_volume=54;,citation_conference_title=Proceedings of the 20th international conference on artificial intelligence and statistics;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=ranger: A fast implementation of random forests for high dimensional data in C++ and R;,citation_author=Marvin N. Wright;,citation_author=Andreas Ziegler;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_doi=10.18637/jss.v077.i01;,citation_volume=77;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Influenza;,citation_abstract=Influenza is an infectious respiratory disease that, in humans, is caused by influenza A and influenza B viruses. Typically characterized by annual seasonal epidemics, sporadic pandemic outbreaks involve influenza A virus strains of zoonotic origin. The WHO estimates that annual epidemics of influenza result in ~1 billion infections, 3–5 million cases of severe illness and 300,000–500,000 deaths. The severity of pandemic influenza depends on multiple factors, including the virulence of the pandemic virus strain and the level of pre-existing immunity. The most severe influenza pandemic, in 1918, resulted in&amp;amp;amp;gt;40 million deaths worldwide. Influenza vaccines are formulated every year to match the circulating strains, as they evolve antigenically owing to antigenic drift. Nevertheless, vaccine efficacy is not optimal and is dramatically low in the case of an antigenic mismatch between the vaccine and the circulating virus strain. Antiviral agents that target the influenza virus enzyme neuraminidase have been developed for prophylaxis and therapy. However, the use of these antivirals is still limited. Emerging approaches to combat influenza include the development of universal influenza virus vaccines that provide protection against antigenically distant influenza viruses, but these vaccines need to be tested in clinical trials to ascertain their effectiveness.;,citation_author=Florian Krammer;,citation_author=Gavin J. D. Smith;,citation_author=Ron A. M. Fouchier;,citation_author=Malik Peiris;,citation_author=Katherine Kedzierska;,citation_author=Peter C. Doherty;,citation_author=Peter Palese;,citation_author=Megan L. Shaw;,citation_author=John Treanor;,citation_author=Robert G. Webster;,citation_author=Adolfo García-Sastre;,citation_publication_date=2018-06-28;,citation_cover_date=2018-06-28;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.1038/s41572-018-0002-y;,citation_issue=1;,citation_doi=10.1038/s41572-018-0002-y;,citation_issn=2056-676X;,citation_volume=4;,citation_journal_title=Nature Reviews Disease Primers;">
<meta name="citation_reference" content="citation_title=Influenza seasonality: Underlying causes and modeling theories;,citation_author=Eric Lofgren;,citation_author=N. H. Fefferman;,citation_author=Y. N. Naumov;,citation_author=J. Gorski;,citation_author=E. N. Naumova;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_fulltext_html_url=https://journals.asm.org/doi/abs/10.1128/jvi.01680-06;,citation_issue=11;,citation_doi=10.1128/jvi.01680-06;,citation_volume=81;,citation_journal_title=Journal of Virology;">
<meta name="citation_reference" content="citation_title=Results from the centers for disease control and prevention’s predict the 2013–2014 influenza season challenge;,citation_abstract=Early insights into the timing of the start, peak, and intensity of the influenza season could be useful in planning influenza prevention and control activities. To encourage development and innovation in influenza forecasting, the Centers for Disease Control and Prevention (CDC) organized a challenge to predict the 2013–14 Unites States influenza season.;,citation_author=Matthew Biggerstaff;,citation_author=David Alper;,citation_author=Mark Dredze;,citation_author=Spencer Fox;,citation_author=Isaac Chun-Hai Fung;,citation_author=Kyle S. Hickmann;,citation_author=Bryan Lewis;,citation_author=Roni Rosenfeld;,citation_author=Jeffrey Shaman;,citation_author=Ming-Hsiang Tsou;,citation_author=Paola Velardi;,citation_author=Alessandro Vespignani;,citation_author=Lyn Finelli;,citation_author=undefined Influenza Forecasting Contest Working Group;,citation_publication_date=2016-07-22;,citation_cover_date=2016-07-22;,citation_year=2016;,citation_fulltext_html_url=https://doi.org/10.1186/s12879-016-1669-x;,citation_issue=1;,citation_doi=10.1186/s12879-016-1669-x;,citation_issn=1471-2334;,citation_volume=16;,citation_journal_title=BMC Infectious Diseases;">
<meta name="citation_reference" content="citation_title=FluSightNetwork: Cdc-flusight-ensemble repository;,citation_author=Abhinav Tushar;,citation_author=Nicholas Reich;,citation_author=Teresa Yamana;,citation_author=Dave Osthus;,citation_author=Craig McGowan;,citation_author=Evan Ray;,citation_author=undefined al.;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_publisher=https://github.com/FluSightNetwork/cdc-flusight-ensemble;">
<meta name="citation_reference" content="citation_title=conformalInference: Tools for conformal inference in regression;,citation_author=Ryan Tibshirani;,citation_author=Jacopo Diquigiovanni;,citation_author=Matteo Fontana;,citation_author=Paolo Vergottini;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=conformalInference.fd: Tools for conformal inference for regression in multivariate functional setting;,citation_author=Jacopo Diquigiovanni;,citation_author=Matteo Fontana;,citation_author=Aldo Solari;,citation_author=Simone Vantini;,citation_author=Paolo Vergottini;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=conformalInference.fd;">
<meta name="citation_reference" content="citation_title=Conformal Inference of Counterfactuals and Individual Treatment Effects;,citation_abstract=Evaluating treatment effect heterogeneity widely informs treatment decision making. At the moment, much emphasis is placed on the estimation of the conditional average treatment effect via flexible machine learning algorithms. While these methods enjoy some theoretical appeal in terms of consistency and convergence rates, they generally perform poorly in terms of uncertainty quantification. This is troubling since assessing risk is crucial for reliable decision-making in sensitive and uncertain environments. In this work, we propose a conformal inference-based approach that can produce reliable interval estimates for counterfactuals and individual treatment effects under the potential outcome framework. For completely randomized or stratified randomized experiments with perfect compliance, the intervals have guaranteed average coverage in finite samples regardless of the unknown data generating mechanism. For randomized experiments with ignorable compliance and general observational studies obeying the strong ignorability assumption, the intervals satisfy a doubly robust property which states the following: the average coverage is approximately controlled if either the propensity score or the conditional quantiles of potential outcomes can be estimated accurately. Numerical studies on both synthetic and real data sets empirically demonstrate that existing methods suffer from a significant coverage deficit even in simple models. In contrast, our methods achieve the desired coverage with reasonably short intervals.;,citation_author=Lihua Lei;,citation_author=Emmanuel J. Candès;,citation_publication_date=2021-10;,citation_cover_date=2021-10;,citation_year=2021;,citation_fulltext_html_url=https://doi.org/10.1111/rssb.12445;,citation_issue=5;,citation_doi=10.1111/rssb.12445;,citation_issn=1369-7412;,citation_volume=83;,citation_journal_title=Journal of the Royal Statistical Society Series B: Statistical Methodology;">
<meta name="citation_reference" content="citation_title=Strictly proper scoring rules, prediction, and estimation;,citation_author=Tilmann Gneiting;,citation_author=Adrian E Raftery;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_fulltext_html_url=https://doi.org/10.1198/016214506000001437;,citation_issue=477;,citation_doi=10.1198/016214506000001437;,citation_volume=102;,citation_journal_title=Journal of the American Statistical Association;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=The M4 competition: 100,000 time series and 61 forecasting methods;,citation_abstract=The M4 Competition follows on from the three previous M competitions, the purpose of which was to learn from empirical evidence both how to improve the forecasting accuracy and how such learning could be used to advance the theory and practice of forecasting. The aim of M4 was to replicate and extend the three previous competitions by: (a) significantly increasing the number of series, (b) expanding the number of forecasting methods, and (c) including prediction intervals in the evaluation process as well as point forecasts. This paper covers all aspects of M4 in detail, including its organization and running, the presentation of its results, the top-performing methods overall and by categories, its major findings and their implications, and the computational requirements of the various methods. Finally, it summarizes its main conclusions and states the expectation that its series will become a testing ground for the evaluation of new methods and the improvement of the practice of forecasting, while also suggesting some ways forward for the field.;,citation_author=Spyros Makridakis;,citation_author=Evangelos Spiliotis;,citation_author=Vassilios Assimakopoulos;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0169207019301128;,citation_issue=1;,citation_doi=https://doi.org/10.1016/j.ijforecast.2019.04.014;,citation_issn=0169-2070;,citation_volume=36;,citation_journal_title=International Journal of Forecasting;">
<meta name="citation_reference" content="citation_title=Achieving risk control in online learning settings;,citation_author=Shai Feldman;,citation_author=Liran Ringel;,citation_author=Stephen Bates;,citation_author=Yaniv Romano;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://openreview.net/forum?id=5Y04GWvoJu;,citation_issn=2835-8856;,citation_journal_title=Transactions on Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Conformal prediction interval for dynamic time-series;,citation_abstract=We develop a method to construct distribution-free prediction intervals for dynamic time-series, called EnbPI that wraps around any bootstrap ensemble estimator to construct sequential prediction intervals. EnbPI is closely related to the conformal prediction (CP) framework but does not require data exchangeability. Theoretically, these intervals attain finite-sample, &amp;amp;amp;lt;i&amp;gt;approximately valid&amp;lt;/i&amp;gt; marginal coverage for broad classes of regression functions and time-series with strongly mixing stochastic errors. Computationally, EnbPI avoids overfitting and requires neither data-splitting nor training multiple ensemble estimators; it efficiently aggregates bootstrap estimators that have been trained. In general, EnbPI is easy to implement, scalable to producing arbitrarily many prediction intervals sequentially, and well-suited to a wide range of regression functions. We perform extensive real-data analyses to demonstrate its effectiveness.;,citation_author=Chen Xu;,citation_author=Yao Xie;,citation_editor=Marina Meila;,citation_editor=Tong Zhang;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://proceedings.mlr.press/v139/xu21h.html;,citation_volume=139;,citation_conference_title=Proceedings of the 38th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Sequential predictive conformal inference for time series;,citation_abstract=We present a new distribution-free conformal prediction algorithm for sequential data (e.g., time series), called the &amp;amp;amp;lt;em&amp;gt;sequential predictive conformal inference&amp;lt;/em&amp;gt; (SPCI). We specifically account for the nature that time series data are non-exchangeable, and thus many existing conformal prediction algorithms are not applicable. The main idea is to adaptively re-estimate the conditional quantile of non-conformity scores (e.g., prediction residuals), upon exploiting the temporal dependence among them. More precisely, we cast the problem of conformal prediction interval as predicting the quantile of a future residual, given a user-specified point prediction algorithm. Theoretically, we establish asymptotic valid conditional coverage upon extending consistency analyses in quantile regression. Using simulation and real-data experiments, we demonstrate a significant reduction in interval width of SPCI compared to other existing methods under the desired empirical coverage.;,citation_author=Chen Xu;,citation_author=Yao Xie;,citation_editor=Andreas Krause;,citation_editor=Emma Brunskill;,citation_editor=Kyunghyun Cho;,citation_editor=Barbara Engelhardt;,citation_editor=Sivan Sabato;,citation_editor=Jonathan Scarlett;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://proceedings.mlr.press/v202/xu23r.html;,citation_volume=202;,citation_conference_title=Proceedings of the 40th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=FluSightNetwork/cdc-flusight-ensemble: End of 2018/2019 US influenza season;,citation_author=Abhinav Tushar;,citation_author=Nicholas G Reich;,citation_author=undefined tkcy;,citation_author=undefined brookslogan;,citation_author=undefined d-osthus;,citation_author=Craig McGowan;,citation_author=Evan Ray;,citation_author=Katie House;,citation_author=Spencer J Fox;,citation_author=Evan Moore;,citation_author=undefined lcbrooks;,citation_author=Adam Leskis;,citation_author=Xinyue X;,citation_author=undefined NutchaW;,citation_publication_date=2019-09;,citation_cover_date=2019-09;,citation_year=2019;,citation_fulltext_html_url=https://doi.org/10.5281/zenodo.3454212;,citation_doi=10.5281/zenodo.3454212;,citation_publisher=Zenodo;">
<meta name="citation_reference" content="citation_title=GitHub - FluSightNetwork/cdc-flusight-ensemble: Guidelines and forecasts for a collaborative u.s. Influenza forecasting project;,citation_author=Flusight Network;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://github.com/FluSightNetwork/;">
<meta name="citation_reference" content="citation_title=Online conformal prediction with decaying step sizes;,citation_author=Anastasios N. Angelopoulos;,citation_author=Rina Foygel Barber;,citation_author=Stephen Bates;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://arxiv.org/abs/2402.01139;">
<meta name="citation_reference" content="citation_title=Conformal online model aggregation;,citation_author=Matteo Gasparin;,citation_author=Aaditya Ramdas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://arxiv.org/abs/2403.15527;">
<meta name="citation_reference" content="citation_title=Discounted adaptive online prediction;,citation_author=Zhiyu Zhang;,citation_author=David Bombara;,citation_author=Heng Yang;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://arxiv.org/abs/2402.02720;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><a href="https://computo.sfds.asso.fr">
        <img src="https://computo.sfds.asso.fr/assets/img/logo_notext_white.png" height="60px">
      </a> &nbsp; AdaptiveConformal: An <code>R</code> Package for Adaptive Conformal Inference</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> source</button></div></div>
            <p class="subtitle lead">AdaptiveConformal: An <code>R</code> Package for Adaptive Conformal Inference</p>
            <p><a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/80x15.png" alt="Creative Commons BY License"></a>
ISSN 2824-7795</p>
            <div>
        <div class="description">
          <p>Conformal Inference (CI) is a popular approach for generating finite sample prediction intervals based on the output of any point prediction method when data are exchangeable. Adaptive Conformal Inference (ACI) algorithms extend CI to the case of sequentially observed data, such as time series, and exhibit strong theoretical guarantees without having to assume exchangeability of the observed data. The common thread that unites algorithms in the ACI family is that they adaptively adjust the width of the generated prediction intervals in response to the observed data. We provide a detailed description of five ACI algorithms and their theoretical guarantees, and test their performance in simulation studies. We then present a case study of producing prediction intervals for influenza incidence in the United States based on black-box point forecasts. Implementations of all the algorithms are released as an open-source <code>R</code> package, <code>AdaptiveConformal</code>, which also includes tools for visualizing and summarizing conformal prediction intervals.</p>
        </div>
      </div>
                </div>
  </div>
    
    <div class="quarto-title-meta-author">
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-heading">Affiliations</div>
          
          <div class="quarto-title-meta-contents">
        <a href="https://herbsusmann.com">Herbert Susmann</a> <a href="https://orcid.org/0000-0002-3540-8255" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://www.ceremade.dauphine.fr/">
                  CEREMADE (UMR 7534), Université Paris-Dauphine PSL, Place du Maréchal de Lattre de Tassigny, Paris, 75016, France
                  </a>
                </p>
            </div>
            <div class="quarto-title-meta-contents">
        <a href="https://helios2.mi.parisdescartes.fr/~chambaz/">Antoine Chambaz</a> <a href="https://orcid.org/0000-0002-5592-6471" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://map5.mi.parisdescartes.fr/">
                  Université Paris Cité, CNRS, MAP5, F-75006 Paris, France
                  </a>
                </p>
            </div>
            <div class="quarto-title-meta-contents">
        <a href="http://juliejosse.com/">Julie Josse</a> <a href="https://orcid.org/0000-0001-9547-891X" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://team.inria.fr/premedical/">
                  Inria PreMeDICaL team, Idesp, Université de Montpellier
                  </a>
                </p>
            </div>
        </div>
                    
  <div class="quarto-title-meta">
                                
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 18, 2024</p>
      </div>
    </div>
                                    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">December 1, 2024</p>
      </div>
    </div>
      
                  
      <div>
      <div class="quarto-title-meta-heading">Keywords</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Conformal inference, Adaptive conformal inference, time series, R</p>
      </div>
    </div>
    
    <div>
      <div class="quarto-title-meta-heading">Status</div>
      <div class="quarto-title-meta-contents">
              <a href="https://github.com/computorg/published-202407-susmann-adaptive-conformal"><img src="https://github.com/computorg/published-202407-susmann-adaptive-conformal/actions/workflows/build.yml/badge.svg" alt="build status"></a>
                    <p class="date"></p>
        <a href="https://github.com/computorg/published-202407-susmann-adaptive-conformal/issues?q=is%3Aopen+is%3Aissue+label%3Areview"><img src="https://img.shields.io/badge/reviews-reports-blue" alt="reviews"></a>
            </div>
    </div>

  </div>
                                                
  <div>
    <div class="abstract">
    <div class="abstract-title">Abstract</div>
      <p>Conformal Inference (CI) is a popular approach for generating finite sample prediction intervals based on the output of any point prediction method when data are exchangeable. Adaptive Conformal Inference (ACI) algorithms extend CI to the case of sequentially observed data, such as time series, and exhibit strong theoretical guarantees without having to assume exchangeability of the observed data. The common thread that unites algorithms in the ACI family is that they adaptively adjust the width of the generated prediction intervals in response to the observed data. We provide a detailed description of five ACI algorithms and their theoretical guarantees, and test their performance in simulation studies. We then present a case study of producing prediction intervals for influenza incidence in the United States based on black-box point forecasts. Implementations of all the algorithms are released as an open-source <code>R</code> package, <code>AdaptiveConformal</code>, which also includes tools for visualizing and summarizing conformal prediction intervals.</p>
    </div>
  </div>

  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#sec-theory" id="toc-sec-theory" class="nav-link" data-scroll-target="#sec-theory"><span class="header-section-number">2</span> Theoretical Framework</a>
  <ul class="collapse">
  <li><a href="#linear-intervals" id="toc-linear-intervals" class="nav-link" data-scroll-target="#linear-intervals"><span class="header-section-number">2.1</span> Linear Intervals</a></li>
  <li><a href="#quantile-intervals" id="toc-quantile-intervals" class="nav-link" data-scroll-target="#quantile-intervals"><span class="header-section-number">2.2</span> Quantile Intervals</a></li>
  <li><a href="#online-learning-framework" id="toc-online-learning-framework" class="nav-link" data-scroll-target="#online-learning-framework"><span class="header-section-number">2.3</span> Online Learning Framework</a></li>
  <li><a href="#assessing-aci-algorithms" id="toc-assessing-aci-algorithms" class="nav-link" data-scroll-target="#assessing-aci-algorithms"><span class="header-section-number">2.4</span> Assessing ACI algorithms</a></li>
  </ul></li>
  <li><a href="#sec-algorithms" id="toc-sec-algorithms" class="nav-link" data-scroll-target="#sec-algorithms"><span class="header-section-number">3</span> Algorithms</a>
  <ul class="collapse">
  <li><a href="#adaptive-conformal-inference-aci" id="toc-adaptive-conformal-inference-aci" class="nav-link" data-scroll-target="#adaptive-conformal-inference-aci"><span class="header-section-number">3.1</span> Adaptive Conformal Inference (ACI)</a>
  <ul class="collapse">
  <li><a href="#theoretical-guarantees" id="toc-theoretical-guarantees" class="nav-link" data-scroll-target="#theoretical-guarantees"><span class="header-section-number">3.1.1</span> Theoretical Guarantees</a></li>
  <li><a href="#tuning-parameters" id="toc-tuning-parameters" class="nav-link" data-scroll-target="#tuning-parameters"><span class="header-section-number">3.1.2</span> Tuning Parameters</a></li>
  </ul></li>
  <li><a href="#aggregated-adaptive-conformal-inference-agaci" id="toc-aggregated-adaptive-conformal-inference-agaci" class="nav-link" data-scroll-target="#aggregated-adaptive-conformal-inference-agaci"><span class="header-section-number">3.2</span> Aggregated Adaptive Conformal Inference (AgACI)</a>
  <ul class="collapse">
  <li><a href="#theoretical-gaurantees" id="toc-theoretical-gaurantees" class="nav-link" data-scroll-target="#theoretical-gaurantees"><span class="header-section-number">3.2.1</span> Theoretical Gaurantees</a></li>
  <li><a href="#sec-agaci-tuning" id="toc-sec-agaci-tuning" class="nav-link" data-scroll-target="#sec-agaci-tuning"><span class="header-section-number">3.2.2</span> Tuning Parameters</a></li>
  </ul></li>
  <li><a href="#dynamically-tuned-adaptive-conformal-inference-dtaci" id="toc-dynamically-tuned-adaptive-conformal-inference-dtaci" class="nav-link" data-scroll-target="#dynamically-tuned-adaptive-conformal-inference-dtaci"><span class="header-section-number">3.3</span> Dynamically-tuned Adaptive Conformal Inference (DtACI)</a>
  <ul class="collapse">
  <li><a href="#theoretical-guarantees-1" id="toc-theoretical-guarantees-1" class="nav-link" data-scroll-target="#theoretical-guarantees-1"><span class="header-section-number">3.3.1</span> Theoretical Guarantees</a></li>
  <li><a href="#tuning-parameters-1" id="toc-tuning-parameters-1" class="nav-link" data-scroll-target="#tuning-parameters-1"><span class="header-section-number">3.3.2</span> Tuning parameters</a></li>
  </ul></li>
  <li><a href="#scale-free-online-gradient-descent-sf-ogd" id="toc-scale-free-online-gradient-descent-sf-ogd" class="nav-link" data-scroll-target="#scale-free-online-gradient-descent-sf-ogd"><span class="header-section-number">3.4</span> Scale-Free Online Gradient Descent (SF-OGD)</a>
  <ul class="collapse">
  <li><a href="#theoretical-guarantees-2" id="toc-theoretical-guarantees-2" class="nav-link" data-scroll-target="#theoretical-guarantees-2"><span class="header-section-number">3.4.1</span> Theoretical Guarantees</a></li>
  <li><a href="#tuning-parameters-2" id="toc-tuning-parameters-2" class="nav-link" data-scroll-target="#tuning-parameters-2"><span class="header-section-number">3.4.2</span> Tuning parameters</a></li>
  </ul></li>
  <li><a href="#strongly-adaptive-online-conformal-prediction-saocp" id="toc-strongly-adaptive-online-conformal-prediction-saocp" class="nav-link" data-scroll-target="#strongly-adaptive-online-conformal-prediction-saocp"><span class="header-section-number">3.5</span> Strongly Adaptive Online Conformal Prediction (SAOCP)</a>
  <ul class="collapse">
  <li><a href="#theoretical-guarantees-3" id="toc-theoretical-guarantees-3" class="nav-link" data-scroll-target="#theoretical-guarantees-3"><span class="header-section-number">3.5.1</span> Theoretical Guarantees</a></li>
  <li><a href="#tuning-parameters-3" id="toc-tuning-parameters-3" class="nav-link" data-scroll-target="#tuning-parameters-3"><span class="header-section-number">3.5.2</span> Tuning Parameters</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#adaptiveconformal-r-package" id="toc-adaptiveconformal-r-package" class="nav-link" data-scroll-target="#adaptiveconformal-r-package"><span class="header-section-number">4</span> <code>AdaptiveConformal</code> <code>R</code> package</a></li>
  <li><a href="#sec-simulations" id="toc-sec-simulations" class="nav-link" data-scroll-target="#sec-simulations"><span class="header-section-number">5</span> Simulation Studies</a>
  <ul class="collapse">
  <li><a href="#time-series-with-arma-errors" id="toc-time-series-with-arma-errors" class="nav-link" data-scroll-target="#time-series-with-arma-errors"><span class="header-section-number">5.1</span> Time series with ARMA errors</a></li>
  <li><a href="#distribution-shift" id="toc-distribution-shift" class="nav-link" data-scroll-target="#distribution-shift"><span class="header-section-number">5.2</span> Distribution shift</a></li>
  </ul></li>
  <li><a href="#sec-case-study" id="toc-sec-case-study" class="nav-link" data-scroll-target="#sec-case-study"><span class="header-section-number">6</span> Case Study: Influenza Forecasting</a></li>
  <li><a href="#sec-discussion" id="toc-sec-discussion" class="nav-link" data-scroll-target="#sec-discussion"><span class="header-section-number">7</span> Discussion</a>
  <ul class="collapse">
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements">Acknowledgements</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  <li><a href="#appendix" id="toc-appendix" class="nav-link" data-scroll-target="#appendix"><span class="header-section-number">8</span> Appendix</a>
  <ul class="collapse">
  <li><a href="#additional-simulation-study-results" id="toc-additional-simulation-study-results" class="nav-link" data-scroll-target="#additional-simulation-study-results"><span class="header-section-number">8.1</span> Additional simulation study results</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="published-202407-susmann-adaptive-conformal.pdf"><i class="bi bi-file-pdf"></i>PDF (computo)</a></li></ul></div></nav>
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Conformal Inference (CI) is a family of methods for generating finite sample prediction intervals around point predictions when data are exchangeable <span class="citation" data-cites="vovk2005 shafer2008conformal angelopoulos2022gentle">(<a href="#ref-vovk2005" role="doc-biblioref">Vovk, Gammerman, and Shafer 2005</a>; <a href="#ref-shafer2008conformal" role="doc-biblioref">Shafer and Vovk 2008</a>; <a href="#ref-angelopoulos2022gentle" role="doc-biblioref">Angelopoulos and Bates 2023</a>)</span>. The input point predictions can be derived from any prediction method, making CI a powerful tool for augmenting black-box prediction algorithms with prediction intervals. Classical CI methods are able to yield marginally valid intervals with only the assumption that the joint distribution of the data does not change based on the order of the observations (that is, they are exchangeable). However, in many real-world settings data are not exchangeable: for example, time series data usually cannot be assumed to be exchangeable due to temporal dependence. A recent line of research examines the problem of generating prediction intervals for observations that are observed online (that is, one at a time) and for which exchangeability is not assumed to hold <span class="citation" data-cites="gibbs2021adaptive zaffran2022agaci gibbs2022faci bhatnagar2023saocp">(<a href="#ref-gibbs2021adaptive" role="doc-biblioref">Gibbs and Candes 2021</a>; <a href="#ref-zaffran2022agaci" role="doc-biblioref">Zaffran et al. 2022</a>; <a href="#ref-gibbs2022faci" role="doc-biblioref">Gibbs and Candès 2022</a>; <a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span>. The methods from this literature, which we refer to generally as <em>Adaptive Conformal Inference</em> (ACI) algorithms, work by adaptively adjusting the width of the generated prediction intervals in response to the observed data.</p>
<p>Informally, suppose a sequence of outcomes <span class="math inline">y_t \in \mathbb{R}</span>, <span class="math inline">t = 1, \dots, T</span> are observed one at a time. Before seeing each observation, we have at our disposal a point prediction <span class="math inline">\hat{\mu}_t \in \mathbb{R}</span> that can be generated by any method. Our goal is to find an algorithm for producing prediction intervals <span class="math inline">[\ell_t, u_t]</span>, <span class="math inline">\ell_t \leq u_t</span> such that, in the long run, the observations <span class="math inline">y_t</span> fall within the corresponding prediction intervals roughly <span class="math inline">\alpha \times 100\%</span> of the time: that is, <span class="math inline">\lim_{T \to \infty} \sfrac{1}{T} \sum_{t=1}^T \mathbb{I}\{ y_t \in [\ell_t, u_t] \} = \alpha</span>. The original ACI algorithm <span class="citation" data-cites="gibbs2021adaptive">(<a href="#ref-gibbs2021adaptive" role="doc-biblioref">Gibbs and Candes 2021</a>)</span> is based on a simple idea: if the previous prediction interval at time <span class="math inline">(t-1)</span> did not cover the true observation, then the next prediction interval at time <span class="math inline">t</span> is made slightly wider. Conversely, if the previous prediction interval did include the observation, then the next prediction interval is made slightly narrower. It can be shown that this procedure yields prediction intervals that in the long run cover the true observations the desired proportion of the time.</p>
<p>The main tuning parameter of the original ACI algorithm is a learning rate that controls how fast prediction interval width changes. If the learning rate is too low, then the prediction intervals will not be able to adapt fast enough to shifts in the data generating distribution; if it is too large, then the intervals will oscillate widely. The critical dependence of the original ACI algorithm on proper choice of its learning rate spurred subsequent research into meta-algorithms that learn the correct learning rate (or an analogue thereof) in various ways, typically drawing on approaches from the online learning literature. In this paper, we present four such algorithms: Aggregated ACI <span class="citation" data-cites="zaffran2022agaci">(AgACI, <a href="#ref-zaffran2022agaci" role="doc-biblioref">Zaffran et al. 2022</a>)</span>, Dynamically-tuned Adaptive ACI <span class="citation" data-cites="gibbs2022faci">(DtACI, <a href="#ref-gibbs2022faci" role="doc-biblioref">Gibbs and Candès 2022</a>)</span>, Scale-Free Online Gradient Descent <span class="citation" data-cites="bhatnagar2023saocp">(SF-OGD, <a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span>, and Strongly Adaptive Online Conformal Prediction <span class="citation" data-cites="bhatnagar2023saocp">(SAOCP, <a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span>. We note that the adaption of conformal inference techniques is an active area of research and the algorithms we focus on in this work are not exhaustive; see among others <span class="citation" data-cites="feldman2023achieving">Feldman et al. (<a href="#ref-feldman2023achieving" role="doc-biblioref">2023</a>)</span>, <span class="citation" data-cites="bastani2022practical">Bastani et al. (<a href="#ref-bastani2022practical" role="doc-biblioref">2022</a>)</span>, <span class="citation" data-cites="xu2021enbpi">Xu and Xie (<a href="#ref-xu2021enbpi" role="doc-biblioref">2021</a>)</span>, <span class="citation" data-cites="xu2023spci">Xu and Xie (<a href="#ref-xu2023spci" role="doc-biblioref">2023</a>)</span>, <span class="citation" data-cites="angelopoulos2024online">Angelopoulos, Barber, and Bates (<a href="#ref-angelopoulos2024online" role="doc-biblioref">2024</a>)</span>, <span class="citation" data-cites="zhang2024discounted">Zhang, Bombara, and Yang (<a href="#ref-zhang2024discounted" role="doc-biblioref">2024</a>)</span>, and <span class="citation" data-cites="gasparin2024conformal">Gasparin and Ramdas (<a href="#ref-gasparin2024conformal" role="doc-biblioref">2024</a>)</span>.</p>
<p>Our primary practical contribution is an implementation of each algorithm in an open source <code>R</code> package, <code>AdaptiveConformal</code>, which is available at <a href="https://github.com/herbps10/AdaptiveConformal">https://github.com/herbps10/AdaptiveConformal</a>. The package also includes routines for visualization and summary of the prediction intervals. We note that Python versions of several algorithms were also made available by <span class="citation" data-cites="zaffran2022agaci">Zaffran et al. (<a href="#ref-zaffran2022agaci" role="doc-biblioref">2022</a>)</span> and <span class="citation" data-cites="bhatnagar2023saocp">Bhatnagar et al. (<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">2023</a>)</span>, but to our knowledge this is the first package implementing them in <code>R</code>. In addition, several <code>R</code> packages exist for conformal inference in other contexts, including <code>conformalInference</code> focusing on regression <span class="citation" data-cites="tibshirani2019ci">(<a href="#ref-tibshirani2019ci" role="doc-biblioref">Tibshirani et al. 2019</a>)</span>, <code>conformalInference.fd</code>, with methods for functional responses <span class="citation" data-cites="diquigiovanni2022fd">(<a href="#ref-diquigiovanni2022fd" role="doc-biblioref">Diquigiovanni et al. 2022</a>)</span>, and <code>cfcausal</code> for causal inference related functionals <span class="citation" data-cites="lei2020cfcausal">(<a href="#ref-lei2020cfcausal" role="doc-biblioref">Lei and Candès 2021</a>)</span>. Our second practical contribution is to compare the performance of the algorithms in simulation studies and in a case study generating prediction intervals for influenza incidence in the United States based on black-box point forecasts.</p>
<p>The rest of the paper unfolds as follows. In <a href="#sec-theory" class="quarto-xref">Section&nbsp;2</a>, we present a unified theoretical framework for analyzing the ACI algorithms based on the online learning paradigm. In <a href="#sec-algorithms" class="quarto-xref">Section&nbsp;3</a> we provide descriptions of each algorithm along with their known theoretical properties. In <a href="#sec-simulations" class="quarto-xref">Section&nbsp;5</a> we compare the performance of the algorithms in several simulation studies. <a href="#sec-case-study" class="quarto-xref">Section&nbsp;6</a> gives a case study based on forecasting influenza in the United States. Finally, <a href="#sec-discussion" class="quarto-xref">Section&nbsp;7</a> provides a discussion and ideas for future research in this rapidly expanding field.</p>
</section>
<section id="sec-theory" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Theoretical Framework</h1>
<p><em>Notation</em>: for any integer <span class="math inline">N \geq 1</span> let <span class="math inline">\llbracket N \rrbracket := \{ 1, \dots, N \}</span>. Let <span class="math inline">\mathbb{I}</span> be the indicator function. Let <span class="math inline">\nabla f</span> denote the gradient (subgradient) of the differentiable (convex) function <span class="math inline">f</span>.</p>
<p>We consider an online learning scenario in which we gain access to a sequence of observations <span class="math inline">(y_t)_{t \geq 1}</span> one at a time (see <span class="citation" data-cites="cesabianchi2006games">Cesa-Bianchi and Lugosi (<a href="#ref-cesabianchi2006games" role="doc-biblioref">2006</a>)</span> for an comprehensive account of online learning theory). Fix <span class="math inline">\alpha \in (0, 1)</span> to be the target empirical coverage of the prediction intervals. The goal is to output at time <span class="math inline">t</span> a prediction interval for the unseen observation <span class="math inline">y_{t}</span>, with the prediction interval generated by an <em>interval construction function</em> <span class="math inline">\widehat{C}_{t}</span>. Formally, let <span class="math inline">\widehat{C}_t</span> be a function that takes as input a parameter <span class="math inline">\theta_t \in \mathbb{R}</span> and outputs a closed prediction interval <span class="math inline">[\ell_t, u_t]</span>. The interval construction function must be nested: if <span class="math inline">\theta^\prime &gt; \theta</span>, then <span class="math inline">\widehat{C}_t(\theta) \subseteq \widehat{C}_t(\theta^\prime)</span>. In words, larger values of <span class="math inline">\theta</span> imply wider prediction intervals. The interval constructor is indexed by <span class="math inline">t</span> to emphasize that it may use other information at each time point, such as a point prediction <span class="math inline">\hat{\mu}_t \in \mathbb{R}</span>. We make no restrictions on how this external information is generated.</p>
<p>Define <span class="math inline">r_t := \inf\{\theta \in \mathbb{R} : y_t \in \widehat{C}_t(\theta) \}</span> to be the <em>radius</em> at time <span class="math inline">t</span>. The radius is the smallest possible <span class="math inline">\theta</span> such that the prediction interval covers the observation <span class="math inline">y_t</span>. A key assumption for the theoretical analysis of several of the algorithms is that the radii are bounded:</p>
<p><strong>Assumption</strong>: there exists a finite <span class="math inline">D &gt; 0</span> such that <span class="math inline">r_t &lt; D</span> for all <span class="math inline">t</span>.</p>
<p>If the outcome space is bounded, then <span class="math inline">D</span> can be easily chosen to cover the entire space. Next, we describe two existing definitions of interval construction functions.</p>
<section id="linear-intervals" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="linear-intervals"><span class="header-section-number">2.1</span> Linear Intervals</h2>
<p>A simple method for forming the prediction intervals is to use the parameter <span class="math inline">\theta_t</span> to directly define the width of the interval. Suppose that at each time <span class="math inline">t</span> we have access to a point prediction <span class="math inline">\hat{\mu}_t \in \mathbb{R}</span>. Then we can form a symmetric prediction interval around the point estimate using <span class="math display">
\begin{aligned}
  \theta \mapsto \widehat{C}_t(\theta) := [\hat{\mu}_t - \theta, \hat{\mu}_t + \theta].
\end{aligned}
</span> We refer to this as the <em>linear interval constructor</em>. Note that in this case, the radius is simply the absolute residual <span class="math inline">r_t = |\hat{\mu}_t - y_t|</span>.</p>
</section>
<section id="quantile-intervals" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="quantile-intervals"><span class="header-section-number">2.2</span> Quantile Intervals</h2>
<p>The original ACI paper proposed constructing intervals based on the previously observed residuals <span class="citation" data-cites="gibbs2021adaptive">(<a href="#ref-gibbs2021adaptive" role="doc-biblioref">Gibbs and Candes 2021</a>)</span>. Let <span class="math inline">S : \mathbb{R}^2 \to \mathbb{R}</span> be a function called a <em>nonconformity score</em>. A popular choice of nonconformity score is the absolute residual: <span class="math inline">(\mu, y) \mapsto  S(\mu, y):= |\mu - y|</span>. Let <span class="math inline">s_t := S(\hat{\mu}_t, y_t)</span> be the nonconformity score of the <span class="math inline">t</span>th-observation. The quantile interval construction function is then given by <span class="math display">
\begin{aligned}
  \widehat{C}_t(\theta_t) := [\hat{\mu}_t - \mathrm{Quantile}(\theta, \{ s_1, \dots, s_{t-1} \}), \hat{\mu}_t + \mathrm{Quantile}(\theta, \{ s_1, \dots, s_{t-1} \})]
\end{aligned}
</span> where <span class="math inline">\mathrm{Quantile}(\theta, A)</span> denotes the empirical <span class="math inline">\theta</span>-quantile of the elements in the set <span class="math inline">A</span>. Note that <span class="math inline">\widehat{C}_t</span> is indeed nested in <span class="math inline">\theta_t</span> because the Quantile function is non-decreasing in <span class="math inline">\theta</span>. Note we define <span class="math inline">\widehat{C}_t(1) = \max\{s_1, \dots, s_{t-1}\}</span> rather than <span class="math inline">\widehat{C}_t(1) = \infty</span> in order to avoid practical problems with trivial prediction intervals <span class="citation" data-cites="zaffran2022agaci">(<a href="#ref-zaffran2022agaci" role="doc-biblioref">Zaffran et al. 2022</a>)</span>. Note that we can always choose <span class="math inline">D = 1</span> to satisfy the outcome boundedness assumption given above.</p>
<p>We focus on the above definition for the quantile interval construction function which is designed to be symmetric around the point prediction <span class="math inline">\hat{\mu}_t</span>. However, we note it is possible to take a more general definition, such as <span class="math display">
\widehat{C}_t(\theta_t) := \{ y : S(\hat{\mu}_t, y) \leq \mathrm{Quantile(\theta, \{ s_1, \dots, s_{t-1}\})} \}
</span> Such an approach allows for prediction intervals that may not be centered on <span class="math inline">\hat{\mu}_t</span>.</p>
<p>Our proposed <code>AdaptiveConformal</code> package takes the absolute residual as the default nonconformity score, although the user may also specify any custom nonconformity score by supplying it as an <code>R</code> function.</p>
</section>
<section id="online-learning-framework" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="online-learning-framework"><span class="header-section-number">2.3</span> Online Learning Framework</h2>
<p>We now introduce a loss function that defines the quality of a prediction interval with respect to a realized observation. Define the <em>pinball loss</em> <span class="math inline">L^\alpha</span> as <span class="math display">
(\theta, r) \mapsto L^\alpha(\theta, r) := \begin{cases}
  (1 - \alpha)(\theta - r), &amp; \theta \geq r \\
  \alpha(r - \theta), &amp; \theta &lt; r.
\end{cases}
</span> The way in which the algorithm gains access to the data and incurs losses is as follows:</p>
<ul>
<li>Sequentially, for <span class="math inline">t = 1, \dots, T</span>:
<ul>
<li>Predict radius <span class="math inline">\theta_t</span> and form prediction interval <span class="math inline">\widehat{C}_t(\theta_t)</span>.</li>
<li>Observe true outcome <span class="math inline">y_t</span> and calculate radius <span class="math inline">r_t</span>.</li>
<li>Record <span class="math inline">\mathrm{err}_t := \mathbb{I}[y_t \not\in \widehat{C}_t(\theta_t)]</span>.</li>
<li>Incur loss <span class="math inline">L^\alpha(\theta_t, r_t)</span>.</li>
</ul></li>
</ul>
<p>This iterative procedure is at the core of the online learning theoretical framework in which theoretical results have been derived.</p>
</section>
<section id="assessing-aci-algorithms" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="assessing-aci-algorithms"><span class="header-section-number">2.4</span> Assessing ACI algorithms</h2>
<p>There are two different perspectives we can take in measuring the quality of an ACI algorithm that generates a sequence <span class="math inline">(\theta_t)_{t \in \llbracket T \rrbracket}</span>. First, we could look at how close the empirical coverage of the generated prediction intervals is to the desired coverage level <span class="math inline">\alpha</span>. Formally, define the empirical coverage as the proportion of observations that fell within the corresponding prediction interval: <span class="math inline">\mathrm{EmpCov}(T) := \frac{1}{T} \sum_{t=1}^T (1 - \mathrm{err}_t)</span>. The coverage error is then given by <span class="math display">
\begin{aligned}
  \mathrm{CovErr}(T) := \mathrm{EmpCov}(T) - \alpha.
\end{aligned}
</span> The second perspective is to look at how well the algorithm controls the incurred pinball losses. Following the classical framework from the online learning literature, we define the <em>regret</em> as the difference between the cumulative loss yielded by a sequence <span class="math inline">(\theta_t)_{t \in \llbracket T \rrbracket}</span> versus the cumulative loss of the best possible fixed choice: <span class="math display">
\begin{aligned}
  \mathrm{Reg}(T) := \sum_{t=1}^T L^\alpha(\theta_t, r_t) - \inf_{\theta^* \in \mathbb{R}} \sum_{t=1}^T L^\alpha(\theta^*, r_t).
\end{aligned}
</span> In settings of distribution shift, it may not be appropriate to compare the cumulative loss of an algorithm to a fixed competitor. As such, stronger notions of regret have been defined. The <em>strongly adaptive regret</em> is the largest regret over any subperiod of length <span class="math inline">m \in \llbracket T \rrbracket</span>: <span class="math display">
\begin{aligned}
  \mathrm{SAReg}(T, m) := \max_{[\tau, \tau + m - 1] \subseteq \llbracket T \rrbracket} \left( \sum_{t=\tau}^{\tau + m - 1} L^{\alpha}(\theta_t, r_t) - \inf_{\theta^* \in \mathbb{R}} \sum_{t=\tau}^{\tau + m - 1} L^\alpha(\theta^*, r_t) \right).
\end{aligned}
</span> Both ways of evaluating ACI methods are important because targeting only one or the other can lead to algorithms that yield prediction intervals that are not practically useful. As a simple pathological example of only targeting the coverage error, suppose we wish to generate <span class="math inline">\alpha = 50\%</span> prediction intervals. We could choose to alternate <span class="math inline">\theta</span> between 0 and <span class="math inline">\infty</span>, such that <span class="math inline">\mathrm{err}_t</span> alternates between 0 and 1. The empirical coverage would then trivially converge to the desired level of 50%. However, the same algorithm would yield infinite regret (see <span class="citation" data-cites="bhatnagar2023saocp">Bhatnagar et al. (<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">2023</a>)</span> for a more in-depth example of an scenario in which coverage is optimal but the regret grows linearly). On the other hand, an algorithm that has arbitrarily small regret may not yield good empirical coverage. Suppose the observations and point predictions are constant: <span class="math inline">y_t = 1</span> and <span class="math inline">\hat{\mu}_t = 0</span> for all <span class="math inline">t \geq 1</span>. Consider a simple class of algorithms that outputs constantly <span class="math inline">\theta_t = \theta'</span> for some <span class="math inline">\theta' &lt; 1</span>. With the linear interval construction function, the prediction intervals are then <span class="math inline">\widehat{C}_t(\theta_t) = [-\theta', \theta']</span>. The regret is given by <span class="math inline">\mathrm{Reg}(T) = 2T\alpha(1-\theta')</span>, which approaches zero as <span class="math inline">\theta'</span> approaches 1. The empirical coverage is, however, always zero. In other words, the regret can be arbitrarily close to zero while at the same time the empirical coverage does not approach the desired level.</p>
<p>These simple examples illustrate that, unfortunately, bounds on the coverage error and bounds on the regret are not in general interchangeable. It is possible, however, to show equivalencies by either (1) making distributional assumptions on the data or (2) using additional information about how the algorithm produces the sequence <span class="math inline">(\theta_t)_{t \in \llbracket T \rrbracket}</span> <span class="citation" data-cites="bhatnagar2023saocp">(<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span>.</p>
<p>It may also be informative to summarize a set of prediction intervals in ways beyond their coverage error or their regret. A common metric for prediction intervals is the <em>mean interval width</em>: <span class="math display">
\begin{aligned}
  \mathrm{MeanWidth}(T) := \frac{1}{T} \sum_{t=1}^T w_t,
\end{aligned}
</span> where <span class="math inline">w_t := u_t - \ell_t</span> is the interval width at time <span class="math inline">t</span>.</p>
<p>Finally, we introduce a metric that is intended to capture pathological behavior that can arise with ACI algorithms where the prediction intervals oscillate between being extremely narrow and extremely wide. Define the <em>path length</em> of prediction intervals generated by an ACI algorithm as <span class="math display">
\begin{aligned}
  \mathrm{PathLength}(T) := \sum_{t=2}^T |w_t - w_{t-1}|.
\end{aligned}
</span> A high path length indicates that the prediction intervals were variable over time, and a low path length indicates the prediction intervals were stable.</p>
</section>
</section>
<section id="sec-algorithms" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Algorithms</h1>
<div id="tbl-aci" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-aci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Summary of ACI algorithms. Only the theoretical guarantees discussed in this paper are shown for each algorithm.
</figcaption>
<div aria-describedby="tbl-aci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 100%">
</colgroup>
<thead>
<tr class="header">
<th>Algorithm</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Adaptive Conformal Inference (ACI)</strong></td>
</tr>
<tr class="even">
<td>- Tuning parameters: learning rate <span class="math inline">\gamma</span></td>
</tr>
<tr class="odd">
<td>- Original interval constructor: quantile</td>
</tr>
<tr class="even">
<td>- Theoretical guarantees: coverage error, regret</td>
</tr>
<tr class="odd">
<td>- Citation: <span class="citation" data-cites="gibbs2021adaptive">Gibbs and Candes (<a href="#ref-gibbs2021adaptive" role="doc-biblioref">2021</a>)</span></td>
</tr>
<tr class="even">
<td><strong>Aggregated Adaptive Conformal Inference (AgACI)</strong></td>
</tr>
<tr class="odd">
<td>- Tuning parameters: candidate learning rates <span class="math inline">(\gamma_k)_{1 \leq k \leq K}</span></td>
</tr>
<tr class="even">
<td>- Original interval constructor: quantile</td>
</tr>
<tr class="odd">
<td>- Citation: <span class="citation" data-cites="zaffran2022agaci">Zaffran et al. (<a href="#ref-zaffran2022agaci" role="doc-biblioref">2022</a>)</span></td>
</tr>
<tr class="even">
<td><strong>Dynamically-tuned Adaptive Conformal Inference (DtACI)</strong></td>
</tr>
<tr class="odd">
<td>- Tuning parameters: candidate learning rates <span class="math inline">(\gamma_k)_{1 \leq k \leq K}</span></td>
</tr>
<tr class="even">
<td>- Original interval constructor: quantile</td>
</tr>
<tr class="odd">
<td>- Theoretical guarantees: coverage error, strongly adaptive regret, dynamic regret</td>
</tr>
<tr class="even">
<td>- Citation</td>
</tr>
<tr class="odd">
<td><strong>Scale-Free Online Gradient Descent (SF-OGD)</strong></td>
</tr>
<tr class="even">
<td>- Tuning parameters: learning rate <span class="math inline">\gamma</span> or maximum radius <span class="math inline">D</span></td>
</tr>
<tr class="odd">
<td>- Original interval constructor: linear</td>
</tr>
<tr class="even">
<td>- Theoretical guarantees: coverage error, anytime regret</td>
</tr>
<tr class="odd">
<td>- Citation: <span class="citation" data-cites="bhatnagar2023saocp">Bhatnagar et al. (<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">2023</a>)</span></td>
</tr>
<tr class="even">
<td><strong>Strongly Adaptive Online Conformal Prediction (SAOCP)</strong></td>
</tr>
<tr class="odd">
<td>- Tuning parameters: learning rate <span class="math inline">\gamma</span>, lifetime multiplier <span class="math inline">g</span></td>
</tr>
<tr class="even">
<td>- Original interval constructor: linear</td>
</tr>
<tr class="odd">
<td>- Theoretical guarantees: coverage error, strongly adaptive regret</td>
</tr>
<tr class="even">
<td>- Citation: <span class="citation" data-cites="bhatnagar2023saocp">Bhatnagar et al. (<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">2023</a>)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>As a simple running example to illustrate each algorithm, we simulate independently <span class="math inline">T = 500</span> values <span class="math inline">y_1, \dots, y_T</span> following <span class="math display">
\begin{aligned}
y_t &amp;\sim N(0, \sigma_t^2), \quad t \in \llbracket T \rrbracket, \\
\sigma_t &amp;= \begin{cases}
  0.2, &amp;t \leq 250, \\
  0.1, &amp;t &gt; 250.
\end{cases}
\end{aligned}
</span> For demonstration purposes we assume we have access to unbiased predictions <span class="math inline">\hat{\mu}_t = 0</span> for all <span class="math inline">t \in \llbracket T \rrbracket</span>. Throughout we set the target empirical coverage to <span class="math inline">\alpha = 0.8</span>.</p>
<section id="adaptive-conformal-inference-aci" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="adaptive-conformal-inference-aci"><span class="header-section-number">3.1</span> Adaptive Conformal Inference (ACI)</h2>
<div id="algo-aci" class="pseudocode-container quarto-float" data-comment-delimiter="//" data-caption-prefix="Algorithm" data-line-number="true" data-indent-size="1.2em" data-no-end="false" data-pseudocode-number="1" data-line-number-punc=":">
<div class="pseudocode">
\begin{algorithm} \caption{Adaptive Conformal Inference} \begin{algorithmic} \State \textbf{Input:} starting value $\theta_1$, learning rate $\gamma &gt; 0$. \For{$t = 1, 2, \dots, T$} \State \textbf{Output:} prediction interval $\widehat{C}_t(\theta_t)$. \State Observe $y_t$. \State Evaluate $\mathrm{err}_t = \mathbb{I}[y_t \not\in \widehat{C}_t(\theta_t)]$. \State Update $\theta_{t+1} = \theta_t + \gamma (\mathrm{err}_t - (1 - \alpha))$. \EndFor \end{algorithmic} \end{algorithm}
</div>
</div>
<p>The original ACI algorithm (<span class="citation" data-cites="gibbs2021adaptive">Gibbs and Candes (<a href="#ref-gibbs2021adaptive" role="doc-biblioref">2021</a>)</span>; <a href="#algo-aci" class="quarto-xref">Algorithm 1</a>) adaptively adjusts the width of the prediction intervals in response to the observations. The updating rule for the estimated radius can be derived as an online subgradient descent scheme. The subgradient of the pinball loss function with respect to <span class="math inline">\theta</span> is given by <span class="math display">
\begin{aligned}
  \nabla L^\alpha(\theta, r) &amp;= \begin{cases}
    \{ -\alpha \}, &amp;\theta &lt; r, \\
    \{ 1 - \alpha \}, &amp; \theta &gt; r, \\
    [-\alpha, 1 - \alpha], &amp;\theta = r
  \end{cases} \\
\end{aligned}
</span> It follows that, for all <span class="math inline">\theta_t \in \mathbb{R}</span> and <span class="math inline">r_t \in \mathbb{R}</span>, <span class="math display">
1 - \alpha - \mathrm{err}_t \in \nabla L^\alpha(\theta_t, r_t).
</span> This leads to the following update rule for <span class="math inline">\theta</span> based on subgradient descent: <span class="math display">
\begin{aligned}
  \theta_{t+1} = \theta_{t} + \gamma (\mathrm{err}_t - (1 - \alpha)),
\end{aligned}
</span> where <span class="math inline">\gamma &gt; 0</span> is a user-specified learning rate. For intuition, note that if <span class="math inline">y_t</span> fell outside of the prediction interval at time <span class="math inline">t</span> (<span class="math inline">\mathrm{err}_t = 1</span>) then the next interval is widened (<span class="math inline">\theta_{t+1} = \theta_t + \gamma \alpha</span>). On the contrary, if <span class="math inline">y_t</span> fell within the interval (<span class="math inline">\mathrm{err}_t = 0</span>) then the next interval is shortened (<span class="math inline">\theta_{t+1} = \theta_t - \gamma(1 - \alpha)</span>). The learning rate <span class="math inline">\gamma</span> controls how fast the width of the prediction intervals changes in response to the data.</p>
<section id="theoretical-guarantees" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="theoretical-guarantees"><span class="header-section-number">3.1.1</span> Theoretical Guarantees</h3>
<p>With the choice of the quantile interval structure, the ACI algorithm has the following finite sample bound on the coverage error (<span class="citation" data-cites="gibbs2021adaptive">Gibbs and Candes (<a href="#ref-gibbs2021adaptive" role="doc-biblioref">2021</a>)</span>; Proposition 4.1). For all <span class="math inline">\gamma &gt; 0</span> (and so long as <span class="math inline">\gamma</span> does not depend on <span class="math inline">T</span>), <span class="math display">
|\mathrm{CovErr}(T)| \leq \frac{\max\{\theta_1, 1 - \theta_1\} + \gamma}{\gamma T}.
</span> This result was originally shown for ACI with the choice of the quantile interval constructor, although it can also be extended to other interval constructors <span class="citation" data-cites="bhatnagar2023saocp">Feldman et al. (<a href="#ref-feldman2023achieving" role="doc-biblioref">2023</a>)</span>. More generally, the algorithm has the following coverage error bound in terms of the radius bound <span class="math inline">D</span> <span class="citation" data-cites="bhatnagar2023saocp">(<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span>: <span class="math display">
|\mathrm{CovErr}(T)| \leq \frac{D + \gamma}{\gamma T}.
</span> In addition, standard results for online subgradient descent yield the following regret bound with the use of the linear interval constructor, assuming that the true radii are bounded by <span class="math inline">D</span>: <span class="math display">
\mathrm{Reg}(T) \leq \mathcal{O}(D^2 / \gamma + \gamma T) \leq \mathcal{O}(D \sqrt{T}),
</span> where the second inequality follows if the optimal choice (with respect to long-term regret) of <span class="math inline">\gamma = D/\sqrt{T}</span> is used <span class="citation" data-cites="bhatnagar2023saocp">(<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span>. Taken together, these theoretical results imply that while the coverage error is guaranteed to converge to zero for any choice of <span class="math inline">\gamma</span>, achieving sublinear regret requires choosing <span class="math inline">\gamma</span> more carefully. This highlights the importance of both ways of assessing ACI algorithms: if we only focused on controlling the coverage error, we might not achieve optimal control of regret, leading to intervals that are not practically useful.</p>
</section>
<section id="tuning-parameters" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="tuning-parameters"><span class="header-section-number">3.1.2</span> Tuning Parameters</h3>
<p>Therefore, the main tuning parameter is the learning rate <span class="math inline">\gamma</span>. The theoretical bounds on the coverage error suggest setting a large <span class="math inline">\gamma</span> such that the coverage error decays quickly in <span class="math inline">T</span>; however, in practice and setting <span class="math inline">\gamma</span> too large will lead to intervals with large oscillations as seen in <a href="#fig-aci" class="quarto-xref">Figure&nbsp;1</a>. This is quantified in the path length, which increases significantly as <span class="math inline">\gamma</span> increases, even though the empirical coverage remains near the desired value of 80%. On the other hand, setting <span class="math inline">\gamma</span> too small will lead to intervals that do not adapt fast enough to distribution shifts. Thus, choosing a good value for <span class="math inline">\gamma</span> is essential. However, the optimal choice <span class="math inline">\gamma = D / \sqrt{T}</span> cannot be used directly in practice unless the time series length <span class="math inline">T</span> is fixed in advance, or the so called “doubling trick” is used to relax the need to know <span class="math inline">T</span> in advance (<span class="citation" data-cites="cesabianchi2006games">Cesa-Bianchi and Lugosi (<a href="#ref-cesabianchi2006games" role="doc-biblioref">2006</a>)</span>; Section 2.3).</p>
<p>The theoretical results guaranteeing the performance of the ACI algorithm do not depend on the choice of starting value <span class="math inline">\theta_1</span>, and thus in practice any value can be chosen. Indeed, the effect of the choice of <span class="math inline">\theta_1</span> decays over time as a function of the chosen learning rate. In practice, substantive prior information can be used to pick a reasonable starting value. By default, the <code>AdaptiveConformal</code> package sets <span class="math inline">\theta_1 = \alpha</span> when the quantile interval predictor is used, and <span class="math inline">\theta_1 = 0</span> otherwise, although in both cases the user can supply their own starting value. The behavior of the early prediction intervals in the examples (<a href="#fig-aci" class="quarto-xref">Figure&nbsp;1</a>) is driven by the small number of residuals available, which makes the output of the quantile interval constructor sensitive to small changes in <span class="math inline">\theta</span>. In practice, a warm-up period can be used before starting to produce prediction intervals so that the quantiles of the residuals are more stable.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-aci" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-aci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-aci-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-aci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Example 80% prediction intervals from the ACI algorithm for different choices of learning rate <span class="math inline">\gamma</span> and with <span class="math inline">\theta_1 = 0.8</span>. Blue and red points are observations that fell inside and outside the prediction intervals, respectively.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="aggregated-adaptive-conformal-inference-agaci" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="aggregated-adaptive-conformal-inference-agaci"><span class="header-section-number">3.2</span> Aggregated Adaptive Conformal Inference (AgACI)</h2>
<div id="algo-agaci" class="pseudocode-container quarto-float" data-comment-delimiter="//" data-caption-prefix="Algorithm" data-line-number="true" data-indent-size="1.2em" data-no-end="false" data-pseudocode-number="2" data-line-number-punc=":">
<div class="pseudocode">
\begin{algorithm} \caption{Aggregated Adaptive Conformal Inference} \begin{algorithmic} \State \textbf{Input:} candidate learning rates $(\gamma_k)_{1 \leq k \leq K }$, starting value $\theta_1$. \State Initialize lower and upper BOA algorithms $\mathcal{B}^\ell := \texttt{BOA}(\alpha \leftarrow (1 - \alpha) / 2)$ and $\mathcal{B}^u := \texttt{BOA}(\alpha \leftarrow (1 - (1 - \alpha)/2))$. \For{$k = 1, \dots, K$} \State Initialize ACI $\mathcal{A}_k = \texttt{ACI}(\alpha \leftarrow \alpha, \gamma \leftarrow \gamma_k, \theta_1 \leftarrow \theta_1)$. \EndFor \For{$t = 1, 2, \dots, T$} \For{$k = 1, \dots, K$} \State Retrieve candidate prediction interval $[\ell^k_{t}, u^k_{t}]$ from $\mathcal{A}_k$. \EndFor \State Compute aggregated lower bound $\tilde{\ell}_t := \mathcal{B}^\ell((\ell^k_t : k \in \{ 1, \dots, K \}))$. \State Compute aggregated upper bound $\tilde{u}_t := \mathcal{B}^u((u^k_t : k \in \{ 1, \dots, K \}))$. \State \textbf{Output:} prediction interval $[\tilde{\ell}_t, \tilde{u}_t]$. \State Observe $y_t$. \For{$k = 1, \dots, K$} \State Update $\mathcal{A}_k$ with observation $y_t$. \EndFor \State Update $\mathcal{B}^\ell$ with observed outcome $y_t$. \State Update $\mathcal{B}^u$ with observed outcome $y_t$. \EndFor \end{algorithmic} \end{algorithm}
</div>
</div>
<p>The Aggregated ACI (AgACI; <a href="#algo-agaci" class="quarto-xref">Algorithm 2</a>) algorithm solves the problem of choosing a learning rate for ACI by running multiple copies of the algorithm with different learning rates, and then separately combining the lower and upper interval bounds using an online aggregation of experts algorithm <span class="citation" data-cites="zaffran2022agaci">(<a href="#ref-zaffran2022agaci" role="doc-biblioref">Zaffran et al. 2022</a>)</span>. That is, one aggregation algorithm seeks to estimate the lower <span class="math inline">(1-\alpha)/2</span> quantile, and the other seeks to estimate the upper <span class="math inline">1 - (1 - \alpha) / 2</span> quantile. <span class="citation" data-cites="zaffran2022agaci">Zaffran et al. (<a href="#ref-zaffran2022agaci" role="doc-biblioref">2022</a>)</span> experimented with multiple online aggregation algorithms, and found that they yielded similar results. Thus, we follow their lead in using the Bernstein Online Aggregation (BOA) algorithm as implemented in the <code>opera</code> <code>R</code> package <span class="citation" data-cites="wintenberger2017boa opera2023">(<a href="#ref-wintenberger2017boa" role="doc-biblioref">Wintenberger 2017</a>; <a href="#ref-opera2023" role="doc-biblioref">Gaillard et al. 2023</a>)</span>. BOA is an online algorithm that forms predictions for the lower (or upper) prediction interval bound as a weighted mean of the candidate ACI prediction interval lower (upper) bound, where the weights are determined by each candidate’s past performance with respect to the quantile loss. As a consequence, the prediction intervals generated by AgACI are not necessarily symmetric around the point prediction, as the weights for the lower and upper bounds are separate.</p>
<section id="theoretical-gaurantees" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="theoretical-gaurantees"><span class="header-section-number">3.2.1</span> Theoretical Gaurantees</h3>
<p>AgACI departs from our main theoretical framework in that it does not yield a sequence <span class="math inline">(\theta_t)_{t \in \llbracket T \rrbracket}</span> whose elements yield prediction intervals via a set construction function <span class="math inline">\widehat{C}_t</span>. Rather, the upper and lower interval bounds from a set of candidate ACI algorithms are aggregated separately. Thus, theoretical results such as regret bounds similar to those for the other algorithms are not available. It would be possible, however, to establish regret bounds for the pinball loss applied separately to the lower and upper bounds of the prediction intervals. It is unclear, however, how to convert such regret bounds into a coverage bound.</p>
</section>
<section id="sec-agaci-tuning" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="sec-agaci-tuning"><span class="header-section-number">3.2.2</span> Tuning Parameters</h3>
<p>The main tuning parameter for AgACI is the set of candidate learning rates. Beyond necessitating additional computational time, there is no drawback to having a large grid. As a default, <code>AdaptiveConformal</code> uses learning rates <span class="math inline">\gamma \in \{ 0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128 \}</span>. As a basic check, we can look at the weights assigned to each of the learning rates. If large weights are given to the smallest (largest) learning rates, it is a sign that smaller (or larger) learning rates may perform well. In addition each of the candidate ACI algorithms requires a starting value, which can be set to any value as discussed in the ACI section. <a href="#fig-agaci" class="quarto-xref">Figure&nbsp;2</a> illustrates AgACI applied to the running example with two sets of learning grids. The first grid is <span class="math inline">\gamma = \{ 0.032, 0.064, 0.128, 0.256 \}</span>, and the second grid includes the additional values <span class="math inline">\{ 0.008, 0.016 \}</span>. For the first grid, we can see that for the lower bound AgACI assigns high weight to the lowest learning rate (<span class="math inline">\gamma = 0.032</span>). The second grid yields weights that are less concentrated on a single learning rate, and the output prediction intervals are smoother.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-agaci" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-agaci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-agaci-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-agaci-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Example 80% prediction intervals from the AgACI algorithm with starting values <span class="math inline">\theta_1 = 0.8</span> and two different learning rate grids. In the left column, blue and red points are observations that fell inside and outside the prediction intervals, respectively.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="dynamically-tuned-adaptive-conformal-inference-dtaci" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="dynamically-tuned-adaptive-conformal-inference-dtaci"><span class="header-section-number">3.3</span> Dynamically-tuned Adaptive Conformal Inference (DtACI)</h2>
<div id="algo-faci" class="pseudocode-container quarto-float" data-comment-delimiter="//" data-caption-prefix="Algorithm" data-line-number="true" data-indent-size="1.2em" data-no-end="false" data-pseudocode-number="3" data-line-number-punc=":">
<div class="pseudocode">
\begin{algorithm} \caption{Dynamically-tuned Adaptive Conformal Inference} \begin{algorithmic} \State \textbf{Input:} starting value $\theta_1$, candidate learning rates $(\gamma_k)_{1 \leq k \leq K }$, parameters $\sigma, \eta$. \For{$k = 1, \dots, K$} \State Initialize expert $\mathcal{A}_k = \texttt{ACI}(\alpha \leftarrow \alpha, \gamma \leftarrow \gamma_k, \theta_1 \leftarrow \theta_1)$. \EndFor \For{$t = 1, 2, \dots, T$} \State Define $p_t^k := p_t^k / \sum_{i=1}^K p_t^i$, for all $1 \leq k \leq K$. \State Set $\theta_t = \sum_{k=1}^K \theta_t^k p_t^k$. \State \textbf{Output:} prediction interval $\widehat{C}_t(\theta_t)$. \State Observe $y_t$ and compute $r_t$. \State $\bar{w}_{t}^k \gets p_t^k \exp(-\eta L^\alpha(\theta_t^k, r_t))$, for all $1 \leq k \leq K$. \State $\bar{W}_t \gets \sum_{i=1}^K \bar{w}_t^i$. \State $p_{t+1}^k \gets (1 - \sigma) \bar{w}_t^k + \bar{W}_t \sigma / K$. \State Set $\mathrm{err}_t := \mathbb{I}[y_t \not\in \widehat{C}_t(\theta_t)]$. \For{$k = 1, \dots, K$} \State Update ACI $\mathcal{A}_k$ with $y_t$ and obtain $\theta_{t+1}^k$. \EndFor \EndFor \end{algorithmic} \end{algorithm}
</div>
</div>
<p>The Dynamically-tuned Adaptive Conformal Inference (DtACI; <a href="#algo-faci" class="quarto-xref">Algorithm 3</a>) algorithm was developed by the authors of the original ACI algorithm in part to address the issue of how to choose the learning rate parameter <span class="math inline">\gamma</span>. In this respect the goal of the algorithm is similar to that of AgACI, although it is achieved slightly differently. DtACI also aggregates predictions from multiple copies of ACI run with different learning rates, but differs in that it directly aggregates the estimated radii emitted from each algorithm based on their pinball loss <span class="citation" data-cites="gibbs2022faci">(<a href="#ref-gibbs2022faci" role="doc-biblioref">Gibbs and Candès 2022</a>)</span> using an exponential reweighting scheme <span class="citation" data-cites="gradu2022adaptive">(<a href="#ref-gradu2022adaptive" role="doc-biblioref">Gradu, Hazan, and Minasyan 2023</a>)</span>. As opposed to AgACI, this construction allows for more straightforward development of theoretical guarantees on the algorithm’s performance, because the upper and lower bounds of the intervals are not aggregated separately.</p>
<section id="theoretical-guarantees-1" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="theoretical-guarantees-1"><span class="header-section-number">3.3.1</span> Theoretical Guarantees</h3>
<p>DtACI was originally proposed with the choice of the quantile interval constructor. DtACI has the following strongly-adaptive regret bound <span class="citation" data-cites="bhatnagar2023saocp">(<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span>: for all <span class="math inline">\eta &gt; 0</span> and subperiod lengths <span class="math inline">m</span>, <span class="math display">
\begin{aligned}
  \mathrm{SAReg}(T, m) \leq \widetilde{\mathcal{O}}(D^2 / \eta + \eta m).
\end{aligned}
</span> If <span class="math inline">m</span> is fixed a-priori, then choosing <span class="math inline">\eta = D/\sqrt{m}</span> yields a strongly adaptive regret bound of order <span class="math inline">\widetilde{\mathcal{O}}(D \sqrt{m})</span> (for a single choice of <span class="math inline">m</span>). Practically, this result implies that, if we know in advance the time length for which we would like to control the regret, it is possible to choose an optimal tuning parameter value. However, we cannot control the regret simultaneously for all possible time lengths.</p>
<p>To establish a bound on the coverage error, the authors investigated a slightly modified version of DtACI in which <span class="math inline">\theta_t</span> is chosen randomly from the candidate <span class="math inline">\theta_{t_k}</span> with weights given by <span class="math inline">p_{t,k}</span>, instead of taking a weighted average. This is a common trick used in the literature as it facilitates theoretical analysis. In practice, the authors comment that this randomized version of DtACI and the deterministic version lead to very similar results. The coverage error result also assumes that the hyperparameters can change over time: that is, we have <span class="math inline">t</span>-specific <span class="math inline">\eta_{t}</span> and <span class="math inline">\sigma_t</span>, rather than fixed <span class="math inline">\eta</span> and <span class="math inline">\sigma</span>. The coverage error then has the following bound (<span class="citation" data-cites="gibbs2022faci">Gibbs and Candès (<a href="#ref-gibbs2022faci" role="doc-biblioref">2022</a>)</span>; Theorem 3.2), where <span class="math inline">\gamma_{\min}</span> and <span class="math inline">\gamma_{\max}</span> are the smallest and largest learning rates in the grid, respectively: <span class="math display">
|\mathrm{CovErr}(T)| \leq \frac{1 + 2\gamma_{\max}}{T \gamma_{\min}} + \frac{(1 + 2\gamma_{\max})^2}{\gamma_{\min}}  \frac{1}{T}\sum_{t=1}^T \eta_t \exp(\eta_t(1 + 2\gamma_{\max})) + 2 \frac{1+\gamma_{\max}}{\gamma_{\min}} \frac{1}{T} \sum_{t=1}^T \sigma_t.
</span> Thus, if <span class="math inline">\eta_t</span> and <span class="math inline">\sigma_t</span> both converge to zero as <span class="math inline">t \to \infty</span>, then the coverage error will also converge to zero. In addition, under mild distributional assumptions the authors provide a type of short-term coverage error bound for arbitrary time spans, for which we refer to <span class="citation" data-cites="gibbs2022faci">(<a href="#ref-gibbs2022faci" role="doc-biblioref">Gibbs and Candès 2022</a>)</span>.</p>
<p>We note one additional result established by <span class="citation" data-cites="gibbs2022faci">Gibbs and Candès (<a href="#ref-gibbs2022faci" role="doc-biblioref">2022</a>)</span> (their Theorem 3.1) on a slightly different dynamic regret bound in terms of the pinball loss, as it informs the choice of tuning parameters. Let <span class="math inline">\gamma_{\mathrm{max}} = \max_{1 \leq k \leq K} \gamma_k</span> be the largest learning rate in the grid and assume that <span class="math inline">\gamma_1 &lt; \gamma_2 &lt; \cdots &lt; \gamma_K</span> with <span class="math inline">\gamma_{k+1}/\gamma \leq 2</span> for all <span class="math inline">1 \leq k &lt; K</span>. Then, for any interval <span class="math inline">I = [r, s] \subseteq \llbracket T \rrbracket</span> and any sequence <span class="math inline">\theta_r^*, \dots, \theta_s^*</span>, under the assumption that <span class="math inline">\gamma_k \geq \sqrt{1 + 1 / |I|}</span>, <span class="math display">
\begin{aligned}
  \frac{1}{|I|} \sum_{t=r}^s \mathbb{E}[L^\alpha(\theta_t, r_t)] - \frac{1}{|I|} \sum_{t=r}^s L^\alpha(\theta_t, \theta_t^*) \leq&amp; \frac{\log(k / \sigma) + 2\sigma|I|}{\eta |I|} + \frac{\eta}{|I|} \sum_{t=r}^s \mathbb{E}[L^\alpha(\theta_t, r_t)^2] \\
  &amp;+ 2\sqrt{3}(1 + \gamma_{\mathrm{max}})^2 \max\left\{ \sqrt{\frac{\sum_{t=r+1}^s |\theta_t^* - \theta_{t-1}^*| + 1}{|I|}}, \gamma_1 \right\},
\end{aligned}
</span> where the expectation is over the randomness in the randomized version of the algorithm. Here the time interval <span class="math inline">I</span> (with length <span class="math inline">|I|</span>) is comparable to the time period length <span class="math inline">m</span> for the strongly adaptive regret. The parameter <span class="math inline">|I|</span>, the time interval of interest for which we would like to control, can be chosen arbitrarily. This dynamic regret bound can be converted to a strongly adaptive regret bound by choosing <span class="math inline">\theta^*_t</span> to be constant.</p>
</section>
<section id="tuning-parameters-1" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="tuning-parameters-1"><span class="header-section-number">3.3.2</span> Tuning parameters</h3>
<p>The recommended settings for the tuning parameters depend on choosing a time interval length <span class="math inline">|I|</span> for which we would like to control the pinball loss. The choice of <span class="math inline">|I|</span> can be chosen arbitrarily. For the tuning parameter <span class="math inline">\sigma</span>, the authors suggest the optimal choice (with respect to the dynamic regret) <span class="math inline">\sigma = 1 / (2 |I|)</span>. Choosing <span class="math inline">\eta</span> is more difficult. The authors suggest the following choice for <span class="math inline">\eta</span>, which they show is optimal if there is in fact no distribution shift: <span class="math display">
\begin{aligned}
  \eta = \sqrt{\frac{3}{|I|}} \sqrt{\frac{\log(K \cdot |I|) + 2}{(\alpha)^2 (1 - \alpha)^3 + (1-\alpha)^2 \alpha^3 }}
\end{aligned}.
</span> Note that this choice is optimal only for the quantile interval constructor, for which <span class="math inline">\theta_t</span> is a quantile of previous nonconformity scores. As an alternative, the authors point out that <span class="math inline">\eta</span> can be learned in an online fashion using the update rule <span class="math display">
\begin{aligned}
  \eta_t := \sqrt{\frac{\log(|I| K) + 2}{\sum_{s=t-|I|}^{t-1} L^\alpha(\theta_s, r_s)}}.
\end{aligned}
</span> Both ways of choosing <span class="math inline">\eta</span> led to very similar results in the original author’s empirical studies. In our proposed <code>AdaptiveConformal</code> package, the first approach is used when the quantile interval construction function is chosen, and the latter approach for the linear interval construction function.</p>
<p><a href="#fig-dtaci-example" class="quarto-xref">Figure&nbsp;3</a> illustrates DtACI with the quantile interval construction function and with the learning rate grid <span class="math inline">\gamma \in \{ 0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128 \}</span>. The tuning parameter <span class="math inline">\eta</span> was set to <span class="math inline">0.001</span>, <span class="math inline">1</span>, and <span class="math inline">100</span> to show how the algorithm responds to extreme choices of the parameter, and to <span class="math inline">\eta \approx 3.19</span> according to the optimal choice recommendation with <span class="math inline">I = 100</span> as described in the previous section. The results show that, in this simple example, high values of <span class="math inline">\eta</span> may lead to intervals that are too reactive to the data, as seen in the longer path length. The algorithm appears more robust, however, to small choices of <span class="math inline">\eta</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dtaci-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dtaci-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-dtaci-example-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dtaci-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Example 80% prediction intervals generated by the DtACI algorithm with starting values <span class="math inline">\theta_1 = 0.8</span> and with several values of the tuning parameter <span class="math inline">\eta</span>. Blue and red points are observations that fell inside and outside the prediction intervals, respectively.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="scale-free-online-gradient-descent-sf-ogd" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="scale-free-online-gradient-descent-sf-ogd"><span class="header-section-number">3.4</span> Scale-Free Online Gradient Descent (SF-OGD)</h2>
<div id="algo-sfogd" class="pseudocode-container quarto-float" data-comment-delimiter="//" data-caption-prefix="Algorithm" data-line-number="true" data-indent-size="1.2em" data-no-end="false" data-pseudocode-number="4" data-line-number-punc=":">
<div class="pseudocode">
\begin{algorithm} \caption{Scale-Free Online Gradient Descent} \begin{algorithmic} \State \textbf{Input:} starting value $\theta_1$, learning rate $\gamma &gt; 0$. \For{$t = 1, 2, \dots, T$} \State \textbf{Output:} prediction interval $\widehat{C}_t(\theta_t)$. \State Observe $y_t$ and compute $r_t$. \State Update $\theta_{t+1} = \theta_t - \gamma \frac{\nabla L^\alpha(\theta_t, r_t)}{\sqrt{\sum_{i=1}^t} \| \nabla L^\alpha(\theta_i, r_i) \|_2^2}$. \EndFor \end{algorithmic} \end{algorithm}
</div>
</div>
<p>Scale-Free Online Gradient Descent (SF-OGD; <a href="#algo-sfogd" class="quarto-xref">Algorithm 4</a>) is a general algorithm for online learning proposed by <span class="citation" data-cites="orabona2018sfogd">Orabona and Pál (<a href="#ref-orabona2018sfogd" role="doc-biblioref">2018</a>)</span>. The algorithm updates <span class="math inline">\theta_t</span> with a gradient descent step where the learning rate adapts to the scale of the previously observed gradients. SF-OGD was first used in the context of ACI as a sub-algorithm for SAOCP (described in the next section). However, it was found to have good performance by itself <span class="citation" data-cites="bhatnagar2023saocp">(<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span> in real-world tasks, so we have made it available in the package as a stand-alone algorithm.</p>
<section id="theoretical-guarantees-2" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="theoretical-guarantees-2"><span class="header-section-number">3.4.1</span> Theoretical Guarantees</h3>
<p>The SF-OGD algorithm with linear interval constructor has the following regret bound, which is called an <em>anytime regret bound</em> because it holds for all <span class="math inline">t \in \llbracket T \rrbracket</span> <span class="citation" data-cites="bhatnagar2023saocp">(<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span>. For any <span class="math inline">\gamma &gt; 0</span>, <span class="math display">
\begin{aligned}
  \mathrm{Reg}(t) \leq \mathcal{O}(D \sqrt{t}) \text{ for all } t \in \llbracket T \rrbracket.
\end{aligned}
</span> A bound for the coverage error has also been established (<span class="citation" data-cites="bhatnagar2023saocp">Bhatnagar et al. (<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">2023</a>)</span>; Theorem 4.2). For any learning rate <span class="math inline">\gamma = \Theta(D)</span> (where <span class="math inline">\gamma = D / \sqrt{3}</span> is optimal) and any starting value <span class="math inline">\theta_1 \in [0, D]</span>, then it holds that for any <span class="math inline">T &gt; 1</span>, <span class="math display">
\begin{aligned}
  |\mathrm{CovErr}(T)| \leq \mathcal{O}\left( (1 - \alpha)^{-2} T^{-1/4} \log T \right).
\end{aligned}
</span></p>
</section>
<section id="tuning-parameters-2" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="tuning-parameters-2"><span class="header-section-number">3.4.2</span> Tuning parameters</h3>
<p><a href="#fig-sf-ogd" class="quarto-xref">Figure&nbsp;4</a> compares results for several choices of <span class="math inline">\gamma</span> to illustrate its effect. The optimal choice of learning rate is <span class="math inline">\gamma = D / \sqrt{3}</span>, where <span class="math inline">D</span> is the maximum possible radius. When <span class="math inline">D</span> is not known, it can be estimated by using an initial subset of the time series as a calibration set and estimating <span class="math inline">D</span> as the maximum of the absolute residuals of the observations and the predictions <span class="citation" data-cites="bhatnagar2023saocp">(<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span>. <a href="#fig-sf-ogd" class="quarto-xref">Figure&nbsp;4</a> illustrates SF-OGD for several values of <span class="math inline">\gamma</span>. In the example, the prediction intervals are not reactive enough and do not achieve optimal coverage when <span class="math inline">\gamma</span> is small. As <span class="math inline">\gamma</span> increases, the coverage error is near optimal, although the path length becomes larger.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-sf-ogd" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sf-ogd-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-sf-ogd-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sf-ogd-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Example 80% prediction intervals generated by the SF-OGD algorithm with different values of the maximum radius tuning parameter <span class="math inline">D</span>. Blue and red points are observations that fell inside and outside the prediction intervals, respectively.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="strongly-adaptive-online-conformal-prediction-saocp" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="strongly-adaptive-online-conformal-prediction-saocp"><span class="header-section-number">3.5</span> Strongly Adaptive Online Conformal Prediction (SAOCP)</h2>
<div id="algo-saocp" class="pseudocode-container quarto-float" data-comment-delimiter="//" data-caption-prefix="Algorithm" data-line-number="true" data-indent-size="1.2em" data-no-end="false" data-pseudocode-number="5" data-line-number-punc=":">
<div class="pseudocode">
\begin{algorithm} \caption{Strongly Adaptive Online Conformal Prediction} \begin{algorithmic} \State \textbf{Input:} initial value $\theta_0$, learning rate $\gamma &gt; 0$. \For{$t = 1, 2, \dots, T$} \State Initialize expert $\mathcal{A}_t = \texttt{SF-OGD}(\alpha \leftarrow \alpha, \gamma \leftarrow \gamma, \theta_1 \leftarrow \theta_{t-1})$, set weight $p_t^t = 0$. \State Compute active set $\mathrm{Active}(t) = \{ i \in \llbracket T \rrbracket : t - L(i) &lt; i \leq t \}$ (see below for definition of $L(t)$). \State Compute prior probability $\pi_i \propto i^{-2} (1 + \lfloor \log_2 i \rfloor )^{-1} \mathbb{I}[i \in \mathrm{Active}(t)]$. \State Compute un-normalized probability $\hat{p}_i = \pi_i [p_{t,i}]_+$ for all $i \in \llbracket t \rrbracket$. \State Normalize $p = \hat{p} / \| \hat{p} \|_1 \in \Delta^t$ if $\| \hat{p} \|_1 &gt; 0$, else $p = \pi$. \State Set $\theta_t = \sum_{i \in \mathrm{Active}(t)} p_i \theta_t^i$ (for $t \geq 2$), and $\theta_t = 0$ for $t = 1$. \State \textbf{Output:} prediction set $\widehat{C}_t(\theta_t)$. \State Observe $y_t$ and compute $r_t$. \For{$i \in \mathrm{Active}(t)$} \State Update expert $\mathcal{A}_t$ with $y_t$ and obtain $\theta_{t+1}^i$. \State Compute $g_t^i = \begin{cases} \frac{1}{D}\left(L^\alpha(\theta_t, r_t) - L^\alpha(\theta_t^i, r_t)\right) &amp; p_t^i &gt; 0 \\ \frac{1}{D}\left[L^\alpha(\theta_t, r_t) - L^\alpha(\theta_t^i, r_t))\right]_+ &amp; p_t^i \leq 0 \\ \end{cases}$. \State Update expert weight $p_{t+1}^i = \frac{1}{t - i + 1}\left( \sum_{j=i}^t g_j^i \right) \left(1 + \sum_{j=i}^t p_j^i g_j^i \right)$. \EndFor \EndFor \end{algorithmic} \end{algorithm}
</div>
</div>
<p>The Strongly Adaptive Online Conformal Prediction (SAOCP; <a href="#algo-saocp" class="quarto-xref">Algorithm 5</a>) algorithm was proposed as an improvement over the extant ACI algorithms in that it features stronger theoretical guarantees. SAOCP works similarly to AgACI and DtACI in that it maintains a library of candidate online learning algorithms that generate prediction intervals which are then aggregated using a meta-algorithm <span class="citation" data-cites="bhatnagar2023saocp">(<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">Bhatnagar et al. 2023</a>)</span>. The candidate algorithm was chosen to be SF-OGD, although any algorithm that features anytime regret guarantees can be chosen. As opposed to AgACI and DtACI, in which each candidate has a different learning rate but is always able to contribute to the final prediction intervals, here each candidate has the same learning rate but only has positive weight over a specific interval of time. New candidate algorithms are continually being spawned in order that, if the distribution shifts rapidly, the newer candidates will be able to react quickly and receive positive weight. Specifically, at each time point, a new expert is instantiated which is active over a finite ``lifetime”. Define the <em>lifetime</em> of an expert instantiated at time <span class="math inline">t</span> as <span class="math display">
\begin{aligned}
  L(t) := g \cdot \max_{n \in \mathbb{Z}} \{ 2^n t \equiv 0 \mod 2^n \},
\end{aligned}
</span> where <span class="math inline">g \in \mathbb{Z}^*</span> is a <em>lifetime multiplier</em> parameter. The active experts are weighted according to their empirical performance with respect to the pinball loss function. The authors show that this construction results in intervals that have strong regret guarantees. The form of the lifetime interval function <span class="math inline">L(t)</span> is due to the use of geometric covering intervals to partition the input time series, and other choices may be possible <span class="citation" data-cites="jun2017coinbetting">(<a href="#ref-jun2017coinbetting" role="doc-biblioref">Jun et al. 2017</a>)</span>.</p>
<section id="theoretical-guarantees-3" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="theoretical-guarantees-3"><span class="header-section-number">3.5.1</span> Theoretical Guarantees</h3>
<p>The theoretical results were established for SAOCP using the linear interval constructor. The following bound for the strongly adaptive regret holds for all subperiod lengths <span class="math inline">m \in \llbracket T \rrbracket</span> (<span class="citation" data-cites="bhatnagar2023saocp">Bhatnagar et al. (<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">2023</a>)</span>; Proposition 4.1): <span class="math display">
\begin{aligned}
  \mathrm{SAReg}(T, m) \leq 15 D \sqrt{m(\log T + 1)} \leq \tilde{\mathcal{O}}(D \sqrt m).
\end{aligned}
</span> It should be emphasized that this regret bounds holds simultaneously across all <span class="math inline">m</span>, as opposed to DtACI, where a similar bound holds only for a single <span class="math inline">m</span>. A bound on the coverage error of SAOCP has also been established as: <span class="math display">
\begin{aligned}
  |\mathrm{CovErr}(T)| \leq \mathcal{O}\left(\inf_\beta(T^{1/2 - \beta} + T^{\beta - 1} S_\beta(T))\right).
\end{aligned}
</span> where <span class="math inline">S_{\beta}(T)</span> is a technical measure of the smoothness of the cumulative gradients and expert weights for each of the candidate experts (<span class="citation" data-cites="bhatnagar2023saocp">Bhatnagar et al. (<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">2023</a>)</span>; Theorem 4.3). For some intuition, <span class="math inline">S_{\beta}</span> can be expected to be small when the weights placed on each algorithm do change quickly, as would be the case under abrupt distributional shifts.</p>
</section>
<section id="tuning-parameters-3" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2" class="anchored" data-anchor-id="tuning-parameters-3"><span class="header-section-number">3.5.2</span> Tuning Parameters</h3>
<p>The primary tuning parameter for SAOCP is the learning rate <span class="math inline">\gamma</span> of the SF-OGD sub-algorithms, which we saw in the previous section has for optimal choice <span class="math inline">\gamma = D / \sqrt{3}</span>. Values for <span class="math inline">D</span> that are too low lead to intervals that adapt slowly, and values that are too large lead to jagged intervals. In their experiments, the authors select a value for <span class="math inline">D</span> by picking the maximum residual from a calibration set. The second tuning parameter is the lifetime multiplier <span class="math inline">g</span> which controls the lifetime of each of the experts. We follow the original paper in setting <span class="math inline">g = 8</span>. <a href="#fig-saocp" class="quarto-xref">Figure&nbsp;5</a> illustrates the SAOCP algorithm for choices of <span class="math inline">D \in \{0.01, 0.1, 0.25, 0.5 \}</span>. Similarly to SF-OGD, the prediction intervals tend to undercover for small <span class="math inline">D</span>, and achieve near-optimal coverage for larger <span class="math inline">D</span> at the expense of larger path lengths.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-saocp" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-saocp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-saocp-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-saocp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Example 80% prediction intervals generated by the SAOCP algorithm with different values of the maximum radius parameter <span class="math inline">D</span>. Blue and red points are observations that fell inside and outside the prediction intervals, respectively.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="adaptiveconformal-r-package" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> <code>AdaptiveConformal</code> <code>R</code> package</h1>
<p>The ACI algorithms described in the previous section have been implemented in the open-source and publically available <code>R</code> package <code>AdaptiveConformal</code>, available at <a href="https://github.com/herbps10/AdaptiveConformal">https://github.com/herbps10/AdaptiveConformal</a>. CIn this section, we briefly introduce the main functionality of the package. Comprehensive documentation is, including several example vignettes, is included with the package.</p>
<p>The <code>AdaptiveConformal</code> package can be installed using the <code>remotes</code> package:</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>remotes<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">"herbps10/AdaptiveConformal"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The ACI algorithms are accessed through the <code>aci</code> function, which takes as input a vector of observations (<span class="math inline">y_t</span>) and a vector or matrix of predictions (<span class="math inline">\hat{y}_t</span>). Using the data generating process from the running example to illustrate, we can fit the original ACI algorithm with learning rate <span class="math inline">\gamma = 0.1</span>:</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">532</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">running_example_data</span>(<span class="at">N =</span> <span class="fl">5e2</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">aci</span>(data<span class="sc">$</span>y, data<span class="sc">$</span>yhat, <span class="at">alpha =</span> <span class="fl">0.8</span>, <span class="at">method =</span> <span class="st">"ACI"</span>, <span class="at">parameters =</span> <span class="fu">list</span>(<span class="at">gamma =</span> <span class="fl">0.1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The available parameters for each method can be found in the documentation for the <code>aci</code> method, accessible with the command <code>?aci</code>. The resulting conformal prediction intervals can then be plotted using the <code>plot</code> function:</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="published-202407-susmann-adaptive-conformal_files/figure-html/unnamed-chunk-4-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The properties of the prediction intervals can also be examined using the <code>summary</code> function:</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Method: ACI
Empirical coverage: 80.6% (403/500)
Below interval: 10.2%
Above interval: 9.2%
Mean interval width: 0.354
Mean interval loss: 0.498</code></pre>
</div>
</div>
</section>
<section id="sec-simulations" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Simulation Studies</h1>
<p>We present two empirical studies in order to compare the performance of the AgACI, DtACI, SF-OGD, and SAOCP algorithms applied to simple simulated datasets. The original ACI algorithm was not included as it is not clear how to set the tuning rate <span class="math inline">\gamma</span>, which can have a large effect on the resulting intervals. For both simulations we set the targeted empirical coverage to <span class="math inline">\alpha = 0.8</span>, <span class="math inline">\alpha = 0.9</span>, and <span class="math inline">\alpha = 0.95</span>. For each algorithm, we chose the interval constructor that was used in its original presentation (see <a href="#tbl-aci" class="quarto-xref">Table&nbsp;1</a>).</p>
<section id="time-series-with-arma-errors" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="time-series-with-arma-errors"><span class="header-section-number">5.1</span> Time series with ARMA errors</h2>
<p>In this simulation we reproduce the setup described in <span class="citation" data-cites="zaffran2022agaci">Zaffran et al. (<a href="#ref-zaffran2022agaci" role="doc-biblioref">2022</a>)</span> (itself based on that of <span class="citation" data-cites="friedman1983">Friedman, Grosse, and Stuetzle (<a href="#ref-friedman1983" role="doc-biblioref">1983</a>)</span>). The time series values <span class="math inline">y_t</span> for <span class="math inline">t \in \llbracket T \rrbracket</span> (<span class="math inline">T = 600</span>) are simulated according to <span class="math display">
\begin{aligned}
  y_t = 10\sin(\pi X_{t,1}X_{t,2}) + 20(X_{t,3} - 0.5)^2 + 10X_{t,4} + 5 X_{t,5} + 0X_{t,6} + \epsilon_t,
\end{aligned}
</span> where <span class="math inline">X_{t,i}</span>, <span class="math inline">i = 1, \dots, 6</span>, <span class="math inline">t \in \llbracket T \rrbracket</span> are independently uniformly distributed on <span class="math inline">[0, 1]</span> and the noise terms <span class="math inline">\epsilon_t</span> are generated according to an ARMA(1, 1) process: <span class="math display">
\begin{aligned}
  \epsilon_t &amp;= \psi \epsilon_{t-1} + \xi_t + \theta \xi_{t-1}, \\
  \xi_t &amp;\sim N(0, \sigma^2).
\end{aligned}
</span> We set <span class="math inline">\psi</span> and <span class="math inline">\theta</span> jointly to each value in <span class="math inline">\{ 0.1, 0.8, 0.9, 0.95, 0.99 \}</span> to simulate time series with increasing temporal dependence. The innovation variance was set to <span class="math inline">\sigma^2 = (1 - \psi^2) / (1 + 2\psi \xi + \xi^2)</span> (to ensure that the process has constant variance). For each setting, 25 simulated datasets were generated.</p>
<p>To provide point predictions for the ACI algorithms, at each time <span class="math inline">t \geq 200</span> a random forest model was fitted to the previously observed data using the <code>ranger</code> <code>R</code> package <span class="citation" data-cites="wright2017ranger">(<a href="#ref-wright2017ranger" role="doc-biblioref">Wright and Ziegler 2017</a>)</span>. The estimated model was then used to predict the subsequent time point. The maximum radius <span class="math inline">D</span> was estimated as the maximum residual observed between time points <span class="math inline">t=200</span> and <span class="math inline">t=249</span>. The ACI models were then executed starting at time point <span class="math inline">t = 250</span>. All metrics are based on time points <span class="math inline">t \geq 300</span> to allow time for the ACI methods to initialize.</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>simulate <span class="ot">&lt;-</span> <span class="cf">function</span>(seed, psi, xi, <span class="at">N =</span> <span class="fl">1e3</span>) {</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(seed)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  s <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  innov_scale <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(s <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> psi<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> psi <span class="sc">*</span> xi <span class="sc">+</span> xi<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">6</span> <span class="sc">*</span> N), <span class="at">ncol =</span> <span class="dv">6</span>, <span class="at">nrow =</span> N)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(X) <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"X"</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  epsilon <span class="ot">&lt;-</span> <span class="fu">arima.sim</span>(<span class="at">n =</span> N, <span class="at">model =</span> <span class="fu">list</span>(<span class="at">ar =</span> psi, <span class="at">ma =</span> xi), <span class="at">sd =</span> innov_scale)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="sc">*</span> <span class="fu">sin</span>(pi <span class="sc">*</span> X[,<span class="dv">1</span>] <span class="sc">*</span> X[,<span class="dv">2</span>]) <span class="sc">+</span> <span class="dv">20</span> <span class="sc">*</span> (X[,<span class="dv">3</span>] <span class="sc">-</span> <span class="fl">0.5</span>)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">10</span> <span class="sc">*</span> X[,<span class="dv">4</span>] <span class="sc">+</span> <span class="dv">5</span> <span class="sc">*</span> X[,<span class="dv">5</span>]</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> mu <span class="sc">+</span> epsilon</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>(X) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">y =</span> y)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>estimate_model <span class="ot">&lt;-</span> <span class="cf">function</span>(data, <span class="at">p =</span> <span class="cn">NULL</span>) {</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span><span class="fu">is.null</span>(p)) <span class="fu">p</span>()</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>  preds <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="fu">nrow</span>(data))</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(t <span class="cf">in</span> <span class="dv">200</span><span class="sc">:</span><span class="fu">nrow</span>(data)) {</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    model <span class="ot">&lt;-</span> ranger<span class="sc">::</span><span class="fu">ranger</span>(y <span class="sc">~</span> X1 <span class="sc">+</span> X2 <span class="sc">+</span> X3 <span class="sc">+</span> X4 <span class="sc">+</span> X5 <span class="sc">+</span> X6, <span class="at">data =</span> data[<span class="dv">1</span><span class="sc">:</span>(t <span class="sc">-</span> <span class="dv">1</span>),])</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    preds[t] <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="at">data =</span> data[t, ])<span class="sc">$</span>predictions</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>  preds</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>metrics <span class="ot">&lt;-</span> <span class="cf">function</span>(fit) {</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">&lt;-</span> <span class="dv">300</span><span class="sc">:</span><span class="fu">length</span>(fit<span class="sc">$</span>Y)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aci_metrics</span>(fit, indices)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="cf">function</span>(data, preds, method, alpha, <span class="at">p =</span> <span class="cn">NULL</span>) {</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span><span class="fu">is.null</span>(p)) <span class="fu">p</span>()</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>  D <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="fu">abs</span>(data<span class="sc">$</span>y <span class="sc">-</span> preds)[<span class="dv">200</span><span class="sc">:</span><span class="dv">249</span>])</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>  gamma <span class="ot">&lt;-</span> D <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">3</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>  interval_constructor <span class="ot">=</span> <span class="fu">case_when</span>(</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"AgACI"</span> <span class="sc">~</span> <span class="st">"conformal"</span>,</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"DtACI"</span> <span class="sc">~</span> <span class="st">"conformal"</span>,</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"SF-OGD"</span> <span class="sc">~</span> <span class="st">"linear"</span>,</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"SAOCP"</span> <span class="sc">~</span> <span class="st">"linear"</span></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(interval_constructor <span class="sc">==</span> <span class="st">"linear"</span>) {</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>    gamma_grid <span class="ot">=</span> <span class="fu">seq</span>(<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="fl">0.1</span>)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span> {</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>    gamma_grid <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.002</span>, <span class="fl">0.004</span>, <span class="fl">0.008</span>, <span class="fl">0.016</span>, <span class="fl">0.032</span>, <span class="fl">0.064</span>, <span class="fl">0.128</span>)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>  parameters <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>    <span class="at">interval_constructor =</span> interval_constructor,</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>    <span class="at">D =</span> D,</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma =</span> gamma,</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma_grid =</span> gamma_grid</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aci</span>(</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>y[<span class="dv">250</span><span class="sc">:</span><span class="fu">nrow</span>(data)],</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>    preds[<span class="dv">250</span><span class="sc">:</span><span class="fu">nrow</span>(data)],</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> method,</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> alpha,</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>    <span class="at">parameters =</span> parameters</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>N_sims <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>simulation_data <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>  <span class="at">index =</span> <span class="dv">1</span><span class="sc">:</span>N_sims,</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>  <span class="at">param =</span>  <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>),</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="dv">600</span></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">psi =</span> param, <span class="at">xi =</span> param)</span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a><span class="co"># For each simulated dataset, fit multiple ACI methods</span></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>simulation_study_setup <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>),</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="fu">c</span>(<span class="st">"AgACI"</span>, <span class="st">"SF-OGD"</span>, <span class="st">"SAOCP"</span>, <span class="st">"DtACI"</span>)</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a><span class="co"># run_simulation_study1 function is defined in helpers.R</span></span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>simulation_study1 <span class="ot">&lt;-</span> <span class="fu">run_simulation_study1</span>(</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>  simulation_data,</span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>  simulation_study_setup,</span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>  estimate_model,</span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>  fit,</span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>  <span class="at">workers =</span> <span class="dv">8</span></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The coverage errors, mean interval widths, path lengths, and strongly adaptive regret (for <span class="math inline">m = 20</span>) of each of the algorithms for <span class="math inline">\alpha = 0.9</span> are shown in <a href="#fig-simulation-one-results" class="quarto-xref">Figure&nbsp;6</a> (results for <span class="math inline">\alpha \in \{ 0.8, 0.95 \}</span> were similar and are available in the appendix). All methods achieved near optimal empirical coverage, although SAOCP tended to slightly undercover. The mean interval widths re similar across methods, although again SAOCP had slightly shorter intervals (as could be expected given its tendency to undercover). The strongly adaptive regret was similar for all methods. The path length of SAOCP was larger than any of the other methods. To investigate why, <a href="#fig-simulation-one-widths" class="quarto-xref">Figure&nbsp;7</a> plots <span class="math inline">w_t - w_{t-1}</span>, the difference in interval width between times <span class="math inline">t-1</span> and <span class="math inline">t</span>, for each method in one of the simulations. The interval widths for AgACI and DtACI change slowly relative to those for SF-OGD and SAOCP. For SAOCP, we can see the interval widths have larger fluctuations than for the other methods, explaining its higher path width. The prediction intervals themselves for the same simulation are shown in <a href="#fig-simulation-one-example" class="quarto-xref">Figure&nbsp;8</a>, which shows that although the path lengths are quite different, the output prediction intervals are quite similar.</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">simulation_one_plot</span>(simulation_study1<span class="sc">$</span>results <span class="sc">%&gt;%</span> <span class="fu">filter</span>(alpha <span class="sc">==</span> <span class="fl">0.9</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-simulation-one-results" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-simulation-one-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-simulation-one-results-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simulation-one-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Coverage errors, mean interval widths, path lengths, and strongly adaptive regret (for <span class="math inline">m = 20</span>) for the first simulation study with target coverage <span class="math inline">\alpha = 0.9</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> simulation_study1<span class="sc">$</span>example_fits</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">diff</span>(fits<span class="sc">$</span>fit[[i]]<span class="sc">$</span>intervals[,<span class="dv">2</span>] <span class="sc">-</span> fits<span class="sc">$</span>fit[[i]]<span class="sc">$</span>intervals[,<span class="dv">1</span>]),</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">main =</span> fits<span class="sc">$</span>method[[i]],</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">"T"</span>,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="fu">expression</span>(w[t] <span class="sc">-</span> w[t <span class="sc">-</span> <span class="dv">1</span>]))</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">4.1</span>, <span class="fl">4.1</span>, <span class="fl">2.1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-simulation-one-widths" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-simulation-one-widths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-simulation-one-widths-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simulation-one-widths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Difference in successive interval widths (<span class="math inline">w_t - w_{t-1}</span>) from an illustrative simulation from the first simulation study.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> simulation_study1<span class="sc">$</span>example_fits</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>coverage    <span class="ot">&lt;-</span> <span class="fu">format_coverage</span>(<span class="fu">map_dbl</span>(<span class="fu">map</span>(fits<span class="sc">$</span>fit, metrics), <span class="st">`</span><span class="at">[[</span><span class="st">`</span>, <span class="st">"coverage"</span>))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>path_length <span class="ot">&lt;-</span> <span class="fu">format_path_length</span>(<span class="fu">map_dbl</span>(<span class="fu">map</span>(fits<span class="sc">$</span>fit, metrics), <span class="st">`</span><span class="at">[[</span><span class="st">`</span>, <span class="st">"path_length"</span>))</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>))</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(fits<span class="sc">$</span>fit[[i]], <span class="at">legend =</span> <span class="cn">FALSE</span>, <span class="at">main =</span> fits<span class="sc">$</span>method[[i]], <span class="at">predictions =</span> <span class="cn">FALSE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">20</span>, <span class="dv">35</span>), <span class="at">index =</span> <span class="dv">50</span><span class="sc">:</span><span class="dv">100</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">text</span>(<span class="at">x =</span> <span class="sc">-</span><span class="dv">0</span>, <span class="at">y =</span> <span class="sc">-</span><span class="fl">7.5</span>, <span class="at">labels =</span> <span class="fu">bquote</span>(EmpCov <span class="sc">==</span> .(coverage[[i]]) ), <span class="at">pos =</span> <span class="dv">4</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">text</span>(<span class="at">x =</span> <span class="sc">-</span><span class="dv">0</span>, <span class="at">y =</span> <span class="sc">-</span><span class="fl">17.5</span>, <span class="at">labels =</span> <span class="fu">bquote</span>(PathLength <span class="sc">==</span> .(path_length[[i]]) ), <span class="at">pos =</span> <span class="dv">4</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">4.1</span>, <span class="fl">4.1</span>, <span class="fl">2.1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-simulation-one-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-simulation-one-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-simulation-one-example-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simulation-one-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Example prediction intervals (target coverage <span class="math inline">\alpha = 0.9</span>) from the first simulation study for time points 300 to 350; metrics shown are for all time points <span class="math inline">t \geq 300</span>. Blue and red points are observations that fell inside and outside the prediction intervals, respectively.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="distribution-shift" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="distribution-shift"><span class="header-section-number">5.2</span> Distribution shift</h2>
<p>This simulation study features time series with distribution shifts. The setup is quite simple in order to probe the basic performance of the methods in response to distribution shift. As a baseline, we simulate time series of independent data with <span class="math display">
\begin{aligned}
  y_t &amp;\sim N(0, \sigma_t^2), \\
  \sigma_t &amp;= 0.2,
\end{aligned}
</span> for all <span class="math inline">t \in \llbracket T \rrbracket</span> (<span class="math inline">T = 500</span>). In the second type of time series, the observations are still independent but their variance increases halfway through the time series: <span class="math display">
\begin{aligned}
y_t &amp;\sim N(0, \sigma_t^2), \\
\sigma_t &amp;= 0.2 + 0.5 \mathbb{I}[t &gt; 250].
\end{aligned}
</span> In each case, the ACI algorithms are provided with the unbiased predictions <span class="math inline">\hat{\mu}_t = 0</span>, <span class="math inline">t \in \llbracket T \rrbracket</span>. Fifty simulated datasets were generated for each type of time series.</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>simulate <span class="ot">&lt;-</span> <span class="cf">function</span>(seed, <span class="at">distribution_shift =</span> <span class="dv">0</span>, <span class="at">N =</span> <span class="fl">1e3</span>, <span class="at">sigma =</span> <span class="fl">0.2</span>) {</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(seed)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, N)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  shift <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>N <span class="sc">&gt;</span> (N <span class="sc">/</span> <span class="dv">2</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  yhat <span class="ot">&lt;-</span> mu</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="fu">length</span>(mu), <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma <span class="sc">+</span> <span class="fu">ifelse</span>(shift, distribution_shift, <span class="dv">0</span>))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">y =</span> y, <span class="at">yhat =</span> yhat)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>metrics <span class="ot">&lt;-</span> <span class="cf">function</span>(fit) {</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  N <span class="ot">&lt;-</span> <span class="fu">length</span>(fit<span class="sc">$</span>Y)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="dv">1</span><span class="sc">:</span>N <span class="sc">&gt;</span> <span class="dv">50</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aci_metrics</span>(fit, indices)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="cf">function</span>(data, method, alpha, <span class="at">p =</span> <span class="cn">NULL</span>) {</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span><span class="fu">is.null</span>(p)) <span class="fu">p</span>()</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>  interval_constructor <span class="ot">=</span> <span class="fu">case_when</span>(</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"AgACI"</span> <span class="sc">~</span> <span class="st">"conformal"</span>,</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"DtACI"</span> <span class="sc">~</span> <span class="st">"conformal"</span>,</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"SF-OGD"</span> <span class="sc">~</span> <span class="st">"linear"</span>,</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"SAOCP"</span> <span class="sc">~</span> <span class="st">"linear"</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(interval_constructor <span class="sc">==</span> <span class="st">"linear"</span>) {</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    D <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="fu">abs</span>(data<span class="sc">$</span>y <span class="sc">-</span> data<span class="sc">$</span>yhat)[<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>])</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span> {</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>    D <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>  gamma <span class="ot">&lt;-</span> D <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">3</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(interval_constructor <span class="sc">==</span> <span class="st">"linear"</span>) {</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    gamma_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.1</span>, <span class="dv">2</span>, <span class="fl">0.1</span>)</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span> {</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>    gamma_grid <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.002</span>, <span class="fl">0.004</span>, <span class="fl">0.008</span>, <span class="fl">0.016</span>, <span class="fl">0.032</span>, <span class="fl">0.064</span>, <span class="fl">0.128</span>)</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>  parameters <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">interval_constructor =</span> interval_constructor,</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>    <span class="at">D =</span> D,</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma =</span> gamma,</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma_grid =</span> gamma_grid</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aci</span>(data<span class="sc">$</span>y, data<span class="sc">$</span>yhat, <span class="at">method =</span> method, <span class="at">alpha =</span> alpha, <span class="at">parameters =</span> parameters)</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>N_sims <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>simulation_study_setup2 <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>  <span class="at">index =</span> <span class="dv">1</span><span class="sc">:</span>N_sims,</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>  <span class="at">distribution_shift =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>),</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>),</span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="dv">500</span>,</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="fu">c</span>(<span class="st">"AgACI"</span>, <span class="st">"SF-OGD"</span>, <span class="st">"SAOCP"</span>, <span class="st">"DtACI"</span>),</span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">data =</span> <span class="fu">pmap</span>(<span class="fu">list</span>(index, distribution_shift, N), simulate))</span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a><span class="co"># run_simulation_study2 function is defined in helpers.R</span></span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a>simulation_study2 <span class="ot">&lt;-</span> <span class="fu">run_simulation_study2</span>(simulation_study_setup2, fit, <span class="at">workers =</span> <span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The coverage error, mean path length, mean interval widths, and strongly adaptive regret (for <span class="math inline">m = 20</span>) of the algorithms are summarized in <a href="#fig-simulation-two-results" class="quarto-xref">Figure&nbsp;9</a> (an alternative plot is included in the appendix as <a href="#fig-simulation-two-joint" class="quarto-xref">Figure&nbsp;14</a>). The coverage error of all the algorithms is near the desired value in the absence of distribution shift. On the contrary, all of the algorithms except AgACI and DtACI undercover when there is distributional shift. SAOCP tends to have higher average path lengths than the other methods. In the distribution shift setting, SF-OGD and SAOCP tended to have smaller strongly adaptive regret than the other methods. An illustrative example of prediction intervals generated by each method for one of the simulated time series with distribution shift is shown in <a href="#fig-simulation-two-example" class="quarto-xref">Figure&nbsp;10</a>. The SAOCP prediction intervals in the example before the distribution shift are more jagged than those produced by the other methods, which illustrates why SAOCP may have longer path lengths.</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">simulation_two_plot</span>(simulation_study2<span class="sc">$</span>results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-simulation-two-results" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-simulation-two-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-simulation-two-results-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simulation-two-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Coverage error, mean interval width, path length, and strongly adaptive regret (<span class="math inline">m = 20</span>) for <span class="math inline">\alpha = 0.8, 0.9, 0.95</span> and simulations with and without distributional shift.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> simulation_study2<span class="sc">$</span>example_fits</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>coverage    <span class="ot">&lt;-</span> <span class="fu">format_coverage</span>(<span class="fu">extract_metric</span>(fits<span class="sc">$</span>fit, <span class="st">"coverage"</span>))</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>path_length <span class="ot">&lt;-</span> <span class="fu">format_path_length</span>(<span class="fu">extract_metric</span>(fits<span class="sc">$</span>fit, <span class="st">"path_length"</span>))</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>))</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(fits<span class="sc">$</span>fit[[i]], <span class="at">legend =</span> <span class="cn">FALSE</span>, <span class="at">main =</span> fits<span class="sc">$</span>method[[i]], <span class="at">index =</span> <span class="dv">51</span><span class="sc">:</span><span class="dv">500</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">text</span>(<span class="at">x =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="at">y =</span> <span class="sc">-</span><span class="fl">1.5</span>, <span class="at">labels =</span> <span class="fu">bquote</span>(EmpCov <span class="sc">==</span> .(coverage[[i]]) ), <span class="at">pos =</span> <span class="dv">4</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">text</span>(<span class="at">x =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="at">y =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">labels =</span> <span class="fu">bquote</span>(PathLength <span class="sc">==</span> .(path_length[[i]]) ), <span class="at">pos =</span> <span class="dv">4</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">4.1</span>, <span class="fl">4.1</span>, <span class="fl">2.1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-simulation-two-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-simulation-two-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-simulation-two-example-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simulation-two-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Example prediction intervals (target coverage <span class="math inline">\alpha = 0.9</span>) from the second simulation study of time series with distributional shift, in which the shift occurs at time 250. Blue and red points are observations that fell inside and outside the prediction intervals, respectively.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-case-study" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Case Study: Influenza Forecasting</h1>
<p>Influenza is a highly infectious disease that is estimated to infect approximately one billion individuals each year around the world <span class="citation" data-cites="krammer2018influenza">(<a href="#ref-krammer2018influenza" role="doc-biblioref">Krammer et al. 2018</a>)</span>. Influenza incidence in temperate climates tends to follow a seasonal pattern, with the highest number of infections during what is commonly referred to as the <span class="citation" data-cites="lofgren2007influenza">(<a href="#ref-lofgren2007influenza" role="doc-biblioref">Lofgren et al. 2007</a>)</span>. Accurate forecasting of influenza is of significant interest to aid in public health planning and resource allocation. To investigate the accuracy of influenza forecasts, the US Centers for Disease Control (CDC) initiated a challenge, referred to as FluSight, in which teams from multiple institutions submitted weekly forecasts of influenza incidence <span class="citation" data-cites="biggerstaff2016flusight">(<a href="#ref-biggerstaff2016flusight" role="doc-biblioref">Biggerstaff et al. 2016</a>)</span>. <span class="citation" data-cites="reich2019influenza">Reich et al. (<a href="#ref-reich2019influenza" role="doc-biblioref">2019</a>)</span> evaluated the accuracy of the forecasts over seven flu seasons from 2010 to 2017. As a case study, we investigate the use of ACI algorithms to augment the FluSight forecasts with prediction intervals.</p>
<p>The FluSight challenge collected forecasts for multiple prediction targets. For this case study, we focus on national (US) one-week ahead forecasts of weighted influenza-like illness (wILI), which is a population-weighted percentage of doctors visits where patients presented with influenza-like symptoms <span class="citation" data-cites="biggerstaff2016flusight">(<a href="#ref-biggerstaff2016flusight" role="doc-biblioref">Biggerstaff et al. 2016</a>)</span>. The FluSight dataset, which is publicly available, include forecasts derived from 21 different forecasting models, from both mechanistic and statistical viewpoints <span class="citation" data-cites="flusight2020 tushar2018flusightnetwork tushar2019flusight">(<a href="#ref-flusight2020" role="doc-biblioref">Flusight Network 2020</a>; <a href="#ref-tushar2018flusightnetwork" role="doc-biblioref">Tushar et al. 2018</a>, <a href="#ref-tushar2019flusight" role="doc-biblioref">2019</a>)</span>. For our purposes, we treat the way the forecasts were produced as a black box.</p>
<p>Formally, let <span class="math inline">y_{t}</span>, <span class="math inline">t \in \llbracket T \rrbracket</span> be the observed national wILI at time <span class="math inline">t</span>, and let <span class="math inline">\hat{\mu}_{j,t}</span>, <span class="math inline">j \in \llbracket J \rrbracket</span>, be the one-week ahead forecast of the wILI from model <span class="math inline">j</span> at time <span class="math inline">t</span>. Two of the original 21 forecasting methods were excluded from this case study due to poor predictive performance ( and ). In addition, six methods had identical forecasts (, , , , ), and therefore we only included one () in the analysis. The ACI methods were then applied to the log-observations and log-predictions, where the log-transformation was used to constrain the final prediction intervals to be positive. The first flu season (2010-2011) was used as a warm-up for each ACI method, and we report the empirical performance of the prediction intervals for the subsequent seasons (six seasons from 2012-2013 to 2016-2017). The ACI algorithms target prediction intervals with coverage of <span class="math inline">\alpha = 0.8</span>, <span class="math inline">\alpha = 0.9</span>, and <span class="math inline">\alpha = 0.95</span>. As in the simulation study, we used the interval constructor corresponding to the original presentation of each algorithm (see <a href="#tbl-aci" class="quarto-xref">Table&nbsp;1</a>).</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Paste together URL so it is not cut off in PDF</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"https://raw.githubusercontent.com/FluSightNetwork/"</span>,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a> <span class="st">"cdc-flusight-ensemble/master/scores/point_ests.csv"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>raw_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(url, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="cf">function</span>(data, method, alpha) {</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  first_season <span class="ot">&lt;-</span> data<span class="sc">$</span>Season <span class="sc">==</span> <span class="st">"2010/2011"</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  D <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="fu">abs</span>(data<span class="sc">$</span>obs_value <span class="sc">-</span> data<span class="sc">$</span>Value)[first_season])</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  interval_constructor <span class="ot">=</span> <span class="fu">case_when</span>(</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"AgACI"</span> <span class="sc">~</span> <span class="st">"conformal"</span>,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"DtACI"</span> <span class="sc">~</span> <span class="st">"conformal"</span>,</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"SF-OGD"</span> <span class="sc">~</span> <span class="st">"linear"</span>,</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    method <span class="sc">==</span> <span class="st">"SAOCP"</span> <span class="sc">~</span> <span class="st">"linear"</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>  gamma <span class="ot">&lt;-</span> D <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">3</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(interval_constructor <span class="sc">==</span> <span class="st">"linear"</span>) {</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    gamma_grid <span class="ot">=</span> <span class="fu">seq</span>(<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="fl">0.1</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span> {</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    gamma_grid <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.002</span>, <span class="fl">0.004</span>, <span class="fl">0.008</span>, <span class="fl">0.016</span>, <span class="fl">0.032</span>, <span class="fl">0.064</span>, <span class="fl">0.128</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>  parameters <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">interval_constructor =</span> interval_constructor,</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">D =</span> D,</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma =</span> gamma,</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">gamma_grid =</span> gamma_grid</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aci</span>(</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> <span class="fu">log</span>(data<span class="sc">$</span>obs_value),</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">predictions =</span> <span class="fu">log</span>(data<span class="sc">$</span>Value),</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> method,</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">parameters =</span> parameters,</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> alpha</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>metrics <span class="ot">&lt;-</span> <span class="cf">function</span>(data, fit) {</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aci_metrics</span>(fit, <span class="at">indices =</span> <span class="fu">which</span>(data<span class="sc">$</span>Season <span class="sc">!=</span> <span class="st">"2010/2011"</span>))</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>analysis_data <span class="ot">&lt;-</span> raw_data <span class="sc">%&gt;%</span></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    Target <span class="sc">==</span> <span class="st">"1 wk ahead"</span>,</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    Location <span class="sc">==</span> <span class="st">"US National"</span>,</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>    <span class="sc">!</span>(model_name <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"Delphi_Uniform"</span>, <span class="st">"CUBMA"</span>, <span class="st">"CU_EAKFC_SIRS"</span>, <span class="st">"CU_EKF_SEIRS"</span>,</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"CU_EKF_SIRS"</span>, <span class="st">"CU_RHF_SEIRS"</span>, <span class="st">"CU_RHF_SIRS"</span>))</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(Year, Model.Week) <span class="sc">%&gt;%</span></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(model_name) <span class="sc">%&gt;%</span></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nest</span>()</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>  analysis_data,</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">method =</span> <span class="fu">c</span>(<span class="st">"AgACI"</span>, <span class="st">"DtACI"</span>, <span class="st">"SF-OGD"</span>, <span class="st">"SAOCP"</span>)),</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">alpha =</span> <span class="fu">c</span>(<span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>))</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">fit =</span> <span class="fu">pmap</span>(<span class="fu">list</span>(data, method, alpha), fit),</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>         <span class="at">metrics =</span> <span class="fu">map2</span>(data, fit, metrics))</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>case_study_results <span class="ot">&lt;-</span> fits <span class="sc">%&gt;%</span></span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>data, <span class="sc">-</span>fit) <span class="sc">%&gt;%</span></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">metrics =</span> <span class="fu">map</span>(metrics, as_tibble)) <span class="sc">%&gt;%</span></span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="fu">c</span>(metrics))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The coverage errors, mean interval widths, path lengths, and strongly adaptive regret (for <span class="math inline">m = 20</span>) of the prediction intervals for each of the underlying forecast models is shown in <a href="#fig-case-study-metrics" class="quarto-xref">Figure&nbsp;11</a>. In all cases the absolute coverage error was less than <span class="math inline">0.1</span>. SF-OGD performed particularly well, with coverage errors close to zero for all forecasting models. Interval widths were similar across methods, with SAOCP slightly shorter. Path Lengths were shorter for AgACI and DtACI and longer for SAOCP.</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">case_study_plot</span>(case_study_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-case-study-metrics" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-case-study-metrics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-case-study-metrics-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-case-study-metrics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Coverage errors, mean interval widths, path lengths, and strongly adaptive regret (for <span class="math inline">m = 20</span>) of prediction intervals generated with each ACI method based on forecasts from each of the 19 underlying influenza forecasting models.
</figcaption>
</figure>
</div>
</div>
</div>
<p>As an illustrative example, in <a href="#fig-case-study-example" class="quarto-xref">Figure&nbsp;12</a> we plot the point forecasts from one of the forecasting models (based on SARIMA with no seasonal differencing) and the associated ACI-generated 90% prediction intervals for each season from 2011-2017. In general, in this practical setting all of the ACI algorithms yield quite similar prediction intervals. Interestingly, the forecasts in 2011-2012 underpredicted the observations for much of the season. The algorithm responds by making the intervals wider to cover the observations, and because the intervals are symmetric the lower bound then becomes unrealistically low. A similar phenomenon can be seen in the growth phase of the 2012/2013 season as well.</p>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>sarima_fits <span class="ot">&lt;-</span> fits <span class="sc">%&gt;%</span> <span class="fu">filter</span>(</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  model_name <span class="sc">==</span> <span class="st">"ReichLab_sarima_seasonal_difference_FALSE"</span>,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  alpha <span class="sc">==</span> <span class="fl">0.9</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">output =</span> <span class="fu">map</span>(fit, extract_intervals)) <span class="sc">%&gt;%</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(method, alpha, data, output) <span class="sc">%&gt;%</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="fu">c</span>(data, output)) <span class="sc">%&gt;%</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Season <span class="sc">!=</span> <span class="st">"2010/2011"</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>sarima_fits <span class="sc">%&gt;%</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Model.Week, <span class="at">y =</span> <span class="fu">log</span>(obs_value))) <span class="sc">+</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">shape =</span> <span class="st">"Observed"</span>)) <span class="sc">+</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> pred, <span class="at">lty =</span> <span class="st">"Forecast"</span>), <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> lower, <span class="at">color =</span> method)) <span class="sc">+</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> upper, <span class="at">color =</span> method)) <span class="sc">+</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>Season) <span class="sc">+</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Flu Season Week"</span>,</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"log(wILI)"</span>,</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"SARIMA forecasts with ACI 90% prediction intervals"</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-case-study-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-case-study-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-case-study-example-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-case-study-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: Example conformal prediction intervals for six flu seasons based on forecasts from a SARIMA type model.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-discussion" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Discussion</h1>
<p>The results of our simulations and case study show that, when tuning parameters are chosen well, Adaptive Conformal Inference algorithms yield well-performing prediction intervals. On the contrary, poor choice of tuning parameters can lead to intervals of low utility: for one example, Figure <a href="#fig-sf-ogd" class="quarto-xref">Figure&nbsp;4</a> shows how choosing the tuning parameter for SF-OGD to be too small can lead to intervals that update too slowly and significantly undercover. Furthermore, in some cases the prediction intervals may appear to perform well with respect to metrics like the empirical coverage error, while simultaneously being useless in practice. The original ACI algorithm illustrates this phenomenon: too small a value of its learning rate <span class="math inline">\gamma</span> yields prediction intervals that are not reactive enough, while too large a value yields intervals that change too fast. In both cases, the empirical coverage may appear well-calibrated, while the prediction intervals will not be useful. Thus, the core challenge in designing an ACI algorithm is in finding an optimal level of reactivity for the prediction intervals. As users of these algorithms, the challenge is in finding values for the tuning parameters that avoid pathological behaviors.</p>
<p>Several of the algorithms investigated in this paper handle the problem of finding an optimal level of reactivity by aggregating prediction intervals generated by a set of underlying ACI algorithms. Our results show the algorithms can perform well in multiple difficult scenarios. However, the overall effect of these approaches is to shift the problem to a higher level of abstraction: we still need to set tuning parameters that control the amount of reactivity, but do so at a higher level than the original ACI algorithm. It is desirable that these tuning parameters be easily interpretable, with simple strategies available for setting them. An advantage of the SF-OGD and SAOCP algorithms in this respect are that their main tuning parameter, the maximum radius <span class="math inline">D</span>, is easily interpretable as the maximum possible difference between the input predictions and the truth. It is also straightforward to choose this parameter based on a calibration set, although this strategy does not necessarily work well in cases of distribution shift. We also found that an advantage of the AgACI method is its robustness to the choice of its main tuning parameter, the set of candidate learning rates, in the sense that the grid of candidate learning rates can always be expanded as illustrated in <a href="#sec-agaci-tuning" class="quarto-xref">Section&nbsp;3.2.2</a>.</p>
<p>A key challenge in tuning the algorithms arises in settings of distribution shift, where methods for choosing hyperparameters based on a calibration set from before the distribution shift will likely not perform well. The second simulation study we conducted probed this setting in a simple scenario. We found that several of the methods yielded prediction intervals that had non-optimal empirical coverage. As we picked hyperparameters based on a calibration set formed before the distribution shift, it is not surprising that the resulting tuning parameters are not optimal. This underscores the difficulty in designing ACI algorithms that can adapt to distribution shifts, and in finding robust methods for choosing hyperparameters. In practice, it is possible the second simulation study does not accurately reflect real-world scenarios. Indeed, the benchmarks presented in <span class="citation" data-cites="bhatnagar2023saocp">Bhatnagar et al. (<a href="#ref-bhatnagar2023saocp" role="doc-biblioref">2023</a>)</span> using the datasets from the M4 competition <span class="citation" data-cites="makridakis2020m4">(<a href="#ref-makridakis2020m4" role="doc-biblioref">Makridakis, Spiliotis, and Assimakopoulos 2020</a>)</span>, and using point predictions generated by diverse prediction algorithms, found that ACI algorithms exhibited good performance in terms of empirical coverage. Nevertheless, our recommendation for future papers in this line of research is to include simulation studies for simple distributional shift scenarios as a benchmark.</p>
<p>Our case study results illustrate the dependence of the ACI algorithms on having access to high-quality point predictions. If the predictions are biased, for example, then the prediction intervals may be able to achieve optimal coverage at the expense of larger interval widths. This type of underperformance due to biased input predictions can be seen in the 2011-2012 flu season in the case study <a href="#fig-case-study-example" class="quarto-xref">Figure&nbsp;12</a>. One way bias can arise in the underlying predictions is due to model misspecification: for example, if a forecast method assumes a time series will evolve according to a particular parametric model that does not accurately capture the true data generating process, then the forecasts may be systematically biased. Using ensemble methods to combine forecasts from several flexible machine learning algorithms is one strategy that can be used to hedge against such model misspecification and improve the quality of forecasts <span class="citation" data-cites="makridakis2020m4">(<a href="#ref-makridakis2020m4" role="doc-biblioref">Makridakis, Spiliotis, and Assimakopoulos 2020</a>)</span>.</p>
<p>Overall, our findings illustrate strengths and weaknesses of all the considered algorithms. The original ACI algorithm is appealing in its simplicity, although its performance depends entirely on a good choice of its tuning parameter. AgACI tended to perform well in the simulation studies in terms of coverage error, although it had slightly higher strongly adaptive regret than other algorithms in some settings. However, there are relatively fewer theoretical guarantees available for AgACI than the other methods. DtACI, SF-OGD, and SAOCP all feature strong theoretical results, although they exhibited some differences in the simulation studies, with SF-OGD and SAOCP slightly undercovering in some scenarios. SAOCP also had longer path lengths than other methods in simulations, although in practice in the influenza forecasting task longer path lengths does not seem to effect the plausibility of the prediction intervals the algorithm produces.</p>
<p>There remain many possible extensions of ACI algorithms. The algorithms presented in this work primarily consider symmetric intervals evaluated using the pinball loss function (AgACI can yield asymmetric intervals because the aggregation rule is applied separately to the lower and upper bounds from the underlying experts, but those underlying experts only produce symmetric intervals). A simple extension would switch to using the interval loss function <span class="citation" data-cites="gneiting2007scoring">(<a href="#ref-gneiting2007scoring" role="doc-biblioref">Gneiting and Raftery 2007</a>)</span>, which would allow for asymmetric intervals where two parameters are learned for the upper and lower bounds, respectively. It may also be of interest to generate prediction intervals that have coverage guarantees for arbitrary subsets of observations (for example, we may seek prediction intervals for daily observations that have near optimal coverage for every day of the week, or month of the year), similar to guarantees provided by the MultiValid Prediction method described in <span class="citation" data-cites="bastani2022practical">(<a href="#ref-bastani2022practical" role="doc-biblioref">Bastani et al. 2022</a>)</span>. Another avenue for theoretical research is to relax the assumption of bounded radii necessary for the theoretical results of algorithms such as SAOCP.</p>
<section id="acknowledgements" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="acknowledgements">Acknowledgements</h2>
<p>This research is partially supported by the Agence Nationale de la Recherche as part of the “Investissements d’avenir” program (reference ANR-19-P3IA-0001; PRAIRIE 3IA Institute) and as part of the program “Au delà de l’apprentissage séquentiel pour de meilleures prises de décisions” (reference ANR-19-CE23-0026; BOLD). We would like to thank Margaux Zaffran for providing helpful comments on the manuscript.</p>
</section>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-angelopoulos2024online" class="csl-entry" role="listitem">
Angelopoulos, Anastasios N., Rina Foygel Barber, and Stephen Bates. 2024. <span>“Online Conformal Prediction with Decaying Step Sizes.”</span> <a href="https://arxiv.org/abs/2402.01139">https://arxiv.org/abs/2402.01139</a>.
</div>
<div id="ref-angelopoulos2022gentle" class="csl-entry" role="listitem">
Angelopoulos, Anastasios N., and Stephen Bates. 2023. <span>“Conformal Prediction: A Gentle Introduction.”</span> <em>Found. Trends Mach. Learn.</em> 16 (4): 494–591. <a href="https://doi.org/10.1561/2200000101">https://doi.org/10.1561/2200000101</a>.
</div>
<div id="ref-bastani2022practical" class="csl-entry" role="listitem">
Bastani, Osbert, Varun Gupta, Christopher Jung, Georgy Noarov, Ramya Ramalingam, and Aaron Roth. 2022. <span>“Practical Adversarial Multivalid Conformal Prediction.”</span> In <em>Advances in Neural Information Processing Systems</em>, edited by S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, 35:29362–73. Curran Associates, Inc. <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/bcdaaa1aec3ae2aa39542acefdec4e4b-Paper-Conference.pdf">https://proceedings.neurips.cc/paper_files/paper/2022/file/bcdaaa1aec3ae2aa39542acefdec4e4b-Paper-Conference.pdf</a>.
</div>
<div id="ref-bhatnagar2023saocp" class="csl-entry" role="listitem">
Bhatnagar, Aadyot, Huan Wang, Caiming Xiong, and Yu Bai. 2023. <span>“Improved Online Conformal Prediction via Strongly Adaptive Online Learning.”</span> In <em>Proceedings of the 40th International Conference on Machine Learning</em>. ICML’23. Honolulu, Hawaii, USA: JMLR.org.
</div>
<div id="ref-biggerstaff2016flusight" class="csl-entry" role="listitem">
Biggerstaff, Matthew, David Alper, Mark Dredze, Spencer Fox, Isaac Chun-Hai Fung, Kyle S. Hickmann, Bryan Lewis, et al. 2016. <span>“Results from the Centers for Disease Control and Prevention’s Predict the 2013–2014 Influenza Season Challenge.”</span> <em>BMC Infectious Diseases</em> 16 (1): 357. <a href="https://doi.org/10.1186/s12879-016-1669-x">https://doi.org/10.1186/s12879-016-1669-x</a>.
</div>
<div id="ref-cesabianchi2006games" class="csl-entry" role="listitem">
Cesa-Bianchi, Nicolo, and Gabor Lugosi. 2006. <em>Prediction, Learning, and Games</em>. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511546921">https://doi.org/10.1017/CBO9780511546921</a>.
</div>
<div id="ref-diquigiovanni2022fd" class="csl-entry" role="listitem">
Diquigiovanni, Jacopo, Matteo Fontana, Aldo Solari, Simone Vantini, and Paolo Vergottini. 2022. <em>conformalInference.fd: Tools for Conformal Inference for Regression in Multivariate Functional Setting</em>. <a href="https://CRAN.R-project.org/package=conformalInference.fd">https://CRAN.R-project.org/package=conformalInference.fd</a>.
</div>
<div id="ref-feldman2023achieving" class="csl-entry" role="listitem">
Feldman, Shai, Liran Ringel, Stephen Bates, and Yaniv Romano. 2023. <span>“Achieving Risk Control in Online Learning Settings.”</span> <em>Transactions on Machine Learning Research</em>. <a href="https://openreview.net/forum?id=5Y04GWvoJu">https://openreview.net/forum?id=5Y04GWvoJu</a>.
</div>
<div id="ref-flusight2020" class="csl-entry" role="listitem">
Flusight Network. 2020. <span>“GitHub - FluSightNetwork/Cdc-Flusight-Ensemble: Guidelines and Forecasts for a Collaborative u.s. Influenza Forecasting Project.”</span> <a href="https://github.com/FluSightNetwork/">https://github.com/FluSightNetwork/</a>.
</div>
<div id="ref-friedman1983" class="csl-entry" role="listitem">
Friedman, Jerome H., Eric Grosse, and Werner Stuetzle. 1983. <span>“Multidimensional Additive Spline Approximation.”</span> <em>SIAM Journal on Scientific and Statistical Computing</em> 4 (2): 291–301. <a href="https://doi.org/10.1137/0904023">https://doi.org/10.1137/0904023</a>.
</div>
<div id="ref-opera2023" class="csl-entry" role="listitem">
Gaillard, Pierre, Yannig Goude, Laurent Plagne, Thibaut Dubois, and Benoit Thieurmel. 2023. <em>Opera: Online Prediction by Expert Aggregation</em>. <a href="http://pierre.gaillard.me/opera.html">http://pierre.gaillard.me/opera.html</a>.
</div>
<div id="ref-gasparin2024conformal" class="csl-entry" role="listitem">
Gasparin, Matteo, and Aaditya Ramdas. 2024. <span>“Conformal Online Model Aggregation.”</span> <a href="https://arxiv.org/abs/2403.15527">https://arxiv.org/abs/2403.15527</a>.
</div>
<div id="ref-gibbs2021adaptive" class="csl-entry" role="listitem">
Gibbs, Isaac, and Emmanuel Candes. 2021. <span>“Adaptive Conformal Inference Under Distribution Shift.”</span> In <em>Advances in Neural Information Processing Systems</em>, edited by M. Ranzato, A. Beygelzimer, Y. Dauphin, P. S. Liang, and J. Wortman Vaughan, 34:1660–72. Curran Associates, Inc. <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/0d441de75945e5acbc865406fc9a2559-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2021/file/0d441de75945e5acbc865406fc9a2559-Paper.pdf</a>.
</div>
<div id="ref-gibbs2022faci" class="csl-entry" role="listitem">
Gibbs, Isaac, and Emmanuel Candès. 2022. <span>“Conformal Inference for Online Prediction with Arbitrary Distribution Shifts.”</span> <a href="https://arxiv.org/abs/2208.08401">https://arxiv.org/abs/2208.08401</a>.
</div>
<div id="ref-gneiting2007scoring" class="csl-entry" role="listitem">
Gneiting, Tilmann, and Adrian E Raftery. 2007. <span>“Strictly Proper Scoring Rules, Prediction, and Estimation.”</span> <em>Journal of the American Statistical Association</em> 102 (477): 359–78. <a href="https://doi.org/10.1198/016214506000001437">https://doi.org/10.1198/016214506000001437</a>.
</div>
<div id="ref-gradu2022adaptive" class="csl-entry" role="listitem">
Gradu, Paula, Elad Hazan, and Edgar Minasyan. 2023. <span>“Adaptive Regret for Control of Time-Varying Dynamics.”</span> In <em>Proceedings of the 5th Annual Learning for Dynamics and Control Conference</em>, edited by Nikolai Matni, Manfred Morari, and George J. Pappas, 211:560–72. Proceedings of Machine Learning Research. PMLR. <a href="https://proceedings.mlr.press/v211/gradu23a.html">https://proceedings.mlr.press/v211/gradu23a.html</a>.
</div>
<div id="ref-jun2017coinbetting" class="csl-entry" role="listitem">
Jun, Kwang-Sung, Francesco Orabona, Stephen Wright, and Rebecca Willett. 2017. <span>“<span class="nocase">Improved Strongly Adaptive Online Learning using Coin Betting</span>.”</span> In <em>Proceedings of the 20th International Conference on Artificial Intelligence and Statistics</em>, edited by Aarti Singh and Jerry Zhu, 54:943–51. Proceedings of Machine Learning Research. PMLR. <a href="https://proceedings.mlr.press/v54/jun17a.html">https://proceedings.mlr.press/v54/jun17a.html</a>.
</div>
<div id="ref-krammer2018influenza" class="csl-entry" role="listitem">
Krammer, Florian, Gavin J. D. Smith, Ron A. M. Fouchier, Malik Peiris, Katherine Kedzierska, Peter C. Doherty, Peter Palese, et al. 2018. <span>“Influenza.”</span> <em>Nature Reviews Disease Primers</em> 4 (1): 3. <a href="https://doi.org/10.1038/s41572-018-0002-y">https://doi.org/10.1038/s41572-018-0002-y</a>.
</div>
<div id="ref-lei2020cfcausal" class="csl-entry" role="listitem">
Lei, Lihua, and Emmanuel J. Candès. 2021. <span>“<span class="nocase">Conformal Inference of Counterfactuals and Individual Treatment Effects</span>.”</span> <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em> 83 (5): 911–38. <a href="https://doi.org/10.1111/rssb.12445">https://doi.org/10.1111/rssb.12445</a>.
</div>
<div id="ref-lofgren2007influenza" class="csl-entry" role="listitem">
Lofgren, Eric, N. H. Fefferman, Y. N. Naumov, J. Gorski, and E. N. Naumova. 2007. <span>“Influenza Seasonality: Underlying Causes and Modeling Theories.”</span> <em>Journal of Virology</em> 81 (11): 5429–36. <a href="https://doi.org/10.1128/jvi.01680-06">https://doi.org/10.1128/jvi.01680-06</a>.
</div>
<div id="ref-makridakis2020m4" class="csl-entry" role="listitem">
Makridakis, Spyros, Evangelos Spiliotis, and Vassilios Assimakopoulos. 2020. <span>“The M4 Competition: 100,000 Time Series and 61 Forecasting Methods.”</span> <em>International Journal of Forecasting</em> 36 (1): 54–74. https://doi.org/<a href="https://doi.org/10.1016/j.ijforecast.2019.04.014">https://doi.org/10.1016/j.ijforecast.2019.04.014</a>.
</div>
<div id="ref-orabona2018sfogd" class="csl-entry" role="listitem">
Orabona, Francesco, and Dávid Pál. 2018. <span>“Scale-Free Online Learning.”</span> <em>Theoretical Computer Science</em> 716: 50–69. https://doi.org/<a href="https://doi.org/10.1016/j.tcs.2017.11.021">https://doi.org/10.1016/j.tcs.2017.11.021</a>.
</div>
<div id="ref-reich2019influenza" class="csl-entry" role="listitem">
Reich, Nicholas G, Logan C Brooks, Spencer J Fox, Sasikiran Kandula, Craig J McGowan, Evan Moore, Dave Osthus, et al. 2019. <span>“A Collaborative Multiyear, Multimodel Assessment of Seasonal Influenza Forecasting in the United States.”</span> <em>Proc. Natl. Acad. Sci. U. S. A.</em> 116 (8): 3146–54.
</div>
<div id="ref-shafer2008conformal" class="csl-entry" role="listitem">
Shafer, Glenn, and Vladimir Vovk. 2008. <span>“A Tutorial on Conformal Prediction.”</span> <em>J. Mach. Learn. Res.</em> 9 (June): 371–421.
</div>
<div id="ref-tibshirani2019ci" class="csl-entry" role="listitem">
Tibshirani, Ryan, Jacopo Diquigiovanni, Matteo Fontana, and Paolo Vergottini. 2019. <em>conformalInference: Tools for Conformal Inference in Regression</em>.
</div>
<div id="ref-tushar2019flusight" class="csl-entry" role="listitem">
Tushar, Abhinav, Nicholas G Reich, tkcy, brookslogan, d-osthus, Craig McGowan, Evan Ray, et al. 2019. <span>“<span class="nocase">FluSightNetwork/cdc-flusight-ensemble: End of 2018/2019 US influenza season</span>.”</span> Zenodo. <a href="https://doi.org/10.5281/zenodo.3454212">https://doi.org/10.5281/zenodo.3454212</a>.
</div>
<div id="ref-tushar2018flusightnetwork" class="csl-entry" role="listitem">
Tushar, Abhinav, Nicholas Reich, Teresa Yamana, Dave Osthus, Craig McGowan, Evan Ray, and et al. 2018. <span>“FluSightNetwork: Cdc-Flusight-Ensemble Repository.”</span> <a href="https://github.com/FluSightNetwork/cdc-flusight-ensemble" class="uri">https://github.com/FluSightNetwork/cdc-flusight-ensemble</a>.
</div>
<div id="ref-vovk2005" class="csl-entry" role="listitem">
Vovk, Vladimir, Alex Gammerman, and Glenn Shafer. 2005. <em>Algorithmic Learning in a Random World</em>. Berlin, Heidelberg: Springer-Verlag.
</div>
<div id="ref-wintenberger2017boa" class="csl-entry" role="listitem">
Wintenberger, Olivier. 2017. <span>“Optimal Learning with Bernstein Online Aggregation.”</span> <em>Machine Learning</em> 106 (1): 119–41. <a href="https://doi.org/10.1007/s10994-016-5592-6">https://doi.org/10.1007/s10994-016-5592-6</a>.
</div>
<div id="ref-wright2017ranger" class="csl-entry" role="listitem">
Wright, Marvin N., and Andreas Ziegler. 2017. <span>“<span class="nocase">ranger</span>: A Fast Implementation of Random Forests for High Dimensional Data in <span>C++</span> and <span>R</span>.”</span> <em>Journal of Statistical Software</em> 77 (1): 1–17. <a href="https://doi.org/10.18637/jss.v077.i01">https://doi.org/10.18637/jss.v077.i01</a>.
</div>
<div id="ref-xu2021enbpi" class="csl-entry" role="listitem">
Xu, Chen, and Yao Xie. 2021. <span>“Conformal Prediction Interval for Dynamic Time-Series.”</span> In <em>Proceedings of the 38th International Conference on Machine Learning</em>, edited by Marina Meila and Tong Zhang, 139:11559–69. Proceedings of Machine Learning Research. PMLR. <a href="https://proceedings.mlr.press/v139/xu21h.html">https://proceedings.mlr.press/v139/xu21h.html</a>.
</div>
<div id="ref-xu2023spci" class="csl-entry" role="listitem">
———. 2023. <span>“Sequential Predictive Conformal Inference for Time Series.”</span> In <em>Proceedings of the 40th International Conference on Machine Learning</em>, edited by Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, 202:38707–27. Proceedings of Machine Learning Research. PMLR. <a href="https://proceedings.mlr.press/v202/xu23r.html">https://proceedings.mlr.press/v202/xu23r.html</a>.
</div>
<div id="ref-zaffran2022agaci" class="csl-entry" role="listitem">
Zaffran, Margaux, Olivier Feron, Yannig Goude, Julie Josse, and Aymeric Dieuleveut. 2022. <span>“Adaptive Conformal Predictions for Time Series.”</span> In <em>Proceedings of the 39th International Conference on Machine Learning</em>, edited by Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, 162:25834–66. Proceedings of Machine Learning Research. PMLR. <a href="https://proceedings.mlr.press/v162/zaffran22a.html">https://proceedings.mlr.press/v162/zaffran22a.html</a>.
</div>
<div id="ref-zhang2024discounted" class="csl-entry" role="listitem">
Zhang, Zhiyu, David Bombara, and Heng Yang. 2024. <span>“Discounted Adaptive Online Prediction.”</span> <a href="https://arxiv.org/abs/2402.02720">https://arxiv.org/abs/2402.02720</a>.
</div>
</div>
</section>
<section id="appendix" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Appendix</h1>
<section id="additional-simulation-study-results" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="additional-simulation-study-results"><span class="header-section-number">8.1</span> Additional simulation study results</h2>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">simulation_one_plot</span>(simulation_study1<span class="sc">$</span>results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="published-202407-susmann-adaptive-conformal_files/figure-html/simulation_one_plot_appendix-1.svg" class="img-fluid figure-img"></p>
<figcaption>Coverage errors, mean interval widths, and path lengths for the first simulation study with target coverage <span class="math inline">\alpha \in \{ 0.8, 0.9, 0.95 \}</span>.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">simulation_one_joint_plot</span>(simulation_study1<span class="sc">$</span>results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-simulation-one-joint" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-simulation-one-joint-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-simulation-one-joint-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simulation-one-joint-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: Mean Interval Width vs Coverage Error for the first simulation study. The error bars represent the 10% to 90% quantiles of the metrics over the simulation datasets.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-simulation-two-joint" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-simulation-two-joint-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="published-202407-susmann-adaptive-conformal_files/figure-html/fig-simulation-two-joint-1.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simulation-two-joint-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14: Mean interval width vs coverage error (top) and Mean Path Length vs.&nbsp;coverage error (bottom) for the second simulation study. The error bars represent the 10% to 90% quantiles of the metrics over the simulation datasets.
</figcaption>
</figure>
</div>
</div>
</div>
<!-- -->

</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{susmann2024,
  author = {Susmann, Herbert and Chambaz, Antoine and Josse, Julie},
  publisher = {Société Française de Statistique},
  title = {AdaptiveConformal: {An} {`R`} {Package} for {Adaptive}
    {Conformal} {Inference}},
  journal = {Computo},
  date = {2024-07-18},
  url = {https://computo.sfds.asso.fr/template-computo-quarto},
  doi = {10.57750/edan-5f53},
  issn = {2824-7795},
  langid = {en},
  abstract = {Conformal Inference (CI) is a popular approach for
    generating finite sample prediction intervals based on the output of
    any point prediction method when data are exchangeable. Adaptive
    Conformal Inference (ACI) algorithms extend CI to the case of
    sequentially observed data, such as time series, and exhibit strong
    theoretical guarantees without having to assume exchangeability of
    the observed data. The common thread that unites algorithms in the
    ACI family is that they adaptively adjust the width of the generated
    prediction intervals in response to the observed data. We provide a
    detailed description of five ACI algorithms and their theoretical
    guarantees, and test their performance in simulation studies. We
    then present a case study of producing prediction intervals for
    influenza incidence in the United States based on black-box point
    forecasts. Implementations of all the algorithms are released as an
    open-source `R` package, `AdaptiveConformal`, which also includes
    tools for visualizing and summarizing conformal prediction
    intervals.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-susmann2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Susmann, Herbert, Antoine Chambaz, and Julie Josse. 2024.
<span>“AdaptiveConformal: An `R` Package for Adaptive Conformal
Inference.”</span> <em>Computo</em>, July. <a href="https://doi.org/10.57750/edan-5f53">https://doi.org/10.57750/edan-5f53</a>.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb18" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "AdaptiveConformal: An `R` Package for Adaptive Conformal Inference"</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "AdaptiveConformal: An `R` Package for Adaptive Conformal Inference"</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Herbert Susmann</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">    corresponding: true</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">    email: herbps10@gmail.com</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">    url: https://herbsusmann.com</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0002-3540-8255</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: CEREMADE (UMR 7534), Université Paris-Dauphine PSL, Place du Maréchal de Lattre de Tassigny, Paris, 75016, France</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://www.ceremade.dauphine.fr/</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Antoine Chambaz</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co">    email: antoine.chambaz@u-paris.fr</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co">    url: https://helios2.mi.parisdescartes.fr/~chambaz/</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0002-5592-6471</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Université Paris Cité, CNRS, MAP5, F-75006 Paris, France</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co">        department:</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://map5.mi.parisdescartes.fr/</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Julie Josse</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co">    email: julie.josse@inria.fr</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="co">    url: http://juliejosse.com/</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0001-9547-891X</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Inria PreMeDICaL team, Idesp, Université de Montpellier</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://team.inria.fr/premedical/</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 07-18-2024</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> last-modified</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> |</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co">  Conformal Inference (CI) is a popular approach for generating finite sample prediction intervals based on the output of any point prediction method when data are exchangeable. Adaptive Conformal Inference (ACI) algorithms extend CI to the case of sequentially observed data, such as time series, and exhibit strong theoretical guarantees without having to assume exchangeability of the observed data. The common thread that unites algorithms in the ACI family is that they adaptively adjust the width of the generated prediction intervals in response to the observed data. We provide a detailed description of five ACI algorithms and their theoretical guarantees, and test their performance in simulation studies. We then present a case study of producing prediction intervals for influenza incidence in the United States based on black-box point forecasts. Implementations of all the algorithms are released as an open-source `R` package, `AdaptiveConformal`, which also includes tools for visualizing and summarizing conformal prediction intervals.</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> &gt;+</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="co">  Conformal Inference (CI) is a popular approach for generating finite sample prediction intervals based on the output of any point prediction method when data are exchangeable. Adaptive Conformal Inference (ACI) algorithms extend CI to the case of sequentially observed data, such as time series, and exhibit strong theoretical guarantees without having to assume exchangeability of the observed data. The common thread that unites algorithms in the ACI family is that they adaptively adjust the width of the generated prediction intervals in response to the observed data. We provide a detailed description of five ACI algorithms and their theoretical guarantees, and test their performance in simulation studies. We then present a case study of producing prediction intervals for influenza incidence in the United States based on black-box point forecasts. Implementations of all the algorithms are released as an open-source `R` package, `AdaptiveConformal`, which also includes tools for visualizing and summarizing conformal prediction intervals.</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span><span class="co"> [Conformal inference, Adaptive conformal inference, time series, R]</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="co">  type: article-journal</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="co">  container-title: "Computo"</span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="co">  doi: "10.57750/edan-5f53"</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a><span class="co">  url: https://computo.sfds.asso.fr/template-computo-quarto</span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="co">  publisher: "Société Française de Statistique"</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a><span class="co">  issn: "2824-7795"</span></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a><span class="an">github-user:</span><span class="co"> computorg</span></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a><span class="an">logo:</span><span class="co"> "true"</span></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a><span class="an">repo:</span><span class="co"> "published-202407-susmann-adaptive-conformal"</span></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> false # set to false once the build is running</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a><span class="an">published:</span><span class="co"> true # will be set to true once accepted</span></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a><span class="an">google-scholar:</span><span class="co"> true</span></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-html:</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-pdf:</span></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a><span class="co">    keep-tex: true</span></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a><span class="co">    include-in-header:</span></span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a><span class="co">      - text: |</span></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a><span class="co">          \usepackage{stmaryrd}</span></span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a><span class="co">          \usepackage{xfrac}</span></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction</span></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>Conformal Inference (CI) is a family of methods for generating finite sample prediction intervals around point predictions when data are exchangeable <span class="co">[</span><span class="ot">@vovk2005; @shafer2008conformal; @angelopoulos2022gentle</span><span class="co">]</span>. The input point predictions can be derived from any prediction method, making CI a powerful tool for augmenting black-box prediction algorithms with prediction intervals. Classical CI methods are able to yield marginally valid intervals with only the assumption that the joint distribution of the data does not change based on the order of the observations (that is, they are exchangeable). However, in many real-world settings data are not exchangeable: for example, time series data usually cannot be assumed to be exchangeable due to temporal dependence. A recent line of research examines the problem of generating prediction intervals for observations that are observed online (that is, one at a time) and for which exchangeability is not assumed to hold <span class="co">[</span><span class="ot">@gibbs2021adaptive; @zaffran2022agaci; @gibbs2022faci; @bhatnagar2023saocp</span><span class="co">]</span>. The methods from this literature, which we refer to generally as _Adaptive Conformal Inference_ (ACI) algorithms, work by adaptively adjusting the width of the generated prediction intervals in response to the observed data.</span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>Informally, suppose a sequence of outcomes $y_t \in \mathbb{R}$, $t = 1, \dots, T$ are observed one at a time. Before seeing each observation, we have at our disposal a point prediction $\hat{\mu}_t \in \mathbb{R}$ that can be generated by any method. Our goal is to find an algorithm for producing prediction intervals $[\ell_t, u_t]$, $\ell_t \leq u_t$ such that, in the long run, the observations $y_t$ fall within the corresponding prediction intervals roughly $\alpha \times 100\%$ of the time: that is, $\lim_{T \to \infty} \sfrac{1}{T} \sum_{t=1}^T \mathbb{I}<span class="sc">\{</span> y_t \in <span class="co">[</span><span class="ot">\ell_t, u_t</span><span class="co">]</span> <span class="sc">\}</span> = \alpha$. The original ACI algorithm <span class="co">[</span><span class="ot">@gibbs2021adaptive</span><span class="co">]</span> is based on a simple idea: if the previous prediction interval at time $(t-1)$ did not cover the true observation, then the next prediction interval at time $t$ is made slightly wider. Conversely, if the previous prediction interval did include the observation, then the next prediction interval is made slightly narrower. It can be shown that this procedure yields prediction intervals that in the long run cover the true observations the desired proportion of the time.</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>The main tuning parameter of the original ACI algorithm is a learning rate that controls how fast prediction interval width changes. If the learning rate is too low, then the prediction intervals will not be able to adapt fast enough to shifts in the data generating distribution; if it is too large, then the intervals will oscillate widely. The critical dependence of the original ACI algorithm on proper choice of its learning rate spurred subsequent research into meta-algorithms that learn the correct learning rate (or an analogue thereof) in various ways, typically drawing on approaches from the online learning literature. In this paper, we present four such algorithms: Aggregated ACI <span class="co">[</span><span class="ot">AgACI, @zaffran2022agaci</span><span class="co">]</span>, Dynamically-tuned Adaptive ACI <span class="co">[</span><span class="ot">DtACI, @gibbs2022faci</span><span class="co">]</span>, Scale-Free Online Gradient Descent <span class="co">[</span><span class="ot">SF-OGD, @bhatnagar2023saocp</span><span class="co">]</span>, and Strongly Adaptive Online Conformal Prediction <span class="co">[</span><span class="ot">SAOCP, @bhatnagar2023saocp</span><span class="co">]</span>. We note that the adaption of conformal inference techniques is an active area of research and the algorithms we focus on in this work are not exhaustive; see among others @feldman2023achieving, @bastani2022practical, @xu2021enbpi, @xu2023spci, @angelopoulos2024online, @zhang2024discounted, and @gasparin2024conformal.</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>Our primary practical contribution is an implementation of each algorithm in an open source <span class="in">`R`</span> package, <span class="in">`AdaptiveConformal`</span>, which is available at <span class="co">[</span><span class="ot">https://github.com/herbps10/AdaptiveConformal</span><span class="co">](https://github.com/herbps10/AdaptiveConformal)</span>. The package also includes routines for visualization and summary of the prediction intervals. We note that Python versions of several algorithms were also made available by @zaffran2022agaci and @bhatnagar2023saocp, but to our knowledge this is the first package implementing them in <span class="in">`R`</span>. In addition, several <span class="in">`R`</span> packages exist for conformal inference in other contexts, including <span class="in">`conformalInference`</span> focusing on regression <span class="co">[</span><span class="ot">@tibshirani2019ci</span><span class="co">]</span>, <span class="in">`conformalInference.fd`</span>, with methods for functional responses <span class="co">[</span><span class="ot">@diquigiovanni2022fd</span><span class="co">]</span>, and <span class="in">`cfcausal`</span> for causal inference related functionals <span class="co">[</span><span class="ot">@lei2020cfcausal</span><span class="co">]</span>. Our second practical contribution is to compare the performance of the algorithms in simulation studies and in a case study generating prediction intervals for influenza incidence in the United States based on black-box point forecasts.</span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>The rest of the paper unfolds as follows. In @sec-theory, we present a unified theoretical framework for analyzing the ACI algorithms based on the online learning paradigm. In @sec-algorithms we provide descriptions of each algorithm along with their known theoretical properties. In @sec-simulations we compare the performance of the algorithms in several simulation studies. @sec-case-study gives a case study based on forecasting influenza in the United States. Finally, @sec-discussion provides a discussion and ideas for future research in this rapidly expanding field.</span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, warning=FALSE, message=FALSE, echo=FALSE}</span></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a><span class="in">library(tidyverse)</span></span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a><span class="in">library(patchwork)</span></span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a><span class="in">library(future)</span></span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a><span class="in">library(furrr)</span></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a><span class="in">library(progressr)</span></span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(echo = TRUE)</span></span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a><span class="in">source("helpers.R")</span></span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a><span class="fu"># Theoretical Framework {#sec-theory}</span></span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>*Notation*: for any integer $N \geq 1$ let $\llbracket N \rrbracket := <span class="sc">\{</span> 1, \dots, N <span class="sc">\}</span>$. Let $\mathbb{I}$ be the indicator function. Let $\nabla f$ denote the gradient (subgradient) of the differentiable (convex) function $f$.</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>We consider an online learning scenario in which we gain access to a sequence of observations $(y_t)_{t \geq 1}$ one at a time (see @cesabianchi2006games for an comprehensive account of online learning theory). Fix $\alpha \in (0, 1)$ to be the target empirical coverage of the prediction intervals. The goal is to output at time $t$ a prediction interval for the unseen observation $y_{t}$, with the prediction interval generated by an _interval construction function_ $\widehat{C}_{t}$. Formally, let $\widehat{C}_t$ be a function that takes as input a parameter $\theta_t \in \mathbb{R}$ and outputs a closed prediction interval $<span class="co">[</span><span class="ot">\ell_t, u_t</span><span class="co">]</span>$. The interval construction function must be nested: if $\theta^\prime &gt; \theta$, then $\widehat{C}_t(\theta) \subseteq \widehat{C}_t(\theta^\prime)$. In words, larger values of $\theta$ imply wider prediction intervals. The interval constructor is indexed by $t$ to emphasize that it may use other information at each time point, such as a point prediction $\hat{\mu}_t \in \mathbb{R}$. We make no restrictions on how this external information is generated.</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>Define $r_t := \inf<span class="sc">\{</span>\theta \in \mathbb{R} : y_t \in \widehat{C}_t(\theta) \}$ to be the _radius_ at time $t$. The radius is the smallest possible $\theta$ such that the prediction interval covers the observation $y_t$. A key assumption for the theoretical analysis of several of the algorithms is that the radii are bounded:</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>**Assumption**: there exists a finite $D &gt; 0$ such that $r_t &lt; D$ for all $t$.</span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>If the outcome space is bounded, then $D$ can be easily chosen to cover the entire space. Next, we describe two existing definitions of interval construction functions.</span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a><span class="fu">## Linear Intervals</span></span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>A simple method for forming the prediction intervals is to use the parameter $\theta_t$ to directly define the width of the interval. Suppose that at each time $t$ we have access to a point prediction $\hat{\mu}_t \in \mathbb{R}$. Then we can form a symmetric prediction interval around the point estimate using</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>  \theta \mapsto \widehat{C}_t(\theta) := <span class="co">[</span><span class="ot">\hat{\mu}_t - \theta, \hat{\mu}_t + \theta</span><span class="co">]</span>.</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a>We refer to this as the _linear interval constructor_. Note that in this case, the radius is simply the absolute residual $r_t = |\hat{\mu}_t - y_t|$.</span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a><span class="fu">## Quantile Intervals</span></span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>The original ACI paper proposed constructing intervals based on the previously observed residuals <span class="co">[</span><span class="ot">@gibbs2021adaptive</span><span class="co">]</span>. Let $S : \mathbb{R}^2 \to \mathbb{R}$ be a function called a _nonconformity score_. A popular choice of nonconformity score is the absolute residual: $(\mu, y) \mapsto  S(\mu, y):= |\mu - y|$.  Let $s_t := S(\hat{\mu}_t, y_t)$ be the nonconformity score of the $t$th-observation. The quantile interval construction function is then given by</span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a>  \widehat{C}_t(\theta_t) := [\hat{\mu}_t - \mathrm{Quantile}(\theta, \{ s_1, \dots, s_{t-1} \}), \hat{\mu}_t + \mathrm{Quantile}(\theta, \{ s_1, \dots, s_{t-1} <span class="sc">\}</span>)]</span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>where $\mathrm{Quantile}(\theta, A)$ denotes the empirical $\theta$-quantile of the elements in the set $A$. Note that $\widehat{C}_t$ is indeed nested in $\theta_t$ because the Quantile function is non-decreasing in $\theta$. Note we define $\widehat{C}_t(1) = \max\{s_1, \dots, s_{t-1}<span class="sc">\}</span>$ rather than $\widehat{C}_t(1) = \infty$ in order to avoid practical problems with trivial prediction intervals <span class="co">[</span><span class="ot">@zaffran2022agaci</span><span class="co">]</span>. Note that we can always choose $D = 1$ to satisfy the outcome boundedness assumption given above.</span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a>We focus on the above definition for the quantile interval construction function which is designed to be symmetric around the point prediction $\hat{\mu}_t$. However, we note it is possible to take a more general definition, such as</span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a>\widehat{C}_t(\theta_t) := \{ y : S(\hat{\mu}_t, y) \leq \mathrm{Quantile(\theta, \{ s_1, \dots, s_{t-1}<span class="sc">\}</span>)} <span class="sc">\}</span></span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a>Such an approach allows for prediction intervals that may not be centered on $\hat{\mu}_t$.</span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a>Our proposed <span class="in">`AdaptiveConformal`</span> package takes the absolute residual as the default nonconformity score, although the user may also specify any custom nonconformity score by supplying it as an <span class="in">`R`</span> function.</span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a><span class="fu">## Online Learning Framework</span></span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a>We now introduce a loss function that defines the quality of a prediction interval with respect to a realized observation. Define the _pinball loss_ $L^\alpha$ as</span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a>(\theta, r) \mapsto L^\alpha(\theta, r) := \begin{cases}</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a>  (1 - \alpha)(\theta - r), &amp; \theta \geq r <span class="sc">\\</span></span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a>  \alpha(r - \theta), &amp; \theta &lt; r.</span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a>The way in which the algorithm gains access to the data and incurs losses is as follows:</span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sequentially, for $t = 1, \dots, T$:</span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Predict radius $\theta_t$ and form prediction interval $\widehat{C}_t(\theta_t)$.</span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Observe true outcome $y_t$ and calculate radius $r_t$.</span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Record $\mathrm{err}_t := \mathbb{I}<span class="co">[</span><span class="ot">y_t \not\in \widehat{C}_t(\theta_t)</span><span class="co">]</span>$.</span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Incur loss $L^\alpha(\theta_t, r_t)$.</span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a>This iterative procedure is at the core of the online learning theoretical framework in which theoretical results have been derived.</span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a><span class="fu">## Assessing ACI algorithms</span></span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a>There are two different perspectives we can take in measuring the quality of an ACI algorithm that generates a sequence $(\theta_t)_{t \in \llbracket T \rrbracket}$. First, we could look at how close the empirical coverage of the generated prediction intervals is to the desired coverage level $\alpha$. Formally, define the empirical coverage as the proportion of observations that fell within the corresponding prediction interval: $\mathrm{EmpCov}(T) := \frac{1}{T} \sum_{t=1}^T (1 - \mathrm{err}_t)$. The coverage error is then given by</span>
<span id="cb18-140"><a href="#cb18-140" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-141"><a href="#cb18-141" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a>  \mathrm{CovErr}(T) := \mathrm{EmpCov}(T) - \alpha.</span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a>The second perspective is to look at how well the algorithm controls the incurred pinball losses. Following the classical framework from the online learning literature, we define the _regret_ as the difference between the cumulative loss yielded by a sequence $(\theta_t)_{t \in \llbracket T \rrbracket}$ versus the cumulative loss of the best possible fixed choice:</span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a>  \mathrm{Reg}(T) := \sum_{t=1}^T L^\alpha(\theta_t, r_t) - \inf_{\theta^* \in \mathbb{R}} \sum_{t=1}^T L^\alpha(\theta^*, r_t).</span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a>In settings of distribution shift, it may not be appropriate to compare the cumulative loss of an algorithm to a fixed competitor. As such, stronger notions of regret have been defined. The _strongly adaptive regret_ is the largest regret over any subperiod of length $m \in \llbracket T \rrbracket$:</span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a>  \mathrm{SAReg}(T, m) := \max_{<span class="co">[</span><span class="ot">\tau, \tau + m - 1</span><span class="co">]</span> \subseteq \llbracket T \rrbracket} \left( \sum_{t=\tau}^{\tau + m - 1} L^{\alpha}(\theta_t, r_t) - \inf_{\theta^* \in \mathbb{R}} \sum_{t=\tau}^{\tau + m - 1} L^\alpha(\theta^*, r_t) \right).</span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a>Both ways of evaluating ACI methods are important because targeting only one or the other can lead to algorithms that yield prediction intervals that are not practically useful. As a simple pathological example of only targeting the coverage error, suppose we wish to generate $\alpha = 50\%$ prediction intervals. We could choose to alternate $\theta$ between 0 and $\infty$, such that $\mathrm{err}_t$ alternates between 0 and 1. The empirical coverage would then trivially converge to the desired level of 50\%. However, the same algorithm would yield infinite regret (see @bhatnagar2023saocp for a more in-depth example of an scenario in which coverage is optimal but the regret grows linearly). On the other hand, an algorithm that has arbitrarily small regret may not yield good empirical coverage. Suppose the observations and point predictions are constant: $y_t = 1$ and $\hat{\mu}_t = 0$ for all $t \geq 1$. Consider a simple class of algorithms that outputs constantly $\theta_t = \theta'$ for some $\theta' &lt; 1$. With the linear interval construction function, the prediction intervals are then $\widehat{C}_t(\theta_t) = <span class="co">[</span><span class="ot">-\theta', \theta'</span><span class="co">]</span>$. The regret is given by $\mathrm{Reg}(T) = 2T\alpha(1-\theta')$, which approaches zero as $\theta'$ approaches 1. The empirical coverage is, however, always zero. In other words, the regret can be arbitrarily close to zero while at the same time the empirical coverage does not approach the desired level.</span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a>These simple examples illustrate that, unfortunately, bounds on the coverage error and bounds on the regret are not in general interchangeable. It is possible, however, to show equivalencies by either (1) making distributional assumptions on the data or (2) using additional information about how the algorithm produces the sequence $(\theta_t)_{t \in \llbracket T \rrbracket}$ <span class="co">[</span><span class="ot">@bhatnagar2023saocp</span><span class="co">]</span>.</span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a>It may also be informative to summarize a set of prediction intervals in ways beyond their coverage error or their regret. A common metric for prediction intervals is the _mean interval width_:</span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a>  \mathrm{MeanWidth}(T) := \frac{1}{T} \sum_{t=1}^T w_t,</span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-166"><a href="#cb18-166" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-167"><a href="#cb18-167" aria-hidden="true" tabindex="-1"></a>where $w_t := u_t - \ell_t$ is the interval width at time $t$.</span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a>Finally, we introduce a metric that is intended to capture pathological behavior that can arise with ACI algorithms where the prediction intervals oscillate between being extremely narrow and extremely wide. Define the _path length_ of prediction intervals generated by an ACI algorithm as</span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a>  \mathrm{PathLength}(T) := \sum_{t=2}^T |w_t - w_{t-1}|.</span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-175"><a href="#cb18-175" aria-hidden="true" tabindex="-1"></a>A high path length indicates that the prediction intervals were variable over time, and a low path length indicates the prediction intervals were stable.</span>
<span id="cb18-176"><a href="#cb18-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-177"><a href="#cb18-177" aria-hidden="true" tabindex="-1"></a><span class="fu"># Algorithms {#sec-algorithms}</span></span>
<span id="cb18-178"><a href="#cb18-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-179"><a href="#cb18-179" aria-hidden="true" tabindex="-1"></a>| Algorithm |</span>
<span id="cb18-180"><a href="#cb18-180" aria-hidden="true" tabindex="-1"></a>| ------------------------------------------------------|</span>
<span id="cb18-181"><a href="#cb18-181" aria-hidden="true" tabindex="-1"></a>| **Adaptive Conformal Inference (ACI)** |</span>
<span id="cb18-182"><a href="#cb18-182" aria-hidden="true" tabindex="-1"></a>| - Tuning parameters: learning rate $\gamma$ |</span>
<span id="cb18-183"><a href="#cb18-183" aria-hidden="true" tabindex="-1"></a>| - Original interval constructor: quantile |</span>
<span id="cb18-184"><a href="#cb18-184" aria-hidden="true" tabindex="-1"></a>| - Theoretical guarantees: coverage error, regret |</span>
<span id="cb18-185"><a href="#cb18-185" aria-hidden="true" tabindex="-1"></a>| - Citation: @gibbs2021adaptive |</span>
<span id="cb18-186"><a href="#cb18-186" aria-hidden="true" tabindex="-1"></a>| **Aggregated Adaptive Conformal Inference (AgACI)** |</span>
<span id="cb18-187"><a href="#cb18-187" aria-hidden="true" tabindex="-1"></a>| - Tuning parameters: candidate learning rates $(\gamma_k)_{1 \leq k \leq K}$ |</span>
<span id="cb18-188"><a href="#cb18-188" aria-hidden="true" tabindex="-1"></a>| - Original interval constructor: quantile |</span>
<span id="cb18-189"><a href="#cb18-189" aria-hidden="true" tabindex="-1"></a>| - Citation: @zaffran2022agaci  |</span>
<span id="cb18-190"><a href="#cb18-190" aria-hidden="true" tabindex="-1"></a>| **Dynamically-tuned Adaptive Conformal Inference (DtACI)** |</span>
<span id="cb18-191"><a href="#cb18-191" aria-hidden="true" tabindex="-1"></a>| - Tuning parameters: candidate learning rates $(\gamma_k)_{1 \leq k \leq K}$ |</span>
<span id="cb18-192"><a href="#cb18-192" aria-hidden="true" tabindex="-1"></a>| - Original interval constructor: quantile |</span>
<span id="cb18-193"><a href="#cb18-193" aria-hidden="true" tabindex="-1"></a>| - Theoretical guarantees: coverage error, strongly adaptive regret, dynamic regret |</span>
<span id="cb18-194"><a href="#cb18-194" aria-hidden="true" tabindex="-1"></a>| - Citation | @gibbs2022faci |</span>
<span id="cb18-195"><a href="#cb18-195" aria-hidden="true" tabindex="-1"></a>| **Scale-Free Online Gradient Descent (SF-OGD)** |</span>
<span id="cb18-196"><a href="#cb18-196" aria-hidden="true" tabindex="-1"></a>| - Tuning parameters: learning rate $\gamma$ or maximum radius $D$ |</span>
<span id="cb18-197"><a href="#cb18-197" aria-hidden="true" tabindex="-1"></a>| - Original interval constructor: linear  |</span>
<span id="cb18-198"><a href="#cb18-198" aria-hidden="true" tabindex="-1"></a>| - Theoretical guarantees: coverage error, anytime regret  |</span>
<span id="cb18-199"><a href="#cb18-199" aria-hidden="true" tabindex="-1"></a>| - Citation: @bhatnagar2023saocp  |</span>
<span id="cb18-200"><a href="#cb18-200" aria-hidden="true" tabindex="-1"></a>| **Strongly Adaptive Online Conformal Prediction (SAOCP)** |</span>
<span id="cb18-201"><a href="#cb18-201" aria-hidden="true" tabindex="-1"></a>| - Tuning parameters: learning rate $\gamma$, lifetime multiplier $g$  |</span>
<span id="cb18-202"><a href="#cb18-202" aria-hidden="true" tabindex="-1"></a>| - Original interval constructor: linear  |</span>
<span id="cb18-203"><a href="#cb18-203" aria-hidden="true" tabindex="-1"></a>| - Theoretical guarantees: coverage error, strongly adaptive regret  |</span>
<span id="cb18-204"><a href="#cb18-204" aria-hidden="true" tabindex="-1"></a>| - Citation: @bhatnagar2023saocp  |</span>
<span id="cb18-205"><a href="#cb18-205" aria-hidden="true" tabindex="-1"></a>: Summary of ACI algorithms. Only the theoretical guarantees discussed in this paper are shown for each algorithm.  {#tbl-aci}</span>
<span id="cb18-206"><a href="#cb18-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-207"><a href="#cb18-207" aria-hidden="true" tabindex="-1"></a>As a simple running example to illustrate each algorithm, we simulate independently $T = 500$ values $y_1, \dots, y_T$ following</span>
<span id="cb18-208"><a href="#cb18-208" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-209"><a href="#cb18-209" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-210"><a href="#cb18-210" aria-hidden="true" tabindex="-1"></a>y_t &amp;\sim N(0, \sigma_t^2), \quad t \in \llbracket T \rrbracket, <span class="sc">\\</span></span>
<span id="cb18-211"><a href="#cb18-211" aria-hidden="true" tabindex="-1"></a>\sigma_t &amp;= \begin{cases}</span>
<span id="cb18-212"><a href="#cb18-212" aria-hidden="true" tabindex="-1"></a>  0.2, &amp;t \leq 250, <span class="sc">\\</span></span>
<span id="cb18-213"><a href="#cb18-213" aria-hidden="true" tabindex="-1"></a>  0.1, &amp;t &gt; 250.</span>
<span id="cb18-214"><a href="#cb18-214" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb18-215"><a href="#cb18-215" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-216"><a href="#cb18-216" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-217"><a href="#cb18-217" aria-hidden="true" tabindex="-1"></a>For demonstration purposes we assume we have access to unbiased predictions $\hat{\mu}_t = 0$ for all $t \in \llbracket T \rrbracket$. Throughout we set the target empirical coverage to $\alpha = 0.8$.</span>
<span id="cb18-218"><a href="#cb18-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-219"><a href="#cb18-219" aria-hidden="true" tabindex="-1"></a><span class="in">```{r example_setup, echo = FALSE}</span></span>
<span id="cb18-220"><a href="#cb18-220" aria-hidden="true" tabindex="-1"></a><span class="in">library(AdaptiveConformal)</span></span>
<span id="cb18-221"><a href="#cb18-221" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(15321)</span></span>
<span id="cb18-222"><a href="#cb18-222" aria-hidden="true" tabindex="-1"></a><span class="in">N &lt;- 5e2</span></span>
<span id="cb18-223"><a href="#cb18-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-224"><a href="#cb18-224" aria-hidden="true" tabindex="-1"></a><span class="in">running_example &lt;- running_example_data(N)</span></span>
<span id="cb18-225"><a href="#cb18-225" aria-hidden="true" tabindex="-1"></a><span class="in">y &lt;- running_example$y</span></span>
<span id="cb18-226"><a href="#cb18-226" aria-hidden="true" tabindex="-1"></a><span class="in">yhat &lt;- running_example$yhat</span></span>
<span id="cb18-227"><a href="#cb18-227" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-228"><a href="#cb18-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-229"><a href="#cb18-229" aria-hidden="true" tabindex="-1"></a><span class="fu">## Adaptive Conformal Inference (ACI)</span></span>
<span id="cb18-230"><a href="#cb18-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-231"><a href="#cb18-231" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb18-232"><a href="#cb18-232" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: algo-aci</span></span>
<span id="cb18-233"><a href="#cb18-233" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.2em"</span></span>
<span id="cb18-234"><a href="#cb18-234" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb18-235"><a href="#cb18-235" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb18-236"><a href="#cb18-236" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number-punc: ":"</span></span>
<span id="cb18-237"><a href="#cb18-237" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb18-238"><a href="#cb18-238" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb18-239"><a href="#cb18-239" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-number: true</span></span>
<span id="cb18-240"><a href="#cb18-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-241"><a href="#cb18-241" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb18-242"><a href="#cb18-242" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Adaptive Conformal Inference}</span></span>
<span id="cb18-243"><a href="#cb18-243" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb18-244"><a href="#cb18-244" aria-hidden="true" tabindex="-1"></a><span class="in">\State \textbf{Input:} starting value $\theta_1$, learning rate $\gamma &gt; 0$.</span></span>
<span id="cb18-245"><a href="#cb18-245" aria-hidden="true" tabindex="-1"></a><span class="in">\For{$t = 1, 2, \dots, T$}</span></span>
<span id="cb18-246"><a href="#cb18-246" aria-hidden="true" tabindex="-1"></a><span class="in">  \State \textbf{Output:} prediction interval $\widehat{C}_t(\theta_t)$.</span></span>
<span id="cb18-247"><a href="#cb18-247" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Observe $y_t$.</span></span>
<span id="cb18-248"><a href="#cb18-248" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Evaluate $\mathrm{err}_t = \mathbb{I}[y_t \not\in \widehat{C}_t(\theta_t)]$.</span></span>
<span id="cb18-249"><a href="#cb18-249" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Update $\theta_{t+1} = \theta_t + \gamma (\mathrm{err}_t - (1 - \alpha))$.</span></span>
<span id="cb18-250"><a href="#cb18-250" aria-hidden="true" tabindex="-1"></a><span class="in">\EndFor</span></span>
<span id="cb18-251"><a href="#cb18-251" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb18-252"><a href="#cb18-252" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb18-253"><a href="#cb18-253" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-254"><a href="#cb18-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-255"><a href="#cb18-255" aria-hidden="true" tabindex="-1"></a>The original ACI algorithm (@gibbs2021adaptive; @algo-aci) adaptively adjusts the width of the prediction intervals in response to the observations. The updating rule for the estimated radius can be derived as an online subgradient descent scheme. The subgradient of the pinball loss function with respect to $\theta$ is given by</span>
<span id="cb18-256"><a href="#cb18-256" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-257"><a href="#cb18-257" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-258"><a href="#cb18-258" aria-hidden="true" tabindex="-1"></a>  \nabla L^\alpha(\theta, r) &amp;= \begin{cases}</span>
<span id="cb18-259"><a href="#cb18-259" aria-hidden="true" tabindex="-1"></a>    <span class="sc">\{</span> -\alpha <span class="sc">\}</span>, &amp;\theta &lt; r, <span class="sc">\\</span></span>
<span id="cb18-260"><a href="#cb18-260" aria-hidden="true" tabindex="-1"></a>    <span class="sc">\{</span> 1 - \alpha <span class="sc">\}</span>, &amp; \theta &gt; r, <span class="sc">\\</span></span>
<span id="cb18-261"><a href="#cb18-261" aria-hidden="true" tabindex="-1"></a>    <span class="co">[</span><span class="ot">-\alpha, 1 - \alpha</span><span class="co">]</span>, &amp;\theta = r</span>
<span id="cb18-262"><a href="#cb18-262" aria-hidden="true" tabindex="-1"></a>  \end{cases} <span class="sc">\\</span></span>
<span id="cb18-263"><a href="#cb18-263" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-264"><a href="#cb18-264" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-265"><a href="#cb18-265" aria-hidden="true" tabindex="-1"></a>It follows that, for all $\theta_t \in \mathbb{R}$ and $r_t \in \mathbb{R}$,</span>
<span id="cb18-266"><a href="#cb18-266" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-267"><a href="#cb18-267" aria-hidden="true" tabindex="-1"></a>1 - \alpha - \mathrm{err}_t \in \nabla L^\alpha(\theta_t, r_t).</span>
<span id="cb18-268"><a href="#cb18-268" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-269"><a href="#cb18-269" aria-hidden="true" tabindex="-1"></a>This leads to the following update rule for $\theta$ based on subgradient descent:</span>
<span id="cb18-270"><a href="#cb18-270" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-271"><a href="#cb18-271" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-272"><a href="#cb18-272" aria-hidden="true" tabindex="-1"></a>  \theta_{t+1} = \theta_{t} + \gamma (\mathrm{err}_t - (1 - \alpha)),</span>
<span id="cb18-273"><a href="#cb18-273" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-274"><a href="#cb18-274" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-275"><a href="#cb18-275" aria-hidden="true" tabindex="-1"></a>where $\gamma &gt; 0$ is a user-specified learning rate. For intuition, note that if $y_t$ fell outside of the prediction interval at time $t$ ($\mathrm{err}_t = 1$) then the next interval is widened ($\theta_{t+1} = \theta_t + \gamma \alpha$). On the contrary, if $y_t$ fell within the interval ($\mathrm{err}_t = 0$) then the next interval is shortened ($\theta_{t+1} = \theta_t - \gamma(1 - \alpha)$). The learning rate $\gamma$ controls how fast the width of the prediction intervals changes in response to the data.</span>
<span id="cb18-276"><a href="#cb18-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-277"><a href="#cb18-277" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theoretical Guarantees</span></span>
<span id="cb18-278"><a href="#cb18-278" aria-hidden="true" tabindex="-1"></a>With the choice of the quantile interval structure, the ACI algorithm has the following finite sample bound on the coverage error  (@gibbs2021adaptive; Proposition 4.1). For all $\gamma &gt; 0$ (and so long as $\gamma$ does not depend on $T$),</span>
<span id="cb18-279"><a href="#cb18-279" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-280"><a href="#cb18-280" aria-hidden="true" tabindex="-1"></a>|\mathrm{CovErr}(T)| \leq \frac{\max<span class="sc">\{</span>\theta_1, 1 - \theta_1<span class="sc">\}</span> + \gamma}{\gamma T}.</span>
<span id="cb18-281"><a href="#cb18-281" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-282"><a href="#cb18-282" aria-hidden="true" tabindex="-1"></a>This result was originally shown for ACI with the choice of the quantile interval constructor, although it can also be extended to other interval constructors <span class="co">[</span><span class="ot">@bhatnagar2023saocp, @feldman2023achieving</span><span class="co">]</span>. More generally, the algorithm has the following coverage error bound in terms of the radius bound $D$ <span class="co">[</span><span class="ot">@bhatnagar2023saocp</span><span class="co">]</span>:</span>
<span id="cb18-283"><a href="#cb18-283" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-284"><a href="#cb18-284" aria-hidden="true" tabindex="-1"></a>|\mathrm{CovErr}(T)| \leq \frac{D + \gamma}{\gamma T}.</span>
<span id="cb18-285"><a href="#cb18-285" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-286"><a href="#cb18-286" aria-hidden="true" tabindex="-1"></a>In addition, standard results for online subgradient descent yield the following regret bound with the use of the linear interval constructor, assuming that the true radii are bounded by $D$:</span>
<span id="cb18-287"><a href="#cb18-287" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-288"><a href="#cb18-288" aria-hidden="true" tabindex="-1"></a>\mathrm{Reg}(T) \leq \mathcal{O}(D^2 / \gamma + \gamma T) \leq \mathcal{O}(D \sqrt{T}),</span>
<span id="cb18-289"><a href="#cb18-289" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-290"><a href="#cb18-290" aria-hidden="true" tabindex="-1"></a>where the second inequality follows if the optimal choice (with respect to long-term regret) of $\gamma = D/\sqrt{T}$ is used <span class="co">[</span><span class="ot">@bhatnagar2023saocp</span><span class="co">]</span>. Taken together, these theoretical results imply that while the coverage error is guaranteed to converge to zero for any choice of $\gamma$, achieving sublinear regret requires choosing $\gamma$ more carefully. This highlights the importance of both ways of assessing ACI algorithms: if we only focused on controlling the coverage error, we might not achieve optimal control of regret, leading to intervals that are not practically useful.</span>
<span id="cb18-291"><a href="#cb18-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-292"><a href="#cb18-292" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning Parameters</span></span>
<span id="cb18-293"><a href="#cb18-293" aria-hidden="true" tabindex="-1"></a>Therefore, the main tuning parameter is the learning rate $\gamma$. The theoretical bounds on the coverage error suggest setting a large $\gamma$ such that the coverage error decays quickly in $T$; however, in practice and setting $\gamma$ too large will lead to intervals with large oscillations as seen in @fig-aci. This is quantified in the path length, which increases significantly as $\gamma$ increases, even though the empirical coverage remains near the desired value of 80\%.  On the other hand, setting $\gamma$ too small will lead to intervals that do not adapt fast enough to distribution shifts. Thus, choosing a good value for $\gamma$ is essential. However, the optimal choice $\gamma = D / \sqrt{T}$ cannot be used directly in practice unless the time series length $T$ is fixed in advance, or the so called "doubling trick" is used to relax the need to know $T$ in advance (@cesabianchi2006games; Section 2.3).</span>
<span id="cb18-294"><a href="#cb18-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-295"><a href="#cb18-295" aria-hidden="true" tabindex="-1"></a>The theoretical results guaranteeing the performance of the ACI algorithm do not depend on the choice of starting value $\theta_1$, and thus in practice any value can be chosen. Indeed, the effect of the choice of $\theta_1$ decays over time as a function of the chosen learning rate. In practice, substantive prior information can be used to pick a reasonable starting value. By default, the <span class="in">`AdaptiveConformal`</span> package sets $\theta_1 = \alpha$ when the quantile interval predictor is used, and $\theta_1 = 0$ otherwise, although in both cases the user can supply their own starting value. The behavior of the early prediction intervals in the examples (@fig-aci) is driven by the small number of residuals available, which makes the output of the quantile interval constructor sensitive to small changes in $\theta$. In practice, a warm-up period can be used before starting to produce prediction intervals so that the quantiles of the residuals are more stable.</span>
<span id="cb18-296"><a href="#cb18-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-297"><a href="#cb18-297" aria-hidden="true" tabindex="-1"></a><span class="in">```{r aci_example_plot, echo = FALSE}</span></span>
<span id="cb18-298"><a href="#cb18-298" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-aci</span></span>
<span id="cb18-299"><a href="#cb18-299" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 4.5</span></span>
<span id="cb18-300"><a href="#cb18-300" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Example 80% prediction intervals from the ACI algorithm for different choices of learning rate $\\gamma$ and with $\\theta_1 = 0.8$. Blue and red points are observations that fell inside and outside the prediction intervals, respectively."</span></span>
<span id="cb18-301"><a href="#cb18-301" aria-hidden="true" tabindex="-1"></a><span class="in">alpha &lt;- 0.8</span></span>
<span id="cb18-302"><a href="#cb18-302" aria-hidden="true" tabindex="-1"></a><span class="in">gamma_grid &lt;- c(0.016, 0.032, 0.064, 0.128)</span></span>
<span id="cb18-303"><a href="#cb18-303" aria-hidden="true" tabindex="-1"></a><span class="in">results &lt;- list(</span></span>
<span id="cb18-304"><a href="#cb18-304" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "ACI", parameters = list(interval_constructor = "conformal", theta0 = alpha, gamma = gamma_grid[1])),</span></span>
<span id="cb18-305"><a href="#cb18-305" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "ACI", parameters = list(interval_constructor = "conformal", theta0 = alpha, gamma = gamma_grid[2])),</span></span>
<span id="cb18-306"><a href="#cb18-306" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "ACI", parameters = list(interval_constructor = "conformal", theta0 = alpha, gamma = gamma_grid[3])),</span></span>
<span id="cb18-307"><a href="#cb18-307" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "ACI", parameters = list(interval_constructor = "conformal", theta0 = alpha, gamma = gamma_grid[4]))</span></span>
<span id="cb18-308"><a href="#cb18-308" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb18-309"><a href="#cb18-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-310"><a href="#cb18-310" aria-hidden="true" tabindex="-1"></a><span class="in">coverage    &lt;- format_coverage(extract_metric(results, "coverage"))</span></span>
<span id="cb18-311"><a href="#cb18-311" aria-hidden="true" tabindex="-1"></a><span class="in">path_length &lt;- format_path_length(extract_metric(results, "path_length"))</span></span>
<span id="cb18-312"><a href="#cb18-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-313"><a href="#cb18-313" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(2, 2), mar = c(3, 3, 2, 1))</span></span>
<span id="cb18-314"><a href="#cb18-314" aria-hidden="true" tabindex="-1"></a><span class="in">for(i in 1:4) {</span></span>
<span id="cb18-315"><a href="#cb18-315" aria-hidden="true" tabindex="-1"></a><span class="in">  plot(results[[i]], legend = FALSE, predictions = FALSE, cex = 0.5, main = bquote(gamma==.(results[[i]]$parameters$gamma)), ylim = c(-0.9, 0.8))</span></span>
<span id="cb18-316"><a href="#cb18-316" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -0.75, labels = bquote(EmpCov == .(coverage[[i]]) ), pos = 4)</span></span>
<span id="cb18-317"><a href="#cb18-317" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -0.9, labels = bquote(PathLength == .(path_length[[i]]) ), pos = 4)</span></span>
<span id="cb18-318"><a href="#cb18-318" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-319"><a href="#cb18-319" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(1, 1), mar = c(5.1, 4.1, 4.1, 2.1))</span></span>
<span id="cb18-320"><a href="#cb18-320" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-321"><a href="#cb18-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-322"><a href="#cb18-322" aria-hidden="true" tabindex="-1"></a><span class="fu">## Aggregated Adaptive Conformal Inference (AgACI)</span></span>
<span id="cb18-323"><a href="#cb18-323" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb18-324"><a href="#cb18-324" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: algo-agaci</span></span>
<span id="cb18-325"><a href="#cb18-325" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.2em"</span></span>
<span id="cb18-326"><a href="#cb18-326" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb18-327"><a href="#cb18-327" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb18-328"><a href="#cb18-328" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number-punc: ":"</span></span>
<span id="cb18-329"><a href="#cb18-329" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb18-330"><a href="#cb18-330" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb18-331"><a href="#cb18-331" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-number: true</span></span>
<span id="cb18-332"><a href="#cb18-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-333"><a href="#cb18-333" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb18-334"><a href="#cb18-334" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Aggregated Adaptive Conformal Inference}</span></span>
<span id="cb18-335"><a href="#cb18-335" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb18-336"><a href="#cb18-336" aria-hidden="true" tabindex="-1"></a><span class="in">  \State \textbf{Input:} candidate learning rates $(\gamma_k)_{1 \leq k \leq K }$, starting value $\theta_1$.</span></span>
<span id="cb18-337"><a href="#cb18-337" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Initialize lower and upper BOA algorithms $\mathcal{B}^\ell := \texttt{BOA}(\alpha \leftarrow (1 - \alpha) / 2)$ and $\mathcal{B}^u := \texttt{BOA}(\alpha \leftarrow (1 - (1 - \alpha)/2))$.</span></span>
<span id="cb18-338"><a href="#cb18-338" aria-hidden="true" tabindex="-1"></a><span class="in">  \For{$k = 1, \dots, K$}</span></span>
<span id="cb18-339"><a href="#cb18-339" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Initialize ACI $\mathcal{A}_k = \texttt{ACI}(\alpha \leftarrow \alpha, \gamma \leftarrow \gamma_k, \theta_1 \leftarrow \theta_1)$.</span></span>
<span id="cb18-340"><a href="#cb18-340" aria-hidden="true" tabindex="-1"></a><span class="in">  \EndFor</span></span>
<span id="cb18-341"><a href="#cb18-341" aria-hidden="true" tabindex="-1"></a><span class="in">  \For{$t = 1, 2, \dots, T$}</span></span>
<span id="cb18-342"><a href="#cb18-342" aria-hidden="true" tabindex="-1"></a><span class="in">    \For{$k = 1, \dots, K$}</span></span>
<span id="cb18-343"><a href="#cb18-343" aria-hidden="true" tabindex="-1"></a><span class="in">      \State Retrieve candidate prediction interval $[\ell^k_{t}, u^k_{t}]$ from $\mathcal{A}_k$.</span></span>
<span id="cb18-344"><a href="#cb18-344" aria-hidden="true" tabindex="-1"></a><span class="in">    \EndFor</span></span>
<span id="cb18-345"><a href="#cb18-345" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Compute aggregated lower bound $\tilde{\ell}_t := \mathcal{B}^\ell((\ell^k_t : k \in \{ 1, \dots, K \}))$.</span></span>
<span id="cb18-346"><a href="#cb18-346" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Compute aggregated upper bound $\tilde{u}_t := \mathcal{B}^u((u^k_t : k \in \{ 1, \dots, K \}))$.</span></span>
<span id="cb18-347"><a href="#cb18-347" aria-hidden="true" tabindex="-1"></a><span class="in">    \State \textbf{Output:} prediction interval $[\tilde{\ell}_t, \tilde{u}_t]$.</span></span>
<span id="cb18-348"><a href="#cb18-348" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Observe $y_t$.</span></span>
<span id="cb18-349"><a href="#cb18-349" aria-hidden="true" tabindex="-1"></a><span class="in">    \For{$k = 1, \dots, K$}</span></span>
<span id="cb18-350"><a href="#cb18-350" aria-hidden="true" tabindex="-1"></a><span class="in">      \State Update $\mathcal{A}_k$ with observation $y_t$.</span></span>
<span id="cb18-351"><a href="#cb18-351" aria-hidden="true" tabindex="-1"></a><span class="in">    \EndFor</span></span>
<span id="cb18-352"><a href="#cb18-352" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Update $\mathcal{B}^\ell$ with observed outcome $y_t$.</span></span>
<span id="cb18-353"><a href="#cb18-353" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Update $\mathcal{B}^u$ with observed outcome $y_t$.</span></span>
<span id="cb18-354"><a href="#cb18-354" aria-hidden="true" tabindex="-1"></a><span class="in">  \EndFor</span></span>
<span id="cb18-355"><a href="#cb18-355" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb18-356"><a href="#cb18-356" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb18-357"><a href="#cb18-357" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-358"><a href="#cb18-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-359"><a href="#cb18-359" aria-hidden="true" tabindex="-1"></a>The Aggregated ACI (AgACI; @algo-agaci) algorithm solves the problem of choosing a learning rate for ACI by running multiple copies of the algorithm with different learning rates, and then separately combining the lower and upper interval bounds using an online aggregation of experts algorithm <span class="co">[</span><span class="ot">@zaffran2022agaci</span><span class="co">]</span>. That is, one aggregation algorithm seeks to estimate the lower $(1-\alpha)/2$ quantile, and the other seeks to estimate the upper $1 - (1 - \alpha) / 2$ quantile. @zaffran2022agaci experimented with multiple online aggregation algorithms, and found that they yielded similar results. Thus, we follow their lead in using the Bernstein Online Aggregation (BOA) algorithm as implemented in the <span class="in">`opera`</span> <span class="in">`R`</span> package <span class="co">[</span><span class="ot">@wintenberger2017boa; @opera2023</span><span class="co">]</span>. BOA is an online algorithm that forms predictions for the lower (or upper) prediction interval bound as a weighted mean of the candidate ACI prediction interval lower (upper) bound, where the weights are determined by each candidate's past performance with respect to the quantile loss. As a consequence, the prediction intervals generated by AgACI are not necessarily symmetric around the point prediction, as the weights for the lower and upper bounds are separate.</span>
<span id="cb18-360"><a href="#cb18-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-361"><a href="#cb18-361" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theoretical Gaurantees</span></span>
<span id="cb18-362"><a href="#cb18-362" aria-hidden="true" tabindex="-1"></a>AgACI departs from our main theoretical framework in that it does not yield a sequence $(\theta_t)_{t \in \llbracket T \rrbracket}$ whose elements yield prediction intervals via a set construction function $\widehat{C}_t$. Rather, the upper and lower interval bounds from a set of candidate ACI algorithms are aggregated separately. Thus, theoretical results such as regret bounds similar to those for the other algorithms are not available. It would be possible, however, to establish regret bounds for the pinball loss applied separately to the lower and upper bounds of the prediction intervals. It is unclear, however, how to convert such regret bounds into a coverage bound.</span>
<span id="cb18-363"><a href="#cb18-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-364"><a href="#cb18-364" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning Parameters {#sec-agaci-tuning}</span></span>
<span id="cb18-365"><a href="#cb18-365" aria-hidden="true" tabindex="-1"></a>The main tuning parameter for AgACI is the set of candidate learning rates. Beyond necessitating additional computational time, there is no drawback to having a large grid. As a default, <span class="in">`AdaptiveConformal`</span> uses learning rates $\gamma \in <span class="sc">\{</span> 0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128 <span class="sc">\}</span>$. As a basic check, we can look at the weights assigned to each of the learning rates. If large weights are given to the smallest (largest) learning rates, it is a sign that smaller (or larger) learning rates may perform well. In addition each of the candidate ACI algorithms requires a starting value, which can be set to any value as discussed in the ACI section. @fig-agaci illustrates AgACI applied to the running example with two sets of learning grids. The first grid is $\gamma = <span class="sc">\{</span> 0.032, 0.064, 0.128, 0.256 <span class="sc">\}</span>$, and the second grid includes the additional values $<span class="sc">\{</span> 0.008, 0.016 <span class="sc">\}</span>$. For the first grid, we can see that for the lower bound AgACI assigns high weight to the lowest learning rate ($\gamma = 0.032$). The second grid yields weights that are less concentrated on a single learning rate, and the output prediction intervals are smoother.</span>
<span id="cb18-366"><a href="#cb18-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-367"><a href="#cb18-367" aria-hidden="true" tabindex="-1"></a><span class="in">```{r agaci_example_plot, echo = FALSE}</span></span>
<span id="cb18-368"><a href="#cb18-368" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-agaci</span></span>
<span id="cb18-369"><a href="#cb18-369" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 4.5</span></span>
<span id="cb18-370"><a href="#cb18-370" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Example 80% prediction intervals from the AgACI algorithm with starting values $\\theta_1 = 0.8$ and two different learning rate grids. In the left column, blue and red points are observations that fell inside and outside the prediction intervals, respectively."</span></span>
<span id="cb18-371"><a href="#cb18-371" aria-hidden="true" tabindex="-1"></a><span class="in">grid1 &lt;- 2^(seq(5, 8, 1)) / 1e3</span></span>
<span id="cb18-372"><a href="#cb18-372" aria-hidden="true" tabindex="-1"></a><span class="in">grid2 &lt;- 2^(seq(1, 8, 1)) / 1e3</span></span>
<span id="cb18-373"><a href="#cb18-373" aria-hidden="true" tabindex="-1"></a><span class="in">results &lt;- list(</span></span>
<span id="cb18-374"><a href="#cb18-374" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "AgACI", parameters = list(interval_constructor = "conformal", gamma_grid = grid1, theta0 = 0.8)),</span></span>
<span id="cb18-375"><a href="#cb18-375" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "AgACI", parameters = list(interval_constructor = "conformal", gamma_grid = grid2, theta0 = 0.8))</span></span>
<span id="cb18-376"><a href="#cb18-376" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb18-377"><a href="#cb18-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-378"><a href="#cb18-378" aria-hidden="true" tabindex="-1"></a><span class="in">coverage    &lt;- format_coverage(extract_metric(results, "coverage"))</span></span>
<span id="cb18-379"><a href="#cb18-379" aria-hidden="true" tabindex="-1"></a><span class="in">path_length &lt;- format_path_length(extract_metric(results, "path_length"))</span></span>
<span id="cb18-380"><a href="#cb18-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-381"><a href="#cb18-381" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(2, 2), mar = c(4, 3, 2, 1))</span></span>
<span id="cb18-382"><a href="#cb18-382" aria-hidden="true" tabindex="-1"></a><span class="in">for(i in 1:2) {</span></span>
<span id="cb18-383"><a href="#cb18-383" aria-hidden="true" tabindex="-1"></a><span class="in">  plot(results[[i]], legend = FALSE, predictions = FALSE, cex = 0.5, main = paste("Grid", i), ylim = c(-0.9, 0.8))</span></span>
<span id="cb18-384"><a href="#cb18-384" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -0.75, labels = bquote(EmpCov == .(coverage[[i]]) ), pos = 4)</span></span>
<span id="cb18-385"><a href="#cb18-385" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -0.9, labels = bquote(PathLength == .(path_length[[i]]) ), pos = 4)</span></span>
<span id="cb18-386"><a href="#cb18-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-387"><a href="#cb18-387" aria-hidden="true" tabindex="-1"></a><span class="in">  plot_agaci_weights(results[[i]], main = "Final Aggregation Weights", legend = "topright", ylim = c(0, 1))</span></span>
<span id="cb18-388"><a href="#cb18-388" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-389"><a href="#cb18-389" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(1, 1), mar = c(5.1, 4.1, 4.1, 2.1))</span></span>
<span id="cb18-390"><a href="#cb18-390" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-391"><a href="#cb18-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-392"><a href="#cb18-392" aria-hidden="true" tabindex="-1"></a><span class="in">```{r agaci_example_plot2, echo = FALSE}</span></span>
<span id="cb18-393"><a href="#cb18-393" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-agaci2</span></span>
<span id="cb18-394"><a href="#cb18-394" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 3</span></span>
<span id="cb18-395"><a href="#cb18-395" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Weights assigned to each of the candidate ACI algorithms by AgACI at the final timepoint."</span></span>
<span id="cb18-396"><a href="#cb18-396" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-397"><a href="#cb18-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-398"><a href="#cb18-398" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dynamically-tuned Adaptive Conformal Inference (DtACI)</span></span>
<span id="cb18-399"><a href="#cb18-399" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb18-400"><a href="#cb18-400" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: algo-faci</span></span>
<span id="cb18-401"><a href="#cb18-401" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.2em"</span></span>
<span id="cb18-402"><a href="#cb18-402" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb18-403"><a href="#cb18-403" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb18-404"><a href="#cb18-404" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number-punc: ":"</span></span>
<span id="cb18-405"><a href="#cb18-405" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb18-406"><a href="#cb18-406" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb18-407"><a href="#cb18-407" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-number: true</span></span>
<span id="cb18-408"><a href="#cb18-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-409"><a href="#cb18-409" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb18-410"><a href="#cb18-410" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Dynamically-tuned Adaptive Conformal Inference}</span></span>
<span id="cb18-411"><a href="#cb18-411" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb18-412"><a href="#cb18-412" aria-hidden="true" tabindex="-1"></a><span class="in">\State \textbf{Input:} starting value $\theta_1$, candidate learning rates $(\gamma_k)_{1 \leq k \leq K }$, parameters $\sigma, \eta$.</span></span>
<span id="cb18-413"><a href="#cb18-413" aria-hidden="true" tabindex="-1"></a><span class="in">\For{$k = 1, \dots, K$}</span></span>
<span id="cb18-414"><a href="#cb18-414" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Initialize expert $\mathcal{A}_k = \texttt{ACI}(\alpha \leftarrow \alpha, \gamma \leftarrow \gamma_k, \theta_1 \leftarrow \theta_1)$.</span></span>
<span id="cb18-415"><a href="#cb18-415" aria-hidden="true" tabindex="-1"></a><span class="in">\EndFor</span></span>
<span id="cb18-416"><a href="#cb18-416" aria-hidden="true" tabindex="-1"></a><span class="in">\For{$t = 1, 2, \dots, T$}</span></span>
<span id="cb18-417"><a href="#cb18-417" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Define $p_t^k := p_t^k / \sum_{i=1}^K p_t^i$, for all $1 \leq k \leq K$.</span></span>
<span id="cb18-418"><a href="#cb18-418" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Set $\theta_t = \sum_{k=1}^K \theta_t^k p_t^k$.</span></span>
<span id="cb18-419"><a href="#cb18-419" aria-hidden="true" tabindex="-1"></a><span class="in">  \State \textbf{Output:} prediction interval $\widehat{C}_t(\theta_t)$.</span></span>
<span id="cb18-420"><a href="#cb18-420" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Observe $y_t$ and compute $r_t$.</span></span>
<span id="cb18-421"><a href="#cb18-421" aria-hidden="true" tabindex="-1"></a><span class="in">  \State $\bar{w}_{t}^k \gets p_t^k \exp(-\eta L^\alpha(\theta_t^k, r_t))$, for all $1 \leq k \leq K$.</span></span>
<span id="cb18-422"><a href="#cb18-422" aria-hidden="true" tabindex="-1"></a><span class="in">  \State $\bar{W}_t \gets \sum_{i=1}^K \bar{w}_t^i$.</span></span>
<span id="cb18-423"><a href="#cb18-423" aria-hidden="true" tabindex="-1"></a><span class="in">  \State $p_{t+1}^k \gets (1 - \sigma) \bar{w}_t^k + \bar{W}_t \sigma / K$.</span></span>
<span id="cb18-424"><a href="#cb18-424" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Set $\mathrm{err}_t := \mathbb{I}[y_t \not\in \widehat{C}_t(\theta_t)]$.</span></span>
<span id="cb18-425"><a href="#cb18-425" aria-hidden="true" tabindex="-1"></a><span class="in">  \For{$k = 1, \dots, K$}</span></span>
<span id="cb18-426"><a href="#cb18-426" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Update ACI $\mathcal{A}_k$ with $y_t$ and obtain $\theta_{t+1}^k$.</span></span>
<span id="cb18-427"><a href="#cb18-427" aria-hidden="true" tabindex="-1"></a><span class="in">  \EndFor</span></span>
<span id="cb18-428"><a href="#cb18-428" aria-hidden="true" tabindex="-1"></a><span class="in">\EndFor</span></span>
<span id="cb18-429"><a href="#cb18-429" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb18-430"><a href="#cb18-430" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb18-431"><a href="#cb18-431" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-432"><a href="#cb18-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-433"><a href="#cb18-433" aria-hidden="true" tabindex="-1"></a>The Dynamically-tuned Adaptive Conformal Inference (DtACI; @algo-faci) algorithm was developed by the authors of the original ACI algorithm in part to address the issue of how to choose the learning rate parameter $\gamma$. In this respect the goal of the algorithm is similar to that of AgACI, although it is achieved slightly differently. DtACI also aggregates predictions from multiple copies of ACI run with different learning rates, but differs in that it directly aggregates the estimated radii emitted from each algorithm based on their pinball loss <span class="co">[</span><span class="ot">@gibbs2022faci</span><span class="co">]</span> using an exponential reweighting scheme <span class="co">[</span><span class="ot">@gradu2022adaptive</span><span class="co">]</span>. As opposed to AgACI, this construction allows for more straightforward development of theoretical guarantees on the algorithm's performance, because the upper and lower bounds of the intervals are not aggregated separately.</span>
<span id="cb18-434"><a href="#cb18-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-435"><a href="#cb18-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-436"><a href="#cb18-436" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theoretical Guarantees</span></span>
<span id="cb18-437"><a href="#cb18-437" aria-hidden="true" tabindex="-1"></a>DtACI was originally proposed with the choice of the quantile interval constructor. DtACI has the following strongly-adaptive regret bound <span class="co">[</span><span class="ot">@bhatnagar2023saocp</span><span class="co">]</span>: for all $\eta &gt; 0$ and subperiod lengths $m$,</span>
<span id="cb18-438"><a href="#cb18-438" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-439"><a href="#cb18-439" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-440"><a href="#cb18-440" aria-hidden="true" tabindex="-1"></a>  \mathrm{SAReg}(T, m) \leq \widetilde{\mathcal{O}}(D^2 / \eta + \eta m).</span>
<span id="cb18-441"><a href="#cb18-441" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-442"><a href="#cb18-442" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-443"><a href="#cb18-443" aria-hidden="true" tabindex="-1"></a>If $m$ is fixed a-priori, then choosing $\eta = D/\sqrt{m}$ yields a strongly adaptive regret bound of order $\widetilde{\mathcal{O}}(D \sqrt{m})$ (for a single choice of $m$). Practically, this result implies that, if we know in advance the time length for which we would like to control the regret, it is possible to choose an optimal tuning parameter value. However, we cannot control the regret simultaneously for all possible time lengths.</span>
<span id="cb18-444"><a href="#cb18-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-445"><a href="#cb18-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-446"><a href="#cb18-446" aria-hidden="true" tabindex="-1"></a>To establish a bound on the coverage error, the authors investigated a slightly modified version of DtACI in which $\theta_t$ is chosen randomly from the candidate $\theta_{t_k}$ with weights given by $p_{t,k}$, instead of taking a weighted average. This is a common trick used in the literature as it facilitates theoretical analysis. In practice, the authors comment that this randomized version of DtACI and the deterministic version lead to very similar results. The coverage error result also assumes that the hyperparameters can change over time: that is, we have $t$-specific $\eta_{t}$ and $\sigma_t$, rather than fixed $\eta$ and $\sigma$. The coverage error then has the following bound (@gibbs2022faci; Theorem 3.2), where $\gamma_{\min}$ and $\gamma_{\max}$ are the smallest and largest learning rates in the grid, respectively:</span>
<span id="cb18-447"><a href="#cb18-447" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-448"><a href="#cb18-448" aria-hidden="true" tabindex="-1"></a>|\mathrm{CovErr}(T)| \leq \frac{1 + 2\gamma_{\max}}{T \gamma_{\min}} + \frac{(1 + 2\gamma_{\max})^2}{\gamma_{\min}}  \frac{1}{T}\sum_{t=1}^T \eta_t \exp(\eta_t(1 + 2\gamma_{\max})) + 2 \frac{1+\gamma_{\max}}{\gamma_{\min}} \frac{1}{T} \sum_{t=1}^T \sigma_t.</span>
<span id="cb18-449"><a href="#cb18-449" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-450"><a href="#cb18-450" aria-hidden="true" tabindex="-1"></a>Thus, if $\eta_t$ and $\sigma_t$ both converge to zero as $t \to \infty$, then the coverage error will also converge to zero. In addition, under mild distributional assumptions the authors provide a type of short-term coverage error bound for arbitrary time spans, for which we refer to <span class="co">[</span><span class="ot">@gibbs2022faci</span><span class="co">]</span>.</span>
<span id="cb18-451"><a href="#cb18-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-452"><a href="#cb18-452" aria-hidden="true" tabindex="-1"></a>We note one additional result established by @gibbs2022faci (their Theorem 3.1) on a slightly different dynamic regret bound in terms of the pinball loss, as it informs the choice of tuning parameters. Let $\gamma_{\mathrm{max}} = \max_{1 \leq k \leq K} \gamma_k$ be the largest learning rate in the grid and assume that $\gamma_1 &lt; \gamma_2 &lt; \cdots &lt; \gamma_K$ with $\gamma_{k+1}/\gamma \leq 2$ for all $1 \leq k &lt; K$. Then, for any interval $I = <span class="co">[</span><span class="ot">r, s</span><span class="co">]</span> \subseteq \llbracket T \rrbracket$ and any sequence $\theta_r^*, \dots, \theta_s^*$, under the assumption that $\gamma_k \geq \sqrt{1 + 1 / |I|}$,</span>
<span id="cb18-453"><a href="#cb18-453" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-454"><a href="#cb18-454" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-455"><a href="#cb18-455" aria-hidden="true" tabindex="-1"></a>  \frac{1}{|I|} \sum_{t=r}^s \mathbb{E}<span class="co">[</span><span class="ot">L^\alpha(\theta_t, r_t)</span><span class="co">]</span> - \frac{1}{|I|} \sum_{t=r}^s L^\alpha(\theta_t, \theta_t^*) \leq&amp; \frac{\log(k / \sigma) + 2\sigma|I|}{\eta |I|} + \frac{\eta}{|I|} \sum_{t=r}^s \mathbb{E}<span class="co">[</span><span class="ot">L^\alpha(\theta_t, r_t)^2</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb18-456"><a href="#cb18-456" aria-hidden="true" tabindex="-1"></a>  &amp;+ 2\sqrt{3}(1 + \gamma_{\mathrm{max}})^2 \max\left<span class="sc">\{</span> \sqrt{\frac{\sum_{t=r+1}^s |\theta_t^* - \theta_{t-1}^*| + 1}{|I|}}, \gamma_1 \right<span class="sc">\}</span>,</span>
<span id="cb18-457"><a href="#cb18-457" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-458"><a href="#cb18-458" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-459"><a href="#cb18-459" aria-hidden="true" tabindex="-1"></a>where the expectation is over the randomness in the randomized version of the algorithm.  Here the time interval $I$ (with length $|I|$) is comparable to the time period length $m$ for the strongly adaptive regret. The parameter $|I|$, the time interval of interest for which we would like to control, can be chosen arbitrarily. This dynamic regret bound can be converted to a strongly adaptive regret bound by choosing $\theta^*_t$ to be constant.</span>
<span id="cb18-460"><a href="#cb18-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-461"><a href="#cb18-461" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning parameters</span></span>
<span id="cb18-462"><a href="#cb18-462" aria-hidden="true" tabindex="-1"></a>The recommended settings for the tuning parameters depend on choosing a time interval length $|I|$ for which we would like to control the pinball loss. The choice of $|I|$ can be chosen arbitrarily.</span>
<span id="cb18-463"><a href="#cb18-463" aria-hidden="true" tabindex="-1"></a>For the tuning parameter $\sigma$, the authors suggest the optimal choice (with respect to the dynamic regret) $\sigma = 1 / (2 |I|)$. Choosing $\eta$ is more difficult. The authors suggest the following choice for $\eta$, which they show is optimal if there is in fact no distribution shift:</span>
<span id="cb18-464"><a href="#cb18-464" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-465"><a href="#cb18-465" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-466"><a href="#cb18-466" aria-hidden="true" tabindex="-1"></a>  \eta = \sqrt{\frac{3}{|I|}} \sqrt{\frac{\log(K \cdot |I|) + 2}{(\alpha)^2 (1 - \alpha)^3 + (1-\alpha)^2 \alpha^3 }}</span>
<span id="cb18-467"><a href="#cb18-467" aria-hidden="true" tabindex="-1"></a>\end{aligned}.</span>
<span id="cb18-468"><a href="#cb18-468" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-469"><a href="#cb18-469" aria-hidden="true" tabindex="-1"></a>Note that this choice is optimal only for the quantile interval constructor, for which $\theta_t$ is a quantile of previous nonconformity scores. As an alternative, the authors point out that $\eta$ can be learned in an online fashion using the update rule</span>
<span id="cb18-470"><a href="#cb18-470" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-471"><a href="#cb18-471" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-472"><a href="#cb18-472" aria-hidden="true" tabindex="-1"></a>  \eta_t := \sqrt{\frac{\log(|I| K) + 2}{\sum_{s=t-|I|}^{t-1} L^\alpha(\theta_s, r_s)}}.</span>
<span id="cb18-473"><a href="#cb18-473" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-474"><a href="#cb18-474" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-475"><a href="#cb18-475" aria-hidden="true" tabindex="-1"></a>Both ways of choosing $\eta$ led to very similar results in the original author's empirical studies. In our proposed <span class="in">`AdaptiveConformal`</span> package, the first approach is used when the quantile interval construction function is chosen, and the latter approach for the linear interval construction function.</span>
<span id="cb18-476"><a href="#cb18-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-477"><a href="#cb18-477" aria-hidden="true" tabindex="-1"></a>@fig-dtaci-example illustrates DtACI with the quantile interval construction function and with the learning rate grid $\gamma \in <span class="sc">\{</span> 0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128 <span class="sc">\}</span>$. The tuning parameter $\eta$ was set to $0.001$, $1$, and $100$ to show how the algorithm responds to extreme choices of the parameter, and to $\eta \approx 3.19$ according to the optimal choice recommendation with $I = 100$ as described in the previous section. The results show that, in this simple example, high values of $\eta$ may lead to intervals that are too reactive to the data, as seen in the longer path length. The algorithm appears more robust, however, to small choices of $\eta$.</span>
<span id="cb18-478"><a href="#cb18-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-479"><a href="#cb18-479" aria-hidden="true" tabindex="-1"></a><span class="in">```{r faci_example_plot, echo = FALSE}</span></span>
<span id="cb18-480"><a href="#cb18-480" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-dtaci-example</span></span>
<span id="cb18-481"><a href="#cb18-481" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 4.5</span></span>
<span id="cb18-482"><a href="#cb18-482" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Example 80% prediction intervals generated by the DtACI algorithm with starting values $\\theta_1 = 0.8$ and with several values of the tuning parameter $\\eta$.  Blue and red points are observations that fell inside and outside the prediction intervals, respectively."</span></span>
<span id="cb18-483"><a href="#cb18-483" aria-hidden="true" tabindex="-1"></a><span class="in">gamma_grid &lt;- c(0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128)</span></span>
<span id="cb18-484"><a href="#cb18-484" aria-hidden="true" tabindex="-1"></a><span class="in">results &lt;- list(</span></span>
<span id="cb18-485"><a href="#cb18-485" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "DtACI", parameters = list(gamma_grid = gamma_grid, interval_constructor = "conformal", eta = 0.001)),</span></span>
<span id="cb18-486"><a href="#cb18-486" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "DtACI", parameters = list(gamma_grid = gamma_grid, interval_constructor = "conformal", eta = 1)),</span></span>
<span id="cb18-487"><a href="#cb18-487" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "DtACI", parameters = list(gamma_grid = gamma_grid, interval_constructor = "conformal", eta = 100)),</span></span>
<span id="cb18-488"><a href="#cb18-488" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "DtACI", parameters = list(gamma_grid = gamma_grid, interval_constructor = "conformal"))</span></span>
<span id="cb18-489"><a href="#cb18-489" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb18-490"><a href="#cb18-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-491"><a href="#cb18-491" aria-hidden="true" tabindex="-1"></a><span class="in">coverage    &lt;- format_coverage(extract_metric(results, "coverage"))</span></span>
<span id="cb18-492"><a href="#cb18-492" aria-hidden="true" tabindex="-1"></a><span class="in">path_length &lt;- format_path_length(extract_metric(results, "path_length"))</span></span>
<span id="cb18-493"><a href="#cb18-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-494"><a href="#cb18-494" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(2, 2), mar = c(3, 3, 2, 1))</span></span>
<span id="cb18-495"><a href="#cb18-495" aria-hidden="true" tabindex="-1"></a><span class="in">for(i in 1:4) {</span></span>
<span id="cb18-496"><a href="#cb18-496" aria-hidden="true" tabindex="-1"></a><span class="in">  plot(results[[i]], legend = FALSE, predictions = FALSE, cex = 0.5, main = bquote(eta==.(results[[i]]$parameters$eta)), ylim = c(-0.9, 0.8))</span></span>
<span id="cb18-497"><a href="#cb18-497" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -0.75, labels = bquote(EmpCov == .(coverage[[i]]) ), pos = 4)</span></span>
<span id="cb18-498"><a href="#cb18-498" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -0.9, labels = bquote(PathLength == .(path_length[[i]])), pos = 4)</span></span>
<span id="cb18-499"><a href="#cb18-499" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-500"><a href="#cb18-500" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(1, 1), mar = c(5.1, 4.1, 4.1, 2.1))</span></span>
<span id="cb18-501"><a href="#cb18-501" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-502"><a href="#cb18-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-503"><a href="#cb18-503" aria-hidden="true" tabindex="-1"></a><span class="fu">## Scale-Free Online Gradient Descent (SF-OGD)</span></span>
<span id="cb18-504"><a href="#cb18-504" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb18-505"><a href="#cb18-505" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: algo-sfogd</span></span>
<span id="cb18-506"><a href="#cb18-506" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.2em"</span></span>
<span id="cb18-507"><a href="#cb18-507" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb18-508"><a href="#cb18-508" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb18-509"><a href="#cb18-509" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number-punc: ":"</span></span>
<span id="cb18-510"><a href="#cb18-510" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb18-511"><a href="#cb18-511" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb18-512"><a href="#cb18-512" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-number: true</span></span>
<span id="cb18-513"><a href="#cb18-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-514"><a href="#cb18-514" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb18-515"><a href="#cb18-515" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Scale-Free Online Gradient Descent}</span></span>
<span id="cb18-516"><a href="#cb18-516" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb18-517"><a href="#cb18-517" aria-hidden="true" tabindex="-1"></a><span class="in">\State \textbf{Input:} starting value $\theta_1$, learning rate $\gamma &gt; 0$.</span></span>
<span id="cb18-518"><a href="#cb18-518" aria-hidden="true" tabindex="-1"></a><span class="in">\For{$t = 1, 2, \dots, T$}</span></span>
<span id="cb18-519"><a href="#cb18-519" aria-hidden="true" tabindex="-1"></a><span class="in">  \State \textbf{Output:} prediction interval $\widehat{C}_t(\theta_t)$.</span></span>
<span id="cb18-520"><a href="#cb18-520" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Observe $y_t$ and compute $r_t$.</span></span>
<span id="cb18-521"><a href="#cb18-521" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Update $\theta_{t+1} = \theta_t - \gamma \frac{\nabla L^\alpha(\theta_t, r_t)}{\sqrt{\sum_{i=1}^t} \| \nabla L^\alpha(\theta_i, r_i) \|_2^2}$.</span></span>
<span id="cb18-522"><a href="#cb18-522" aria-hidden="true" tabindex="-1"></a><span class="in">\EndFor</span></span>
<span id="cb18-523"><a href="#cb18-523" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb18-524"><a href="#cb18-524" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb18-525"><a href="#cb18-525" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-526"><a href="#cb18-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-527"><a href="#cb18-527" aria-hidden="true" tabindex="-1"></a>Scale-Free Online Gradient Descent (SF-OGD; @algo-sfogd) is a general algorithm for online learning proposed by @orabona2018sfogd. The algorithm updates $\theta_t$ with a gradient descent step where the learning rate adapts to the scale of the previously observed gradients. SF-OGD was first used in the context of ACI as a sub-algorithm for SAOCP (described in the next section). However, it was found to have good performance by itself <span class="co">[</span><span class="ot">@bhatnagar2023saocp</span><span class="co">]</span> in real-world tasks, so we have made it available in the package as a stand-alone algorithm.</span>
<span id="cb18-528"><a href="#cb18-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-529"><a href="#cb18-529" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theoretical Guarantees</span></span>
<span id="cb18-530"><a href="#cb18-530" aria-hidden="true" tabindex="-1"></a>The SF-OGD algorithm with linear interval constructor has the following regret bound, which is called an _anytime regret bound_ because it holds for all $t \in \llbracket T \rrbracket$ <span class="co">[</span><span class="ot">@bhatnagar2023saocp</span><span class="co">]</span>. For any $\gamma &gt; 0$,</span>
<span id="cb18-531"><a href="#cb18-531" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-532"><a href="#cb18-532" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-533"><a href="#cb18-533" aria-hidden="true" tabindex="-1"></a>  \mathrm{Reg}(t) \leq \mathcal{O}(D \sqrt{t}) \text{ for all } t \in \llbracket T \rrbracket.</span>
<span id="cb18-534"><a href="#cb18-534" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-535"><a href="#cb18-535" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-536"><a href="#cb18-536" aria-hidden="true" tabindex="-1"></a>A bound for the coverage error has also been established (@bhatnagar2023saocp; Theorem 4.2). For any learning rate $\gamma = \Theta(D)$ (where $\gamma = D / \sqrt{3}$ is optimal) and any starting value $\theta_1 \in <span class="co">[</span><span class="ot">0, D</span><span class="co">]</span>$, then it holds that for any $T &gt; 1$,</span>
<span id="cb18-537"><a href="#cb18-537" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-538"><a href="#cb18-538" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-539"><a href="#cb18-539" aria-hidden="true" tabindex="-1"></a>  |\mathrm{CovErr}(T)| \leq \mathcal{O}\left( (1 - \alpha)^{-2} T^{-1/4} \log T \right).</span>
<span id="cb18-540"><a href="#cb18-540" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-541"><a href="#cb18-541" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-542"><a href="#cb18-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-543"><a href="#cb18-543" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning parameters</span></span>
<span id="cb18-544"><a href="#cb18-544" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@fig-sf-ogd</span><span class="co">]</span> compares results for several choices of $\gamma$ to illustrate its effect. The optimal choice of learning rate is $\gamma = D / \sqrt{3}$, where $D$ is the maximum possible radius. When $D$ is not known, it can be estimated by using an initial subset of the time series as a calibration set and estimating $D$ as the maximum of the absolute residuals of the observations and the predictions <span class="co">[</span><span class="ot">@bhatnagar2023saocp</span><span class="co">]</span>. @fig-sf-ogd illustrates SF-OGD for several values of $\gamma$. In the example, the prediction intervals are not reactive enough and do not achieve optimal coverage when $\gamma$ is small. As $\gamma$ increases, the coverage error is near optimal, although the path length becomes larger.</span>
<span id="cb18-545"><a href="#cb18-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-546"><a href="#cb18-546" aria-hidden="true" tabindex="-1"></a><span class="in">```{r sfogd_example_plot, echo = FALSE}</span></span>
<span id="cb18-547"><a href="#cb18-547" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-sf-ogd</span></span>
<span id="cb18-548"><a href="#cb18-548" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 4.5</span></span>
<span id="cb18-549"><a href="#cb18-549" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Example 80% prediction intervals generated by the SF-OGD algorithm with different values of the maximum radius tuning parameter $D$. Blue and red points are observations that fell inside and outside the prediction intervals, respectively."</span></span>
<span id="cb18-550"><a href="#cb18-550" aria-hidden="true" tabindex="-1"></a><span class="in">alpha &lt;- 0.8</span></span>
<span id="cb18-551"><a href="#cb18-551" aria-hidden="true" tabindex="-1"></a><span class="in">results &lt;- list(</span></span>
<span id="cb18-552"><a href="#cb18-552" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "SF-OGD", parameters = list(gamma = 0.01)),</span></span>
<span id="cb18-553"><a href="#cb18-553" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "SF-OGD", parameters = list(gamma = 0.1)),</span></span>
<span id="cb18-554"><a href="#cb18-554" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "SF-OGD", parameters = list(gamma = 0.25)),</span></span>
<span id="cb18-555"><a href="#cb18-555" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "SF-OGD", parameters = list(gamma = 0.5))</span></span>
<span id="cb18-556"><a href="#cb18-556" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb18-557"><a href="#cb18-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-558"><a href="#cb18-558" aria-hidden="true" tabindex="-1"></a><span class="in">coverage    &lt;- format_coverage(extract_metric(results, "coverage"))</span></span>
<span id="cb18-559"><a href="#cb18-559" aria-hidden="true" tabindex="-1"></a><span class="in">path_length &lt;- format_path_length(extract_metric(results, "path_length"))</span></span>
<span id="cb18-560"><a href="#cb18-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-561"><a href="#cb18-561" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(2, 2), mar = c(3, 3, 2, 1))</span></span>
<span id="cb18-562"><a href="#cb18-562" aria-hidden="true" tabindex="-1"></a><span class="in">for(i in 1:4) {</span></span>
<span id="cb18-563"><a href="#cb18-563" aria-hidden="true" tabindex="-1"></a><span class="in">  plot(results[[i]], legend = FALSE, predictions = FALSE, cex = 0.5, main = bquote(gamma==.(results[[i]]$parameters$gamma)), ylim = c(-0.9, 0.8))</span></span>
<span id="cb18-564"><a href="#cb18-564" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -0.75, labels = bquote(EmpCov == .(coverage[[i]]) ), pos = 4)</span></span>
<span id="cb18-565"><a href="#cb18-565" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -0.9, labels = bquote(PathLength == .(path_length[[i]])), pos = 4)</span></span>
<span id="cb18-566"><a href="#cb18-566" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-567"><a href="#cb18-567" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(1, 1), mar = c(5.1, 4.1, 4.1, 2.1))</span></span>
<span id="cb18-568"><a href="#cb18-568" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-569"><a href="#cb18-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-570"><a href="#cb18-570" aria-hidden="true" tabindex="-1"></a><span class="fu">## Strongly Adaptive Online Conformal Prediction (SAOCP)</span></span>
<span id="cb18-571"><a href="#cb18-571" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb18-572"><a href="#cb18-572" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: algo-saocp</span></span>
<span id="cb18-573"><a href="#cb18-573" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.2em"</span></span>
<span id="cb18-574"><a href="#cb18-574" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb18-575"><a href="#cb18-575" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb18-576"><a href="#cb18-576" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number-punc: ":"</span></span>
<span id="cb18-577"><a href="#cb18-577" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb18-578"><a href="#cb18-578" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb18-579"><a href="#cb18-579" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-number: true</span></span>
<span id="cb18-580"><a href="#cb18-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-581"><a href="#cb18-581" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb18-582"><a href="#cb18-582" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Strongly Adaptive Online Conformal Prediction}</span></span>
<span id="cb18-583"><a href="#cb18-583" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb18-584"><a href="#cb18-584" aria-hidden="true" tabindex="-1"></a><span class="in">\State \textbf{Input:} initial value $\theta_0$, learning rate $\gamma &gt; 0$.</span></span>
<span id="cb18-585"><a href="#cb18-585" aria-hidden="true" tabindex="-1"></a><span class="in">\For{$t = 1, 2, \dots, T$}</span></span>
<span id="cb18-586"><a href="#cb18-586" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Initialize expert $\mathcal{A}_t = \texttt{SF-OGD}(\alpha \leftarrow \alpha, \gamma \leftarrow \gamma, \theta_1 \leftarrow \theta_{t-1})$, set weight $p_t^t = 0$.</span></span>
<span id="cb18-587"><a href="#cb18-587" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Compute active set $\mathrm{Active}(t) = \{ i \in \llbracket T \rrbracket : t - L(i) &lt; i \leq t \}$ (see below for definition of $L(t)$).</span></span>
<span id="cb18-588"><a href="#cb18-588" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Compute prior probability $\pi_i \propto i^{-2} (1 + \lfloor \log_2 i \rfloor )^{-1} \mathbb{I}[i \in \mathrm{Active}(t)]$.</span></span>
<span id="cb18-589"><a href="#cb18-589" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Compute un-normalized probability $\hat{p}_i = \pi_i [p_{t,i}]_+$ for all $i \in \llbracket t \rrbracket$.</span></span>
<span id="cb18-590"><a href="#cb18-590" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Normalize $p = \hat{p} / \| \hat{p} \|_1 \in \Delta^t$ if $\| \hat{p} \|_1 &gt; 0$, else $p = \pi$.</span></span>
<span id="cb18-591"><a href="#cb18-591" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Set $\theta_t = \sum_{i \in \mathrm{Active}(t)} p_i \theta_t^i$ (for $t \geq 2$), and $\theta_t = 0$ for $t = 1$.</span></span>
<span id="cb18-592"><a href="#cb18-592" aria-hidden="true" tabindex="-1"></a><span class="in">  \State \textbf{Output:} prediction set $\widehat{C}_t(\theta_t)$.</span></span>
<span id="cb18-593"><a href="#cb18-593" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Observe $y_t$ and compute $r_t$.</span></span>
<span id="cb18-594"><a href="#cb18-594" aria-hidden="true" tabindex="-1"></a><span class="in">  \For{$i \in \mathrm{Active}(t)$}</span></span>
<span id="cb18-595"><a href="#cb18-595" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Update expert $\mathcal{A}_t$ with $y_t$ and obtain $\theta_{t+1}^i$.</span></span>
<span id="cb18-596"><a href="#cb18-596" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Compute $g_t^i = \begin{cases}</span></span>
<span id="cb18-597"><a href="#cb18-597" aria-hidden="true" tabindex="-1"></a><span class="in">      \frac{1}{D}\left(L^\alpha(\theta_t, r_t) - L^\alpha(\theta_t^i, r_t)\right) &amp; p_t^i &gt; 0 \\</span></span>
<span id="cb18-598"><a href="#cb18-598" aria-hidden="true" tabindex="-1"></a><span class="in">      \frac{1}{D}\left[L^\alpha(\theta_t, r_t) - L^\alpha(\theta_t^i, r_t))\right]_+ &amp; p_t^i \leq 0 \\</span></span>
<span id="cb18-599"><a href="#cb18-599" aria-hidden="true" tabindex="-1"></a><span class="in">    \end{cases}$.</span></span>
<span id="cb18-600"><a href="#cb18-600" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Update expert weight $p_{t+1}^i = \frac{1}{t - i + 1}\left( \sum_{j=i}^t g_j^i \right) \left(1 + \sum_{j=i}^t p_j^i g_j^i \right)$.</span></span>
<span id="cb18-601"><a href="#cb18-601" aria-hidden="true" tabindex="-1"></a><span class="in">  \EndFor</span></span>
<span id="cb18-602"><a href="#cb18-602" aria-hidden="true" tabindex="-1"></a><span class="in">\EndFor</span></span>
<span id="cb18-603"><a href="#cb18-603" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb18-604"><a href="#cb18-604" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb18-605"><a href="#cb18-605" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-606"><a href="#cb18-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-607"><a href="#cb18-607" aria-hidden="true" tabindex="-1"></a>The Strongly Adaptive Online Conformal Prediction (SAOCP; @algo-saocp) algorithm was proposed as an improvement over the extant ACI algorithms in that it features stronger theoretical guarantees. SAOCP works similarly to AgACI and DtACI in that it maintains a library of candidate online learning algorithms that generate prediction intervals which are then aggregated using a meta-algorithm <span class="co">[</span><span class="ot">@bhatnagar2023saocp</span><span class="co">]</span>. The candidate algorithm was chosen to be SF-OGD, although any algorithm that features anytime regret guarantees can be chosen. As opposed to AgACI and DtACI, in which each candidate has a different learning rate but is always able to contribute to the final prediction intervals, here each candidate has the same learning rate but only has positive weight over a specific interval of time. New candidate algorithms are continually being spawned in order that, if the distribution shifts rapidly, the newer candidates will be able to react quickly and receive positive weight. Specifically, at each time point, a new expert is instantiated which is active over a finite ``lifetime". Define the _lifetime_ of an expert instantiated at time $t$ as</span>
<span id="cb18-608"><a href="#cb18-608" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-609"><a href="#cb18-609" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-610"><a href="#cb18-610" aria-hidden="true" tabindex="-1"></a>  L(t) := g \cdot \max_{n \in \mathbb{Z}} <span class="sc">\{</span> 2^n t \equiv 0 \mod 2^n <span class="sc">\}</span>,</span>
<span id="cb18-611"><a href="#cb18-611" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-612"><a href="#cb18-612" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-613"><a href="#cb18-613" aria-hidden="true" tabindex="-1"></a>where $g \in \mathbb{Z}^*$ is a _lifetime multiplier_ parameter. The active experts are weighted according to their empirical performance with respect to the pinball loss function. The authors show that this construction results in intervals that have strong regret guarantees. The form of the lifetime interval function $L(t)$ is due to the use of geometric covering intervals to partition the input time series, and other choices may be possible <span class="co">[</span><span class="ot">@jun2017coinbetting</span><span class="co">]</span>.</span>
<span id="cb18-614"><a href="#cb18-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-615"><a href="#cb18-615" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theoretical Guarantees</span></span>
<span id="cb18-616"><a href="#cb18-616" aria-hidden="true" tabindex="-1"></a>The theoretical results were established for SAOCP using the linear interval constructor. The following bound for the strongly adaptive regret holds for all subperiod lengths $m \in \llbracket T \rrbracket$ (@bhatnagar2023saocp; Proposition 4.1):</span>
<span id="cb18-617"><a href="#cb18-617" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-618"><a href="#cb18-618" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-619"><a href="#cb18-619" aria-hidden="true" tabindex="-1"></a>  \mathrm{SAReg}(T, m) \leq 15 D \sqrt{m(\log T + 1)} \leq \tilde{\mathcal{O}}(D \sqrt m).</span>
<span id="cb18-620"><a href="#cb18-620" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-621"><a href="#cb18-621" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-622"><a href="#cb18-622" aria-hidden="true" tabindex="-1"></a>It should be emphasized that this regret bounds holds simultaneously across all $m$, as opposed to DtACI, where a similar bound holds only for a single $m$. A bound on the coverage error of SAOCP has also been established as:</span>
<span id="cb18-623"><a href="#cb18-623" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-624"><a href="#cb18-624" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-625"><a href="#cb18-625" aria-hidden="true" tabindex="-1"></a>  |\mathrm{CovErr}(T)| \leq \mathcal{O}\left(\inf_\beta(T^{1/2 - \beta} + T^{\beta - 1} S_\beta(T))\right).</span>
<span id="cb18-626"><a href="#cb18-626" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-627"><a href="#cb18-627" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-628"><a href="#cb18-628" aria-hidden="true" tabindex="-1"></a>where $S_{\beta}(T)$ is a technical measure of the smoothness of the cumulative gradients and expert weights for each of the candidate experts (@bhatnagar2023saocp; Theorem 4.3). For some intuition, $S_{\beta}$ can be expected to be small when the weights placed on each algorithm do change quickly, as would be the case under abrupt distributional shifts.</span>
<span id="cb18-629"><a href="#cb18-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-630"><a href="#cb18-630" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tuning Parameters</span></span>
<span id="cb18-631"><a href="#cb18-631" aria-hidden="true" tabindex="-1"></a>The primary tuning parameter for SAOCP is the learning rate $\gamma$ of the SF-OGD sub-algorithms, which we saw in the previous section has for optimal choice $\gamma = D / \sqrt{3}$. Values for $D$ that are too low lead to intervals that adapt slowly, and values that are too large lead to jagged intervals. In their experiments, the authors select a value for $D$ by picking the maximum residual from a calibration set. The second tuning parameter is the lifetime multiplier $g$ which controls the lifetime of each of the experts. We follow the original paper in setting $g = 8$. @fig-saocp illustrates the SAOCP algorithm for choices of $D \in <span class="sc">\{</span>0.01, 0.1, 0.25, 0.5 <span class="sc">\}</span>$. Similarly to SF-OGD, the prediction intervals tend to undercover for small $D$, and achieve near-optimal coverage for larger $D$ at the expense of larger path lengths.</span>
<span id="cb18-632"><a href="#cb18-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-633"><a href="#cb18-633" aria-hidden="true" tabindex="-1"></a><span class="in">```{r saocp_example_plot, echo = FALSE, cache = TRUE}</span></span>
<span id="cb18-634"><a href="#cb18-634" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-saocp</span></span>
<span id="cb18-635"><a href="#cb18-635" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 4.5</span></span>
<span id="cb18-636"><a href="#cb18-636" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Example 80% prediction intervals generated by the SAOCP algorithm with different values of the maximum radius parameter $D$. Blue and red points are observations that fell inside and outside the prediction intervals, respectively."</span></span>
<span id="cb18-637"><a href="#cb18-637" aria-hidden="true" tabindex="-1"></a><span class="in">alpha &lt;- 0.8</span></span>
<span id="cb18-638"><a href="#cb18-638" aria-hidden="true" tabindex="-1"></a><span class="in">results &lt;- list(</span></span>
<span id="cb18-639"><a href="#cb18-639" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "SAOCP", parameters = list(D = 0.01)),</span></span>
<span id="cb18-640"><a href="#cb18-640" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "SAOCP", parameters = list(D = 0.1)),</span></span>
<span id="cb18-641"><a href="#cb18-641" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "SAOCP", parameters = list(D = 0.25)),</span></span>
<span id="cb18-642"><a href="#cb18-642" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(y, yhat, alpha = alpha, method = "SAOCP", parameters = list(D = 0.5))</span></span>
<span id="cb18-643"><a href="#cb18-643" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb18-644"><a href="#cb18-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-645"><a href="#cb18-645" aria-hidden="true" tabindex="-1"></a><span class="in">coverage    &lt;- format_coverage(extract_metric(results, "coverage"))</span></span>
<span id="cb18-646"><a href="#cb18-646" aria-hidden="true" tabindex="-1"></a><span class="in">path_length &lt;- format_path_length(extract_metric(results, "path_length"))</span></span>
<span id="cb18-647"><a href="#cb18-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-648"><a href="#cb18-648" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(2, 2), mar = c(3, 3, 2, 1))</span></span>
<span id="cb18-649"><a href="#cb18-649" aria-hidden="true" tabindex="-1"></a><span class="in">for(i in 1:4) {</span></span>
<span id="cb18-650"><a href="#cb18-650" aria-hidden="true" tabindex="-1"></a><span class="in">  plot(results[[i]], legend = FALSE, predictions = FALSE, cex = 0.5, main = bquote(D==.(results[[i]]$parameters$D)), ylim = c(-0.9, 0.8))</span></span>
<span id="cb18-651"><a href="#cb18-651" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -0.75, labels = bquote(EmpCov == .(coverage[[i]])), pos = 4)</span></span>
<span id="cb18-652"><a href="#cb18-652" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -0.9, labels = bquote(PathLength == .(path_length[[i]])), pos = 4)</span></span>
<span id="cb18-653"><a href="#cb18-653" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-654"><a href="#cb18-654" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(1, 1), mar = c(5.1, 4.1, 4.1, 2.1))</span></span>
<span id="cb18-655"><a href="#cb18-655" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-656"><a href="#cb18-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-657"><a href="#cb18-657" aria-hidden="true" tabindex="-1"></a><span class="fu"># `AdaptiveConformal` `R` package</span></span>
<span id="cb18-658"><a href="#cb18-658" aria-hidden="true" tabindex="-1"></a>The ACI algorithms described in the previous section have been implemented in the open-source and publically available <span class="in">`R`</span> package <span class="in">`AdaptiveConformal`</span>, available at <span class="co">[</span><span class="ot">https://github.com/herbps10/AdaptiveConformal</span><span class="co">](https://github.com/herbps10/AdaptiveConformal)</span>. CIn this section, we briefly introduce the main functionality of the package. Comprehensive documentation is, including several example vignettes, is included with the package.</span>
<span id="cb18-659"><a href="#cb18-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-660"><a href="#cb18-660" aria-hidden="true" tabindex="-1"></a>The <span class="in">`AdaptiveConformal`</span> package can be installed using the <span class="in">`remotes`</span> package:</span>
<span id="cb18-661"><a href="#cb18-661" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, eval = FALSE}</span></span>
<span id="cb18-662"><a href="#cb18-662" aria-hidden="true" tabindex="-1"></a><span class="in">remotes::install_github("herbps10/AdaptiveConformal")</span></span>
<span id="cb18-663"><a href="#cb18-663" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-664"><a href="#cb18-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-665"><a href="#cb18-665" aria-hidden="true" tabindex="-1"></a>The ACI algorithms are accessed through the <span class="in">`aci`</span> function, which takes as input a vector of observations ($y_t$) and a vector or matrix of predictions ($\hat{y}_t$). Using the data generating process from the running example to illustrate, we can fit the original ACI algorithm with learning rate $\gamma = 0.1$:</span>
<span id="cb18-668"><a href="#cb18-668" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-669"><a href="#cb18-669" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">532</span>)</span>
<span id="cb18-670"><a href="#cb18-670" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">running_example_data</span>(<span class="at">N =</span> <span class="fl">5e2</span>)</span>
<span id="cb18-671"><a href="#cb18-671" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">aci</span>(data<span class="sc">$</span>y, data<span class="sc">$</span>yhat, <span class="at">alpha =</span> <span class="fl">0.8</span>, <span class="at">method =</span> <span class="st">"ACI"</span>, <span class="at">parameters =</span> <span class="fu">list</span>(<span class="at">gamma =</span> <span class="fl">0.1</span>))</span>
<span id="cb18-672"><a href="#cb18-672" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-673"><a href="#cb18-673" aria-hidden="true" tabindex="-1"></a>The available parameters for each method can be found in the documentation for the <span class="in">`aci`</span> method, accessible with the command <span class="in">`?aci`</span>. The resulting conformal prediction intervals can then be plotted using the <span class="in">`plot`</span> function:</span>
<span id="cb18-674"><a href="#cb18-674" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.height = 4}</span></span>
<span id="cb18-675"><a href="#cb18-675" aria-hidden="true" tabindex="-1"></a><span class="in">plot(fit)</span></span>
<span id="cb18-676"><a href="#cb18-676" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-677"><a href="#cb18-677" aria-hidden="true" tabindex="-1"></a>The properties of the prediction intervals can also be examined using the <span class="in">`summary`</span> function:</span>
<span id="cb18-680"><a href="#cb18-680" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-681"><a href="#cb18-681" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span>
<span id="cb18-682"><a href="#cb18-682" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-683"><a href="#cb18-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-684"><a href="#cb18-684" aria-hidden="true" tabindex="-1"></a><span class="fu"># Simulation Studies {#sec-simulations}</span></span>
<span id="cb18-685"><a href="#cb18-685" aria-hidden="true" tabindex="-1"></a>We present two empirical studies in order to compare the performance of the AgACI, DtACI, SF-OGD, and SAOCP algorithms applied to simple simulated datasets. The original ACI algorithm was not included as it is not clear how to set the tuning rate $\gamma$, which can have a large effect on the resulting intervals. For both simulations we set the targeted empirical coverage to $\alpha = 0.8$, $\alpha = 0.9$, and $\alpha = 0.95$. For each algorithm, we chose the interval constructor that was used in its original presentation (see @tbl-aci).</span>
<span id="cb18-686"><a href="#cb18-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-687"><a href="#cb18-687" aria-hidden="true" tabindex="-1"></a><span class="fu">## Time series with ARMA errors</span></span>
<span id="cb18-688"><a href="#cb18-688" aria-hidden="true" tabindex="-1"></a>In this simulation we reproduce the setup described in @zaffran2022agaci (itself based on that of @friedman1983). The time series values $y_t$ for $t \in \llbracket T \rrbracket$ ($T = 600$) are simulated according to</span>
<span id="cb18-689"><a href="#cb18-689" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-690"><a href="#cb18-690" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-691"><a href="#cb18-691" aria-hidden="true" tabindex="-1"></a>  y_t = 10\sin(\pi X_{t,1}X_{t,2}) + 20(X_{t,3} - 0.5)^2 + 10X_{t,4} + 5 X_{t,5} + 0X_{t,6} + \epsilon_t,</span>
<span id="cb18-692"><a href="#cb18-692" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-693"><a href="#cb18-693" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-694"><a href="#cb18-694" aria-hidden="true" tabindex="-1"></a>where $X_{t,i}$, $i = 1, \dots, 6$, $t \in \llbracket T \rrbracket$ are independently uniformly distributed on $<span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>$ and the noise terms $\epsilon_t$ are generated according to an ARMA(1, 1) process:</span>
<span id="cb18-695"><a href="#cb18-695" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-696"><a href="#cb18-696" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-697"><a href="#cb18-697" aria-hidden="true" tabindex="-1"></a>  \epsilon_t &amp;= \psi \epsilon_{t-1} + \xi_t + \theta \xi_{t-1}, <span class="sc">\\</span></span>
<span id="cb18-698"><a href="#cb18-698" aria-hidden="true" tabindex="-1"></a>  \xi_t &amp;\sim N(0, \sigma^2).</span>
<span id="cb18-699"><a href="#cb18-699" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-700"><a href="#cb18-700" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-701"><a href="#cb18-701" aria-hidden="true" tabindex="-1"></a>We set $\psi$ and $\theta$ jointly to each value in $<span class="sc">\{</span> 0.1, 0.8, 0.9, 0.95, 0.99 <span class="sc">\}</span>$ to simulate time series with increasing temporal dependence. The innovation variance was set to $\sigma^2 = (1 - \psi^2) / (1 + 2\psi \xi + \xi^2)$ (to ensure that the process has constant variance). For each setting, 25 simulated datasets were generated.</span>
<span id="cb18-702"><a href="#cb18-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-703"><a href="#cb18-703" aria-hidden="true" tabindex="-1"></a>To provide point predictions for the ACI algorithms, at each time $t \geq 200$ a random forest model was fitted to the previously observed data using the <span class="in">`ranger`</span> <span class="in">`R`</span> package <span class="co">[</span><span class="ot">@wright2017ranger</span><span class="co">]</span>. The estimated model was then used to predict the subsequent time point. The maximum radius $D$ was estimated as the maximum residual observed between time points $t=200$ and $t=249$. The ACI models were then executed starting at time point $t = 250$. All metrics are based on time points $t \geq 300$ to allow time for the ACI methods to initialize.</span>
<span id="cb18-704"><a href="#cb18-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-705"><a href="#cb18-705" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simulation_study_one, cache = TRUE}</span></span>
<span id="cb18-706"><a href="#cb18-706" aria-hidden="true" tabindex="-1"></a><span class="in">simulate &lt;- function(seed, psi, xi, N = 1e3) {</span></span>
<span id="cb18-707"><a href="#cb18-707" aria-hidden="true" tabindex="-1"></a><span class="in">  set.seed(seed)</span></span>
<span id="cb18-708"><a href="#cb18-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-709"><a href="#cb18-709" aria-hidden="true" tabindex="-1"></a><span class="in">  s &lt;- 10</span></span>
<span id="cb18-710"><a href="#cb18-710" aria-hidden="true" tabindex="-1"></a><span class="in">  innov_scale &lt;- sqrt(s * (1 - psi^2) / (1 + 2 * psi * xi + xi^2))</span></span>
<span id="cb18-711"><a href="#cb18-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-712"><a href="#cb18-712" aria-hidden="true" tabindex="-1"></a><span class="in">  X &lt;- matrix(runif(6 * N), ncol = 6, nrow = N)</span></span>
<span id="cb18-713"><a href="#cb18-713" aria-hidden="true" tabindex="-1"></a><span class="in">  colnames(X) &lt;- paste0("X", 1:6)</span></span>
<span id="cb18-714"><a href="#cb18-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-715"><a href="#cb18-715" aria-hidden="true" tabindex="-1"></a><span class="in">  epsilon &lt;- arima.sim(n = N, model = list(ar = psi, ma = xi), sd = innov_scale)</span></span>
<span id="cb18-716"><a href="#cb18-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-717"><a href="#cb18-717" aria-hidden="true" tabindex="-1"></a><span class="in">  mu &lt;- 10 * sin(pi * X[,1] * X[,2]) + 20 * (X[,3] - 0.5)^2 + 10 * X[,4] + 5 * X[,5]</span></span>
<span id="cb18-718"><a href="#cb18-718" aria-hidden="true" tabindex="-1"></a><span class="in">  y &lt;- mu + epsilon</span></span>
<span id="cb18-719"><a href="#cb18-719" aria-hidden="true" tabindex="-1"></a><span class="in">  as_tibble(X) %&gt;% mutate(y = y)</span></span>
<span id="cb18-720"><a href="#cb18-720" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-721"><a href="#cb18-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-722"><a href="#cb18-722" aria-hidden="true" tabindex="-1"></a><span class="in">estimate_model &lt;- function(data, p = NULL) {</span></span>
<span id="cb18-723"><a href="#cb18-723" aria-hidden="true" tabindex="-1"></a><span class="in">  if(!is.null(p)) p()</span></span>
<span id="cb18-724"><a href="#cb18-724" aria-hidden="true" tabindex="-1"></a><span class="in">  preds &lt;- numeric(nrow(data))</span></span>
<span id="cb18-725"><a href="#cb18-725" aria-hidden="true" tabindex="-1"></a><span class="in">  for(t in 200:nrow(data)) {</span></span>
<span id="cb18-726"><a href="#cb18-726" aria-hidden="true" tabindex="-1"></a><span class="in">    model &lt;- ranger::ranger(y ~ X1 + X2 + X3 + X4 + X5 + X6, data = data[1:(t - 1),])</span></span>
<span id="cb18-727"><a href="#cb18-727" aria-hidden="true" tabindex="-1"></a><span class="in">    preds[t] &lt;- predict(model, data = data[t, ])$predictions</span></span>
<span id="cb18-728"><a href="#cb18-728" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb18-729"><a href="#cb18-729" aria-hidden="true" tabindex="-1"></a><span class="in">  preds</span></span>
<span id="cb18-730"><a href="#cb18-730" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-731"><a href="#cb18-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-732"><a href="#cb18-732" aria-hidden="true" tabindex="-1"></a><span class="in">metrics &lt;- function(fit) {</span></span>
<span id="cb18-733"><a href="#cb18-733" aria-hidden="true" tabindex="-1"></a><span class="in">  indices &lt;- 300:length(fit$Y)</span></span>
<span id="cb18-734"><a href="#cb18-734" aria-hidden="true" tabindex="-1"></a><span class="in">  aci_metrics(fit, indices)</span></span>
<span id="cb18-735"><a href="#cb18-735" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-736"><a href="#cb18-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-737"><a href="#cb18-737" aria-hidden="true" tabindex="-1"></a><span class="in">fit &lt;- function(data, preds, method, alpha, p = NULL) {</span></span>
<span id="cb18-738"><a href="#cb18-738" aria-hidden="true" tabindex="-1"></a><span class="in">  if(!is.null(p)) p()</span></span>
<span id="cb18-739"><a href="#cb18-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-740"><a href="#cb18-740" aria-hidden="true" tabindex="-1"></a><span class="in">  D &lt;- max(abs(data$y - preds)[200:249])</span></span>
<span id="cb18-741"><a href="#cb18-741" aria-hidden="true" tabindex="-1"></a><span class="in">  gamma &lt;- D / sqrt(3)</span></span>
<span id="cb18-742"><a href="#cb18-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-743"><a href="#cb18-743" aria-hidden="true" tabindex="-1"></a><span class="in">  interval_constructor = case_when(</span></span>
<span id="cb18-744"><a href="#cb18-744" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "AgACI" ~ "conformal",</span></span>
<span id="cb18-745"><a href="#cb18-745" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "DtACI" ~ "conformal",</span></span>
<span id="cb18-746"><a href="#cb18-746" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "SF-OGD" ~ "linear",</span></span>
<span id="cb18-747"><a href="#cb18-747" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "SAOCP" ~ "linear"</span></span>
<span id="cb18-748"><a href="#cb18-748" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb18-749"><a href="#cb18-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-750"><a href="#cb18-750" aria-hidden="true" tabindex="-1"></a><span class="in">  if(interval_constructor == "linear") {</span></span>
<span id="cb18-751"><a href="#cb18-751" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma_grid = seq(0.1, 1, 0.1)</span></span>
<span id="cb18-752"><a href="#cb18-752" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb18-753"><a href="#cb18-753" aria-hidden="true" tabindex="-1"></a><span class="in">  else {</span></span>
<span id="cb18-754"><a href="#cb18-754" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma_grid &lt;- c(0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128)</span></span>
<span id="cb18-755"><a href="#cb18-755" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb18-756"><a href="#cb18-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-757"><a href="#cb18-757" aria-hidden="true" tabindex="-1"></a><span class="in">  parameters &lt;- list(</span></span>
<span id="cb18-758"><a href="#cb18-758" aria-hidden="true" tabindex="-1"></a><span class="in">    interval_constructor = interval_constructor,</span></span>
<span id="cb18-759"><a href="#cb18-759" aria-hidden="true" tabindex="-1"></a><span class="in">    D = D,</span></span>
<span id="cb18-760"><a href="#cb18-760" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma = gamma,</span></span>
<span id="cb18-761"><a href="#cb18-761" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma_grid = gamma_grid</span></span>
<span id="cb18-762"><a href="#cb18-762" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb18-763"><a href="#cb18-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-764"><a href="#cb18-764" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(</span></span>
<span id="cb18-765"><a href="#cb18-765" aria-hidden="true" tabindex="-1"></a><span class="in">    data$y[250:nrow(data)],</span></span>
<span id="cb18-766"><a href="#cb18-766" aria-hidden="true" tabindex="-1"></a><span class="in">    preds[250:nrow(data)],</span></span>
<span id="cb18-767"><a href="#cb18-767" aria-hidden="true" tabindex="-1"></a><span class="in">    method = method,</span></span>
<span id="cb18-768"><a href="#cb18-768" aria-hidden="true" tabindex="-1"></a><span class="in">    alpha = alpha,</span></span>
<span id="cb18-769"><a href="#cb18-769" aria-hidden="true" tabindex="-1"></a><span class="in">    parameters = parameters</span></span>
<span id="cb18-770"><a href="#cb18-770" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb18-771"><a href="#cb18-771" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-772"><a href="#cb18-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-773"><a href="#cb18-773" aria-hidden="true" tabindex="-1"></a><span class="in">N_sims &lt;- 100</span></span>
<span id="cb18-774"><a href="#cb18-774" aria-hidden="true" tabindex="-1"></a><span class="in">simulation_data &lt;- expand_grid(</span></span>
<span id="cb18-775"><a href="#cb18-775" aria-hidden="true" tabindex="-1"></a><span class="in">  index = 1:N_sims,</span></span>
<span id="cb18-776"><a href="#cb18-776" aria-hidden="true" tabindex="-1"></a><span class="in">  param =  c(0.1, 0.8, 0.9, 0.95, 0.99),</span></span>
<span id="cb18-777"><a href="#cb18-777" aria-hidden="true" tabindex="-1"></a><span class="in">  N = 600</span></span>
<span id="cb18-778"><a href="#cb18-778" aria-hidden="true" tabindex="-1"></a><span class="in">) %&gt;%</span></span>
<span id="cb18-779"><a href="#cb18-779" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(psi = param, xi = param)</span></span>
<span id="cb18-780"><a href="#cb18-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-781"><a href="#cb18-781" aria-hidden="true" tabindex="-1"></a><span class="in"># For each simulated dataset, fit multiple ACI methods</span></span>
<span id="cb18-782"><a href="#cb18-782" aria-hidden="true" tabindex="-1"></a><span class="in">simulation_study_setup &lt;- expand_grid(</span></span>
<span id="cb18-783"><a href="#cb18-783" aria-hidden="true" tabindex="-1"></a><span class="in">  alpha = c(0.8, 0.9, 0.95),</span></span>
<span id="cb18-784"><a href="#cb18-784" aria-hidden="true" tabindex="-1"></a><span class="in">  method = c("AgACI", "SF-OGD", "SAOCP", "DtACI")</span></span>
<span id="cb18-785"><a href="#cb18-785" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb18-786"><a href="#cb18-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-787"><a href="#cb18-787" aria-hidden="true" tabindex="-1"></a><span class="in"># run_simulation_study1 function is defined in helpers.R</span></span>
<span id="cb18-788"><a href="#cb18-788" aria-hidden="true" tabindex="-1"></a><span class="in">simulation_study1 &lt;- run_simulation_study1(</span></span>
<span id="cb18-789"><a href="#cb18-789" aria-hidden="true" tabindex="-1"></a><span class="in">  simulation_data,</span></span>
<span id="cb18-790"><a href="#cb18-790" aria-hidden="true" tabindex="-1"></a><span class="in">  simulation_study_setup,</span></span>
<span id="cb18-791"><a href="#cb18-791" aria-hidden="true" tabindex="-1"></a><span class="in">  estimate_model,</span></span>
<span id="cb18-792"><a href="#cb18-792" aria-hidden="true" tabindex="-1"></a><span class="in">  fit,</span></span>
<span id="cb18-793"><a href="#cb18-793" aria-hidden="true" tabindex="-1"></a><span class="in">  workers = 8</span></span>
<span id="cb18-794"><a href="#cb18-794" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb18-795"><a href="#cb18-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-796"><a href="#cb18-796" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-797"><a href="#cb18-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-798"><a href="#cb18-798" aria-hidden="true" tabindex="-1"></a>The coverage errors, mean interval widths, path lengths, and strongly adaptive regret (for $m = 20$) of each of the algorithms for $\alpha = 0.9$ are shown in @fig-simulation-one-results (results for $\alpha \in <span class="sc">\{</span> 0.8, 0.95 <span class="sc">\}</span>$ were similar and are available in the appendix). All methods achieved near optimal empirical coverage, although SAOCP tended to slightly undercover. The mean interval widths re similar across methods, although again SAOCP had slightly shorter intervals (as could be expected given its tendency to undercover).  The strongly adaptive regret was similar for all methods. The path length of SAOCP was larger than any of the other methods. To investigate why, @fig-simulation-one-widths plots $w_t - w_{t-1}$, the difference in interval width between times $t-1$ and $t$, for each method in one of the simulations. The interval widths for AgACI and DtACI change slowly relative to those for SF-OGD and SAOCP. For SAOCP, we can see the interval widths have larger fluctuations than for the other methods, explaining its higher path width. The prediction intervals themselves for the same simulation are shown in @fig-simulation-one-example, which shows that although the path lengths are quite different, the output prediction intervals are quite similar.</span>
<span id="cb18-799"><a href="#cb18-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-800"><a href="#cb18-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-801"><a href="#cb18-801" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simulation_one_plot, message=FALSE, warning=FALSE}</span></span>
<span id="cb18-802"><a href="#cb18-802" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-simulation-one-results</span></span>
<span id="cb18-803"><a href="#cb18-803" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 9</span></span>
<span id="cb18-804"><a href="#cb18-804" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Coverage errors, mean interval widths, path lengths, and strongly adaptive regret (for $m = 20$) for the first simulation study with target coverage $\\alpha = 0.9$."</span></span>
<span id="cb18-805"><a href="#cb18-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-806"><a href="#cb18-806" aria-hidden="true" tabindex="-1"></a><span class="in">simulation_one_plot(simulation_study1$results %&gt;% filter(alpha == 0.9))</span></span>
<span id="cb18-807"><a href="#cb18-807" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-808"><a href="#cb18-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-809"><a href="#cb18-809" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simulation_one_width_plot}</span></span>
<span id="cb18-810"><a href="#cb18-810" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-simulation-one-widths</span></span>
<span id="cb18-811"><a href="#cb18-811" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 5</span></span>
<span id="cb18-812"><a href="#cb18-812" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Difference in successive interval widths ($w_t - w_{t-1}$) from an illustrative simulation from the first simulation study."</span></span>
<span id="cb18-813"><a href="#cb18-813" aria-hidden="true" tabindex="-1"></a><span class="in">fits &lt;- simulation_study1$example_fits</span></span>
<span id="cb18-814"><a href="#cb18-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-815"><a href="#cb18-815" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(2, 2), mar = c(3, 4, 2, 1))</span></span>
<span id="cb18-816"><a href="#cb18-816" aria-hidden="true" tabindex="-1"></a><span class="in">for(i in 1:4) {</span></span>
<span id="cb18-817"><a href="#cb18-817" aria-hidden="true" tabindex="-1"></a><span class="in">  plot(</span></span>
<span id="cb18-818"><a href="#cb18-818" aria-hidden="true" tabindex="-1"></a><span class="in">    diff(fits$fit[[i]]$intervals[,2] - fits$fit[[i]]$intervals[,1]),</span></span>
<span id="cb18-819"><a href="#cb18-819" aria-hidden="true" tabindex="-1"></a><span class="in">    main = fits$method[[i]],</span></span>
<span id="cb18-820"><a href="#cb18-820" aria-hidden="true" tabindex="-1"></a><span class="in">    xlab = "T",</span></span>
<span id="cb18-821"><a href="#cb18-821" aria-hidden="true" tabindex="-1"></a><span class="in">    ylab = expression(w[t] - w[t - 1]))</span></span>
<span id="cb18-822"><a href="#cb18-822" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-823"><a href="#cb18-823" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(1, 1), mar = c(5.1, 4.1, 4.1, 2.1))</span></span>
<span id="cb18-824"><a href="#cb18-824" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-825"><a href="#cb18-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-826"><a href="#cb18-826" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simulation_one_example_plots}</span></span>
<span id="cb18-827"><a href="#cb18-827" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-simulation-one-example</span></span>
<span id="cb18-828"><a href="#cb18-828" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 6</span></span>
<span id="cb18-829"><a href="#cb18-829" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Example prediction intervals (target coverage $\\alpha = 0.9$) from the first simulation study for time points 300 to 350; metrics shown are for all time points $t \\geq 300$. Blue and red points are observations that fell inside and outside the prediction intervals, respectively."</span></span>
<span id="cb18-830"><a href="#cb18-830" aria-hidden="true" tabindex="-1"></a><span class="in">fits &lt;- simulation_study1$example_fits</span></span>
<span id="cb18-831"><a href="#cb18-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-832"><a href="#cb18-832" aria-hidden="true" tabindex="-1"></a><span class="in">coverage    &lt;- format_coverage(map_dbl(map(fits$fit, metrics), `[[`, "coverage"))</span></span>
<span id="cb18-833"><a href="#cb18-833" aria-hidden="true" tabindex="-1"></a><span class="in">path_length &lt;- format_path_length(map_dbl(map(fits$fit, metrics), `[[`, "path_length"))</span></span>
<span id="cb18-834"><a href="#cb18-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-835"><a href="#cb18-835" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(2, 2), mar = c(3, 3, 2, 1))</span></span>
<span id="cb18-836"><a href="#cb18-836" aria-hidden="true" tabindex="-1"></a><span class="in">for(i in 1:4) {</span></span>
<span id="cb18-837"><a href="#cb18-837" aria-hidden="true" tabindex="-1"></a><span class="in">  plot(fits$fit[[i]], legend = FALSE, main = fits$method[[i]], predictions = FALSE, ylim = c(-20, 35), index = 50:100)</span></span>
<span id="cb18-838"><a href="#cb18-838" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -0, y = -7.5, labels = bquote(EmpCov == .(coverage[[i]]) ), pos = 4)</span></span>
<span id="cb18-839"><a href="#cb18-839" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -0, y = -17.5, labels = bquote(PathLength == .(path_length[[i]]) ), pos = 4)</span></span>
<span id="cb18-840"><a href="#cb18-840" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-841"><a href="#cb18-841" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(1, 1), mar = c(5.1, 4.1, 4.1, 2.1))</span></span>
<span id="cb18-842"><a href="#cb18-842" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-843"><a href="#cb18-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-844"><a href="#cb18-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-845"><a href="#cb18-845" aria-hidden="true" tabindex="-1"></a><span class="fu">## Distribution shift</span></span>
<span id="cb18-846"><a href="#cb18-846" aria-hidden="true" tabindex="-1"></a>This simulation study features time series with distribution shifts. The setup is quite simple in order to probe the basic performance of the methods in response to distribution shift. As a baseline, we simulate time series of independent data with</span>
<span id="cb18-847"><a href="#cb18-847" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-848"><a href="#cb18-848" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-849"><a href="#cb18-849" aria-hidden="true" tabindex="-1"></a>  y_t &amp;\sim N(0, \sigma_t^2), <span class="sc">\\</span></span>
<span id="cb18-850"><a href="#cb18-850" aria-hidden="true" tabindex="-1"></a>  \sigma_t &amp;= 0.2,</span>
<span id="cb18-851"><a href="#cb18-851" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-852"><a href="#cb18-852" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-853"><a href="#cb18-853" aria-hidden="true" tabindex="-1"></a>for all $t \in \llbracket T \rrbracket$ ($T = 500$). In the second type of time series, the observations are still independent but their variance increases halfway through the time series:</span>
<span id="cb18-854"><a href="#cb18-854" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-855"><a href="#cb18-855" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb18-856"><a href="#cb18-856" aria-hidden="true" tabindex="-1"></a>y_t &amp;\sim N(0, \sigma_t^2), <span class="sc">\\</span></span>
<span id="cb18-857"><a href="#cb18-857" aria-hidden="true" tabindex="-1"></a>\sigma_t &amp;= 0.2 + 0.5 \mathbb{I}<span class="co">[</span><span class="ot">t &gt; 250</span><span class="co">]</span>.</span>
<span id="cb18-858"><a href="#cb18-858" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb18-859"><a href="#cb18-859" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-860"><a href="#cb18-860" aria-hidden="true" tabindex="-1"></a>In each case, the ACI algorithms are provided with the unbiased predictions $\hat{\mu}_t = 0$, $t \in \llbracket T \rrbracket$. Fifty simulated datasets were generated for each type of time series.</span>
<span id="cb18-861"><a href="#cb18-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-862"><a href="#cb18-862" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simulation_two, cache = TRUE}</span></span>
<span id="cb18-863"><a href="#cb18-863" aria-hidden="true" tabindex="-1"></a><span class="in">simulate &lt;- function(seed, distribution_shift = 0, N = 1e3, sigma = 0.2) {</span></span>
<span id="cb18-864"><a href="#cb18-864" aria-hidden="true" tabindex="-1"></a><span class="in">  set.seed(seed)</span></span>
<span id="cb18-865"><a href="#cb18-865" aria-hidden="true" tabindex="-1"></a><span class="in">  mu &lt;- rep(0, N)</span></span>
<span id="cb18-866"><a href="#cb18-866" aria-hidden="true" tabindex="-1"></a><span class="in">  shift &lt;- 1:N &gt; (N / 2)</span></span>
<span id="cb18-867"><a href="#cb18-867" aria-hidden="true" tabindex="-1"></a><span class="in">  yhat &lt;- mu</span></span>
<span id="cb18-868"><a href="#cb18-868" aria-hidden="true" tabindex="-1"></a><span class="in">  y &lt;- rnorm(n = length(mu), mean = mu, sd = sigma + ifelse(shift, distribution_shift, 0))</span></span>
<span id="cb18-869"><a href="#cb18-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-870"><a href="#cb18-870" aria-hidden="true" tabindex="-1"></a><span class="in">  tibble(y = y, yhat = yhat)</span></span>
<span id="cb18-871"><a href="#cb18-871" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-872"><a href="#cb18-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-873"><a href="#cb18-873" aria-hidden="true" tabindex="-1"></a><span class="in">metrics &lt;- function(fit) {</span></span>
<span id="cb18-874"><a href="#cb18-874" aria-hidden="true" tabindex="-1"></a><span class="in">  N &lt;- length(fit$Y)</span></span>
<span id="cb18-875"><a href="#cb18-875" aria-hidden="true" tabindex="-1"></a><span class="in">  indices &lt;- which(1:N &gt; 50)</span></span>
<span id="cb18-876"><a href="#cb18-876" aria-hidden="true" tabindex="-1"></a><span class="in">  aci_metrics(fit, indices)</span></span>
<span id="cb18-877"><a href="#cb18-877" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-878"><a href="#cb18-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-879"><a href="#cb18-879" aria-hidden="true" tabindex="-1"></a><span class="in">fit &lt;- function(data, method, alpha, p = NULL) {</span></span>
<span id="cb18-880"><a href="#cb18-880" aria-hidden="true" tabindex="-1"></a><span class="in">  if(!is.null(p)) p()</span></span>
<span id="cb18-881"><a href="#cb18-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-882"><a href="#cb18-882" aria-hidden="true" tabindex="-1"></a><span class="in">  interval_constructor = case_when(</span></span>
<span id="cb18-883"><a href="#cb18-883" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "AgACI" ~ "conformal",</span></span>
<span id="cb18-884"><a href="#cb18-884" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "DtACI" ~ "conformal",</span></span>
<span id="cb18-885"><a href="#cb18-885" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "SF-OGD" ~ "linear",</span></span>
<span id="cb18-886"><a href="#cb18-886" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "SAOCP" ~ "linear"</span></span>
<span id="cb18-887"><a href="#cb18-887" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb18-888"><a href="#cb18-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-889"><a href="#cb18-889" aria-hidden="true" tabindex="-1"></a><span class="in">  if(interval_constructor == "linear") {</span></span>
<span id="cb18-890"><a href="#cb18-890" aria-hidden="true" tabindex="-1"></a><span class="in">    D &lt;- max(abs(data$y - data$yhat)[1:50])</span></span>
<span id="cb18-891"><a href="#cb18-891" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb18-892"><a href="#cb18-892" aria-hidden="true" tabindex="-1"></a><span class="in">  else {</span></span>
<span id="cb18-893"><a href="#cb18-893" aria-hidden="true" tabindex="-1"></a><span class="in">    D &lt;- 1</span></span>
<span id="cb18-894"><a href="#cb18-894" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb18-895"><a href="#cb18-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-896"><a href="#cb18-896" aria-hidden="true" tabindex="-1"></a><span class="in">  gamma &lt;- D / sqrt(3)</span></span>
<span id="cb18-897"><a href="#cb18-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-898"><a href="#cb18-898" aria-hidden="true" tabindex="-1"></a><span class="in">  if(interval_constructor == "linear") {</span></span>
<span id="cb18-899"><a href="#cb18-899" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma_grid &lt;- seq(0.1, 2, 0.1)</span></span>
<span id="cb18-900"><a href="#cb18-900" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb18-901"><a href="#cb18-901" aria-hidden="true" tabindex="-1"></a><span class="in">  else {</span></span>
<span id="cb18-902"><a href="#cb18-902" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma_grid &lt;- c(0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128)</span></span>
<span id="cb18-903"><a href="#cb18-903" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb18-904"><a href="#cb18-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-905"><a href="#cb18-905" aria-hidden="true" tabindex="-1"></a><span class="in">  parameters &lt;- list(</span></span>
<span id="cb18-906"><a href="#cb18-906" aria-hidden="true" tabindex="-1"></a><span class="in">    interval_constructor = interval_constructor,</span></span>
<span id="cb18-907"><a href="#cb18-907" aria-hidden="true" tabindex="-1"></a><span class="in">    D = D,</span></span>
<span id="cb18-908"><a href="#cb18-908" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma = gamma,</span></span>
<span id="cb18-909"><a href="#cb18-909" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma_grid = gamma_grid</span></span>
<span id="cb18-910"><a href="#cb18-910" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb18-911"><a href="#cb18-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-912"><a href="#cb18-912" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(data$y, data$yhat, method = method, alpha = alpha, parameters = parameters)</span></span>
<span id="cb18-913"><a href="#cb18-913" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-914"><a href="#cb18-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-915"><a href="#cb18-915" aria-hidden="true" tabindex="-1"></a><span class="in">N_sims &lt;- 100</span></span>
<span id="cb18-916"><a href="#cb18-916" aria-hidden="true" tabindex="-1"></a><span class="in">simulation_study_setup2 &lt;- expand_grid(</span></span>
<span id="cb18-917"><a href="#cb18-917" aria-hidden="true" tabindex="-1"></a><span class="in">  index = 1:N_sims,</span></span>
<span id="cb18-918"><a href="#cb18-918" aria-hidden="true" tabindex="-1"></a><span class="in">  distribution_shift = c(0, 0.5),</span></span>
<span id="cb18-919"><a href="#cb18-919" aria-hidden="true" tabindex="-1"></a><span class="in">  alpha = c(0.8, 0.9, 0.95),</span></span>
<span id="cb18-920"><a href="#cb18-920" aria-hidden="true" tabindex="-1"></a><span class="in">  N = 500,</span></span>
<span id="cb18-921"><a href="#cb18-921" aria-hidden="true" tabindex="-1"></a><span class="in">  method = c("AgACI", "SF-OGD", "SAOCP", "DtACI"),</span></span>
<span id="cb18-922"><a href="#cb18-922" aria-hidden="true" tabindex="-1"></a><span class="in">) %&gt;%</span></span>
<span id="cb18-923"><a href="#cb18-923" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(data = pmap(list(index, distribution_shift, N), simulate))</span></span>
<span id="cb18-924"><a href="#cb18-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-925"><a href="#cb18-925" aria-hidden="true" tabindex="-1"></a><span class="in"># run_simulation_study2 function is defined in helpers.R</span></span>
<span id="cb18-926"><a href="#cb18-926" aria-hidden="true" tabindex="-1"></a><span class="in">simulation_study2 &lt;- run_simulation_study2(simulation_study_setup2, fit, workers = 8)</span></span>
<span id="cb18-927"><a href="#cb18-927" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-928"><a href="#cb18-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-929"><a href="#cb18-929" aria-hidden="true" tabindex="-1"></a>The coverage error, mean path length, mean interval widths, and strongly adaptive regret (for $m = 20$) of the algorithms are summarized in @fig-simulation-two-results (an alternative plot is included in the appendix as @fig-simulation-two-joint). The coverage error of all the algorithms is near the desired value in the absence of distribution shift. On the contrary, all of the algorithms except AgACI and DtACI undercover when there is distributional shift. SAOCP tends to have higher average path lengths than the other methods. In the distribution shift setting, SF-OGD and SAOCP tended to have smaller strongly adaptive regret than the other methods. An illustrative example of prediction intervals generated by each method for one of the simulated time series with distribution shift is shown in @fig-simulation-two-example. The SAOCP prediction intervals in the example before the distribution shift are more jagged than those produced by the other methods, which illustrates why SAOCP may have longer path lengths.</span>
<span id="cb18-930"><a href="#cb18-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-931"><a href="#cb18-931" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simulation_two_plot}</span></span>
<span id="cb18-932"><a href="#cb18-932" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-simulation-two-results</span></span>
<span id="cb18-933"><a href="#cb18-933" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 6.5</span></span>
<span id="cb18-934"><a href="#cb18-934" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Coverage error, mean interval width, path length, and strongly adaptive regret ($m = 20$) for $\\alpha = 0.8, 0.9, 0.95$ and simulations with and without distributional shift."</span></span>
<span id="cb18-935"><a href="#cb18-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-936"><a href="#cb18-936" aria-hidden="true" tabindex="-1"></a><span class="in">simulation_two_plot(simulation_study2$results)</span></span>
<span id="cb18-937"><a href="#cb18-937" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-938"><a href="#cb18-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-939"><a href="#cb18-939" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simulation_two_example_plot}</span></span>
<span id="cb18-940"><a href="#cb18-940" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-simulation-two-example</span></span>
<span id="cb18-941"><a href="#cb18-941" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 6</span></span>
<span id="cb18-942"><a href="#cb18-942" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Example prediction intervals (target coverage $\\alpha = 0.9$) from the second simulation study of time series with distributional shift, in which the shift occurs at time 250. Blue and red points are observations that fell inside and outside the prediction intervals, respectively."</span></span>
<span id="cb18-943"><a href="#cb18-943" aria-hidden="true" tabindex="-1"></a><span class="in">fits &lt;- simulation_study2$example_fits</span></span>
<span id="cb18-944"><a href="#cb18-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-945"><a href="#cb18-945" aria-hidden="true" tabindex="-1"></a><span class="in">coverage    &lt;- format_coverage(extract_metric(fits$fit, "coverage"))</span></span>
<span id="cb18-946"><a href="#cb18-946" aria-hidden="true" tabindex="-1"></a><span class="in">path_length &lt;- format_path_length(extract_metric(fits$fit, "path_length"))</span></span>
<span id="cb18-947"><a href="#cb18-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-948"><a href="#cb18-948" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(2, 2), mar = c(3, 3, 2, 1))</span></span>
<span id="cb18-949"><a href="#cb18-949" aria-hidden="true" tabindex="-1"></a><span class="in">for(i in 1:4) {</span></span>
<span id="cb18-950"><a href="#cb18-950" aria-hidden="true" tabindex="-1"></a><span class="in">  plot(fits$fit[[i]], legend = FALSE, main = fits$method[[i]], index = 51:500)</span></span>
<span id="cb18-951"><a href="#cb18-951" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -1.5, labels = bquote(EmpCov == .(coverage[[i]]) ), pos = 4)</span></span>
<span id="cb18-952"><a href="#cb18-952" aria-hidden="true" tabindex="-1"></a><span class="in">  text(x = -10, y = -2, labels = bquote(PathLength == .(path_length[[i]]) ), pos = 4)</span></span>
<span id="cb18-953"><a href="#cb18-953" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-954"><a href="#cb18-954" aria-hidden="true" tabindex="-1"></a><span class="in">par(mfrow = c(1, 1), mar = c(5.1, 4.1, 4.1, 2.1))</span></span>
<span id="cb18-955"><a href="#cb18-955" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-956"><a href="#cb18-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-957"><a href="#cb18-957" aria-hidden="true" tabindex="-1"></a><span class="fu"># Case Study: Influenza Forecasting {#sec-case-study}</span></span>
<span id="cb18-958"><a href="#cb18-958" aria-hidden="true" tabindex="-1"></a>Influenza is a highly infectious disease that is estimated to infect approximately one billion individuals each year around the world <span class="co">[</span><span class="ot">@krammer2018influenza</span><span class="co">]</span>. Influenza incidence in temperate climates tends to follow a seasonal pattern, with the highest number of infections during what is commonly referred to as the \textit{flu season} <span class="co">[</span><span class="ot">@lofgren2007influenza</span><span class="co">]</span>. Accurate forecasting of influenza is of significant interest to aid in public health planning and resource allocation. To investigate the accuracy of influenza forecasts, the US Centers for Disease Control (CDC) initiated a challenge, referred to as FluSight, in which teams from multiple institutions submitted weekly forecasts of influenza incidence <span class="co">[</span><span class="ot">@biggerstaff2016flusight</span><span class="co">]</span>. @reich2019influenza evaluated the accuracy of the forecasts over seven flu seasons from 2010 to 2017. As a case study, we investigate the use of ACI algorithms to augment the FluSight forecasts with prediction intervals.</span>
<span id="cb18-959"><a href="#cb18-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-960"><a href="#cb18-960" aria-hidden="true" tabindex="-1"></a>The FluSight challenge collected forecasts for multiple prediction targets. For this case study, we focus on national (US) one-week ahead forecasts of weighted influenza-like illness (wILI), which is a population-weighted percentage of doctors visits where patients presented with influenza-like symptoms <span class="co">[</span><span class="ot">@biggerstaff2016flusight</span><span class="co">]</span>. The FluSight dataset, which is publicly available, include forecasts derived from 21 different forecasting models, from both mechanistic and statistical viewpoints <span class="co">[</span><span class="ot">@flusight2020;@tushar2018flusightnetwork;@tushar2019flusight</span><span class="co">]</span>. For our purposes, we treat the way the forecasts were produced as a black box.</span>
<span id="cb18-961"><a href="#cb18-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-962"><a href="#cb18-962" aria-hidden="true" tabindex="-1"></a>Formally, let $y_{t}$, $t \in \llbracket T \rrbracket$ be the observed national wILI at time $t$, and let $\hat{\mu}_{j,t}$, $j \in \llbracket J \rrbracket$, be the one-week ahead forecast of the wILI from model $j$ at time $t$. Two of the original 21 forecasting methods were excluded from this case study due to poor predictive performance (\texttt{Delphi<span class="sc">\_</span>Uniform} and \texttt{CUBMA}). In addition, six methods had identical forecasts (\texttt{CU<span class="sc">\_</span>EAKFC<span class="sc">\_</span>SIRS}, \texttt{CU<span class="sc">\_</span>EKF<span class="sc">\_</span>SEIRS}, \texttt{CU<span class="sc">\_</span>EKF<span class="sc">\_</span>SIRS}, \texttt{CU<span class="sc">\_</span>RHF<span class="sc">\_</span>SEIRS}, \texttt{CU<span class="sc">\_</span>RHF<span class="sc">\_</span>SIRS}), and therefore we only included one (\texttt{CU<span class="sc">\_</span>EAKFC<span class="sc">\_</span>SEIRS}) in the analysis. The ACI methods were then applied to the log-observations and log-predictions, where the log-transformation was used to constrain the final prediction intervals to be positive. The first flu season (2010-2011) was used as a warm-up for each ACI method, and we report the empirical performance of the prediction intervals for the subsequent seasons (six seasons from 2012-2013 to 2016-2017). The ACI algorithms target prediction intervals with coverage of $\alpha = 0.8$, $\alpha = 0.9$, and $\alpha = 0.95$. As in the simulation study, we used the interval constructor corresponding to the original presentation of each algorithm (see @tbl-aci).</span>
<span id="cb18-963"><a href="#cb18-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-964"><a href="#cb18-964" aria-hidden="true" tabindex="-1"></a><span class="in">```{r case_study, cache = TRUE}</span></span>
<span id="cb18-965"><a href="#cb18-965" aria-hidden="true" tabindex="-1"></a><span class="in"># Paste together URL so it is not cut off in PDF</span></span>
<span id="cb18-966"><a href="#cb18-966" aria-hidden="true" tabindex="-1"></a><span class="in">url &lt;- paste0("https://raw.githubusercontent.com/FluSightNetwork/",</span></span>
<span id="cb18-967"><a href="#cb18-967" aria-hidden="true" tabindex="-1"></a><span class="in"> "cdc-flusight-ensemble/master/scores/point_ests.csv")</span></span>
<span id="cb18-968"><a href="#cb18-968" aria-hidden="true" tabindex="-1"></a><span class="in">raw_data &lt;- read_csv(url, show_col_types = FALSE)</span></span>
<span id="cb18-969"><a href="#cb18-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-970"><a href="#cb18-970" aria-hidden="true" tabindex="-1"></a><span class="in">fit &lt;- function(data, method, alpha) {</span></span>
<span id="cb18-971"><a href="#cb18-971" aria-hidden="true" tabindex="-1"></a><span class="in">  first_season &lt;- data$Season == "2010/2011"</span></span>
<span id="cb18-972"><a href="#cb18-972" aria-hidden="true" tabindex="-1"></a><span class="in">  D &lt;- max(abs(data$obs_value - data$Value)[first_season])</span></span>
<span id="cb18-973"><a href="#cb18-973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-974"><a href="#cb18-974" aria-hidden="true" tabindex="-1"></a><span class="in">  interval_constructor = case_when(</span></span>
<span id="cb18-975"><a href="#cb18-975" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "AgACI" ~ "conformal",</span></span>
<span id="cb18-976"><a href="#cb18-976" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "DtACI" ~ "conformal",</span></span>
<span id="cb18-977"><a href="#cb18-977" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "SF-OGD" ~ "linear",</span></span>
<span id="cb18-978"><a href="#cb18-978" aria-hidden="true" tabindex="-1"></a><span class="in">    method == "SAOCP" ~ "linear"</span></span>
<span id="cb18-979"><a href="#cb18-979" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb18-980"><a href="#cb18-980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-981"><a href="#cb18-981" aria-hidden="true" tabindex="-1"></a><span class="in">  gamma &lt;- D / sqrt(3)</span></span>
<span id="cb18-982"><a href="#cb18-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-983"><a href="#cb18-983" aria-hidden="true" tabindex="-1"></a><span class="in">  if(interval_constructor == "linear") {</span></span>
<span id="cb18-984"><a href="#cb18-984" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma_grid = seq(0.1, 1, 0.1)</span></span>
<span id="cb18-985"><a href="#cb18-985" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb18-986"><a href="#cb18-986" aria-hidden="true" tabindex="-1"></a><span class="in">  else {</span></span>
<span id="cb18-987"><a href="#cb18-987" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma_grid &lt;- c(0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128)</span></span>
<span id="cb18-988"><a href="#cb18-988" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb18-989"><a href="#cb18-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-990"><a href="#cb18-990" aria-hidden="true" tabindex="-1"></a><span class="in">  parameters &lt;- list(</span></span>
<span id="cb18-991"><a href="#cb18-991" aria-hidden="true" tabindex="-1"></a><span class="in">    interval_constructor = interval_constructor,</span></span>
<span id="cb18-992"><a href="#cb18-992" aria-hidden="true" tabindex="-1"></a><span class="in">    D = D,</span></span>
<span id="cb18-993"><a href="#cb18-993" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma = gamma,</span></span>
<span id="cb18-994"><a href="#cb18-994" aria-hidden="true" tabindex="-1"></a><span class="in">    gamma_grid = gamma_grid</span></span>
<span id="cb18-995"><a href="#cb18-995" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb18-996"><a href="#cb18-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-997"><a href="#cb18-997" aria-hidden="true" tabindex="-1"></a><span class="in">  aci(</span></span>
<span id="cb18-998"><a href="#cb18-998" aria-hidden="true" tabindex="-1"></a><span class="in">    Y = log(data$obs_value),</span></span>
<span id="cb18-999"><a href="#cb18-999" aria-hidden="true" tabindex="-1"></a><span class="in">    predictions = log(data$Value),</span></span>
<span id="cb18-1000"><a href="#cb18-1000" aria-hidden="true" tabindex="-1"></a><span class="in">    method = method,</span></span>
<span id="cb18-1001"><a href="#cb18-1001" aria-hidden="true" tabindex="-1"></a><span class="in">    parameters = parameters,</span></span>
<span id="cb18-1002"><a href="#cb18-1002" aria-hidden="true" tabindex="-1"></a><span class="in">    alpha = alpha</span></span>
<span id="cb18-1003"><a href="#cb18-1003" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb18-1004"><a href="#cb18-1004" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-1005"><a href="#cb18-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1006"><a href="#cb18-1006" aria-hidden="true" tabindex="-1"></a><span class="in">metrics &lt;- function(data, fit) {</span></span>
<span id="cb18-1007"><a href="#cb18-1007" aria-hidden="true" tabindex="-1"></a><span class="in">  aci_metrics(fit, indices = which(data$Season != "2010/2011"))</span></span>
<span id="cb18-1008"><a href="#cb18-1008" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb18-1009"><a href="#cb18-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1010"><a href="#cb18-1010" aria-hidden="true" tabindex="-1"></a><span class="in">analysis_data &lt;- raw_data %&gt;%</span></span>
<span id="cb18-1011"><a href="#cb18-1011" aria-hidden="true" tabindex="-1"></a><span class="in">  filter(</span></span>
<span id="cb18-1012"><a href="#cb18-1012" aria-hidden="true" tabindex="-1"></a><span class="in">    Target == "1 wk ahead",</span></span>
<span id="cb18-1013"><a href="#cb18-1013" aria-hidden="true" tabindex="-1"></a><span class="in">    Location == "US National",</span></span>
<span id="cb18-1014"><a href="#cb18-1014" aria-hidden="true" tabindex="-1"></a><span class="in">    !(model_name %in% c("Delphi_Uniform", "CUBMA", "CU_EAKFC_SIRS", "CU_EKF_SEIRS",</span></span>
<span id="cb18-1015"><a href="#cb18-1015" aria-hidden="true" tabindex="-1"></a><span class="in">                        "CU_EKF_SIRS", "CU_RHF_SEIRS", "CU_RHF_SIRS"))</span></span>
<span id="cb18-1016"><a href="#cb18-1016" aria-hidden="true" tabindex="-1"></a><span class="in">  ) %&gt;%</span></span>
<span id="cb18-1017"><a href="#cb18-1017" aria-hidden="true" tabindex="-1"></a><span class="in">  arrange(Year, Model.Week) %&gt;%</span></span>
<span id="cb18-1018"><a href="#cb18-1018" aria-hidden="true" tabindex="-1"></a><span class="in">  group_by(model_name) %&gt;%</span></span>
<span id="cb18-1019"><a href="#cb18-1019" aria-hidden="true" tabindex="-1"></a><span class="in">  nest()</span></span>
<span id="cb18-1020"><a href="#cb18-1020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1021"><a href="#cb18-1021" aria-hidden="true" tabindex="-1"></a><span class="in">fits &lt;- expand_grid(</span></span>
<span id="cb18-1022"><a href="#cb18-1022" aria-hidden="true" tabindex="-1"></a><span class="in">  analysis_data,</span></span>
<span id="cb18-1023"><a href="#cb18-1023" aria-hidden="true" tabindex="-1"></a><span class="in">  tibble(method = c("AgACI", "DtACI", "SF-OGD", "SAOCP")),</span></span>
<span id="cb18-1024"><a href="#cb18-1024" aria-hidden="true" tabindex="-1"></a><span class="in">  tibble(alpha = c(0.8, 0.9, 0.95))</span></span>
<span id="cb18-1025"><a href="#cb18-1025" aria-hidden="true" tabindex="-1"></a><span class="in">) %&gt;%</span></span>
<span id="cb18-1026"><a href="#cb18-1026" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(fit = pmap(list(data, method, alpha), fit),</span></span>
<span id="cb18-1027"><a href="#cb18-1027" aria-hidden="true" tabindex="-1"></a><span class="in">         metrics = map2(data, fit, metrics))</span></span>
<span id="cb18-1028"><a href="#cb18-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1029"><a href="#cb18-1029" aria-hidden="true" tabindex="-1"></a><span class="in">case_study_results &lt;- fits %&gt;%</span></span>
<span id="cb18-1030"><a href="#cb18-1030" aria-hidden="true" tabindex="-1"></a><span class="in">  select(-data, -fit) %&gt;%</span></span>
<span id="cb18-1031"><a href="#cb18-1031" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(metrics = map(metrics, as_tibble)) %&gt;%</span></span>
<span id="cb18-1032"><a href="#cb18-1032" aria-hidden="true" tabindex="-1"></a><span class="in">  unnest(c(metrics))</span></span>
<span id="cb18-1033"><a href="#cb18-1033" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1034"><a href="#cb18-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1035"><a href="#cb18-1035" aria-hidden="true" tabindex="-1"></a>The coverage errors, mean interval widths, path lengths, and strongly adaptive regret (for $m = 20$) of the prediction intervals for each of the underlying forecast models is shown in @fig-case-study-metrics. In all cases the absolute coverage error was less than $0.1$. SF-OGD performed particularly well, with coverage errors close to zero for all forecasting models. Interval widths were similar across methods, with SAOCP slightly shorter. Path Lengths were shorter for AgACI and DtACI and longer for SAOCP.</span>
<span id="cb18-1036"><a href="#cb18-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1037"><a href="#cb18-1037" aria-hidden="true" tabindex="-1"></a><span class="in">```{r case_study_metrics_plot}</span></span>
<span id="cb18-1038"><a href="#cb18-1038" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-case-study-metrics</span></span>
<span id="cb18-1039"><a href="#cb18-1039" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 8.5</span></span>
<span id="cb18-1040"><a href="#cb18-1040" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Coverage errors, mean interval widths, path lengths, and strongly adaptive regret (for $m = 20$) of prediction intervals generated with each ACI method based on forecasts from each of the 19 underlying influenza forecasting models."</span></span>
<span id="cb18-1041"><a href="#cb18-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1042"><a href="#cb18-1042" aria-hidden="true" tabindex="-1"></a><span class="in">case_study_plot(case_study_results)</span></span>
<span id="cb18-1043"><a href="#cb18-1043" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1044"><a href="#cb18-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1045"><a href="#cb18-1045" aria-hidden="true" tabindex="-1"></a>As an illustrative example, in @fig-case-study-example we plot the point forecasts from one of the forecasting models (based on SARIMA with no seasonal differencing) and the associated ACI-generated 90\% prediction intervals for each season from 2011-2017. In general, in this practical setting all of the ACI algorithms yield quite similar prediction intervals. Interestingly, the forecasts in 2011-2012 underpredicted the observations for much of the season. The algorithm responds by making the intervals wider to cover the observations, and because the intervals are symmetric the lower bound then becomes unrealistically low. A similar phenomenon can be seen in the growth phase of the 2012/2013 season as well.</span>
<span id="cb18-1046"><a href="#cb18-1046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1047"><a href="#cb18-1047" aria-hidden="true" tabindex="-1"></a><span class="in">```{r case_study_example_plot}</span></span>
<span id="cb18-1048"><a href="#cb18-1048" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-case-study-example</span></span>
<span id="cb18-1049"><a href="#cb18-1049" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 4</span></span>
<span id="cb18-1050"><a href="#cb18-1050" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Example conformal prediction intervals for six flu seasons based on forecasts from a SARIMA type model."</span></span>
<span id="cb18-1051"><a href="#cb18-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1052"><a href="#cb18-1052" aria-hidden="true" tabindex="-1"></a><span class="in">sarima_fits &lt;- fits %&gt;% filter(</span></span>
<span id="cb18-1053"><a href="#cb18-1053" aria-hidden="true" tabindex="-1"></a><span class="in">  model_name == "ReichLab_sarima_seasonal_difference_FALSE",</span></span>
<span id="cb18-1054"><a href="#cb18-1054" aria-hidden="true" tabindex="-1"></a><span class="in">  alpha == 0.9</span></span>
<span id="cb18-1055"><a href="#cb18-1055" aria-hidden="true" tabindex="-1"></a><span class="in">) %&gt;%</span></span>
<span id="cb18-1056"><a href="#cb18-1056" aria-hidden="true" tabindex="-1"></a><span class="in">  mutate(output = map(fit, extract_intervals)) %&gt;%</span></span>
<span id="cb18-1057"><a href="#cb18-1057" aria-hidden="true" tabindex="-1"></a><span class="in">  select(method, alpha, data, output) %&gt;%</span></span>
<span id="cb18-1058"><a href="#cb18-1058" aria-hidden="true" tabindex="-1"></a><span class="in">  unnest(c(data, output)) %&gt;%</span></span>
<span id="cb18-1059"><a href="#cb18-1059" aria-hidden="true" tabindex="-1"></a><span class="in">  filter(Season != "2010/2011")</span></span>
<span id="cb18-1060"><a href="#cb18-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1061"><a href="#cb18-1061" aria-hidden="true" tabindex="-1"></a><span class="in">sarima_fits %&gt;%</span></span>
<span id="cb18-1062"><a href="#cb18-1062" aria-hidden="true" tabindex="-1"></a><span class="in">  ggplot(aes(x = Model.Week, y = log(obs_value))) +</span></span>
<span id="cb18-1063"><a href="#cb18-1063" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_point(aes(shape = "Observed")) +</span></span>
<span id="cb18-1064"><a href="#cb18-1064" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_line(aes(y = pred, lty = "Forecast"), color = "black") +</span></span>
<span id="cb18-1065"><a href="#cb18-1065" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_line(aes(y = lower, color = method)) +</span></span>
<span id="cb18-1066"><a href="#cb18-1066" aria-hidden="true" tabindex="-1"></a><span class="in">  geom_line(aes(y = upper, color = method)) +</span></span>
<span id="cb18-1067"><a href="#cb18-1067" aria-hidden="true" tabindex="-1"></a><span class="in">  facet_wrap(~Season) +</span></span>
<span id="cb18-1068"><a href="#cb18-1068" aria-hidden="true" tabindex="-1"></a><span class="in">  labs(</span></span>
<span id="cb18-1069"><a href="#cb18-1069" aria-hidden="true" tabindex="-1"></a><span class="in">    x = "Flu Season Week",</span></span>
<span id="cb18-1070"><a href="#cb18-1070" aria-hidden="true" tabindex="-1"></a><span class="in">    y = "log(wILI)",</span></span>
<span id="cb18-1071"><a href="#cb18-1071" aria-hidden="true" tabindex="-1"></a><span class="in">    title = "SARIMA forecasts with ACI 90% prediction intervals"</span></span>
<span id="cb18-1072"><a href="#cb18-1072" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb18-1073"><a href="#cb18-1073" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1074"><a href="#cb18-1074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1075"><a href="#cb18-1075" aria-hidden="true" tabindex="-1"></a><span class="fu"># Discussion {#sec-discussion}</span></span>
<span id="cb18-1076"><a href="#cb18-1076" aria-hidden="true" tabindex="-1"></a>The results of our simulations and case study show that, when tuning parameters are chosen well, Adaptive Conformal Inference algorithms yield well-performing prediction intervals. On the contrary, poor choice of tuning parameters can lead to intervals of low utility: for one example, Figure <span class="co">[</span><span class="ot">@fig-sf-ogd</span><span class="co">]</span> shows how choosing the tuning parameter for SF-OGD to be too small can lead to intervals that update too slowly and significantly undercover. Furthermore, in some cases the prediction intervals may appear to perform well with respect to metrics like the empirical coverage error, while simultaneously being useless in practice. The original ACI algorithm illustrates this phenomenon: too small a value of its learning rate $\gamma$ yields prediction intervals that are not reactive enough, while too large a value yields intervals that change too fast. In both cases, the empirical coverage may appear well-calibrated, while the prediction intervals will not be useful. Thus, the core challenge in designing an ACI algorithm is in finding an optimal level of reactivity for the prediction intervals. As users of these algorithms, the challenge is in finding values for the tuning parameters that avoid pathological behaviors.</span>
<span id="cb18-1077"><a href="#cb18-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1078"><a href="#cb18-1078" aria-hidden="true" tabindex="-1"></a>Several of the algorithms investigated in this paper handle the problem of finding an optimal level of reactivity by aggregating prediction intervals generated by a set of underlying ACI algorithms.</span>
<span id="cb18-1079"><a href="#cb18-1079" aria-hidden="true" tabindex="-1"></a>Our results show the algorithms can perform well in multiple difficult scenarios. However, the overall effect of these approaches is to shift the problem to a higher level of abstraction: we still need to set tuning parameters that control the amount of reactivity, but do so at a higher level than the original ACI algorithm. It is desirable that these tuning parameters be easily interpretable, with simple strategies available for setting them.  An advantage of the SF-OGD and SAOCP algorithms in this respect are that their main tuning parameter, the maximum radius $D$, is easily interpretable as the maximum possible difference between the input predictions and the truth. It is also straightforward to choose this parameter based on a calibration set, although this strategy does not necessarily work well in cases of distribution shift. We also found that an advantage of the AgACI method is its robustness to the choice of its main tuning parameter, the set of candidate learning rates, in the sense that the grid of candidate learning rates can always be expanded as illustrated in @sec-agaci-tuning.</span>
<span id="cb18-1080"><a href="#cb18-1080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1081"><a href="#cb18-1081" aria-hidden="true" tabindex="-1"></a>A key challenge in tuning the algorithms arises in settings of distribution shift, where methods for choosing hyperparameters based on a calibration set from before the distribution shift will likely not perform well. The second simulation study we conducted probed this setting in a simple scenario. We found that several of the methods yielded prediction intervals that had non-optimal empirical coverage. As we picked hyperparameters based on a calibration set formed before the distribution shift, it is not surprising that the resulting tuning parameters are not optimal. This underscores the difficulty in designing  ACI algorithms that can adapt to distribution shifts, and in finding robust methods for choosing hyperparameters. In practice, it is possible the second simulation study does not accurately reflect real-world scenarios. Indeed, the benchmarks presented in @bhatnagar2023saocp using the datasets from the M4 competition <span class="co">[</span><span class="ot">@makridakis2020m4</span><span class="co">]</span>, and using point predictions generated by diverse prediction algorithms, found that ACI algorithms exhibited good performance in terms of empirical coverage.  Nevertheless, our recommendation for future papers in this line of research is to include simulation studies for simple distributional shift scenarios as a benchmark.</span>
<span id="cb18-1082"><a href="#cb18-1082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1083"><a href="#cb18-1083" aria-hidden="true" tabindex="-1"></a>Our case study results illustrate the dependence of the ACI algorithms on having access to high-quality point predictions. If the predictions are biased, for example, then the prediction intervals may be able to achieve optimal coverage at the expense of larger interval widths. This type of underperformance due to biased input predictions can be seen in the 2011-2012 flu season in the case study <span class="co">[</span><span class="ot">@fig-case-study-example</span><span class="co">]</span>. One way bias can arise in the underlying predictions is due to model misspecification: for example, if a forecast method assumes a time series will evolve according to a particular parametric model that does not accurately capture the true data generating process, then the forecasts may be systematically biased. Using ensemble methods to combine forecasts from several flexible machine learning algorithms is one strategy that can be used to hedge against such model misspecification and improve the quality of forecasts <span class="co">[</span><span class="ot">@makridakis2020m4</span><span class="co">]</span>.</span>
<span id="cb18-1084"><a href="#cb18-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1085"><a href="#cb18-1085" aria-hidden="true" tabindex="-1"></a>Overall, our findings illustrate strengths and weaknesses of all the considered algorithms. The original ACI algorithm is appealing in its simplicity, although its performance depends entirely on a good choice of its tuning parameter. AgACI tended to perform well in the simulation studies in terms of coverage error, although it had slightly higher strongly adaptive regret than other algorithms in some settings. However, there are relatively fewer theoretical guarantees available for AgACI than the other methods. DtACI, SF-OGD, and SAOCP all feature strong theoretical results, although they exhibited some differences in the simulation studies, with SF-OGD and SAOCP slightly undercovering in some scenarios. SAOCP also had longer path lengths than other methods in simulations, although in practice in the influenza forecasting task longer path lengths does not seem to effect the plausibility of the prediction intervals the algorithm produces.</span>
<span id="cb18-1086"><a href="#cb18-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1087"><a href="#cb18-1087" aria-hidden="true" tabindex="-1"></a>There remain many possible extensions of ACI algorithms. The algorithms presented in this work primarily consider symmetric intervals evaluated using the pinball loss function (AgACI can yield asymmetric intervals because the aggregation rule is applied separately to the lower and upper bounds from the underlying experts, but those underlying experts only produce symmetric intervals). A simple extension would switch to using the interval loss function <span class="co">[</span><span class="ot">@gneiting2007scoring</span><span class="co">]</span>, which would allow for asymmetric intervals where two parameters are learned for the upper and lower bounds, respectively. It may also be of interest to generate prediction intervals that have coverage guarantees for arbitrary subsets of observations (for example, we may seek prediction intervals for daily observations that have near optimal coverage for every day of the week, or month of the year), similar to guarantees provided by the MultiValid Prediction method described in <span class="co">[</span><span class="ot">@bastani2022practical</span><span class="co">]</span>. Another avenue for theoretical research is to relax the assumption of bounded radii necessary for the theoretical results of algorithms such as SAOCP.</span>
<span id="cb18-1088"><a href="#cb18-1088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1089"><a href="#cb18-1089" aria-hidden="true" tabindex="-1"></a><span class="fu">## Acknowledgements {.unnumbered}</span></span>
<span id="cb18-1090"><a href="#cb18-1090" aria-hidden="true" tabindex="-1"></a>This research is partially supported by the Agence Nationale de la Recherche as part of the “Investissements d’avenir” program (reference ANR-19-P3IA-0001; PRAIRIE 3IA Institute) and as part of the program "Au delà de l'apprentissage séquentiel pour de meilleures prises de décisions" (reference ANR-19-CE23-0026; BOLD).  We would like to thank Margaux Zaffran for providing helpful comments on the manuscript.</span>
<span id="cb18-1091"><a href="#cb18-1091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1092"><a href="#cb18-1092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1093"><a href="#cb18-1093" aria-hidden="true" tabindex="-1"></a><span class="fu"># References {.unnumbered}</span></span>
<span id="cb18-1094"><a href="#cb18-1094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1095"><a href="#cb18-1095" aria-hidden="true" tabindex="-1"></a>::: {#refs}</span>
<span id="cb18-1096"><a href="#cb18-1096" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1097"><a href="#cb18-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1098"><a href="#cb18-1098" aria-hidden="true" tabindex="-1"></a><span class="fu"># Appendix</span></span>
<span id="cb18-1099"><a href="#cb18-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1100"><a href="#cb18-1100" aria-hidden="true" tabindex="-1"></a><span class="fu">## Additional simulation study results</span></span>
<span id="cb18-1101"><a href="#cb18-1101" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simulation_one_plot_appendix}</span></span>
<span id="cb18-1102"><a href="#cb18-1102" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Coverage errors, mean interval widths, and path lengths for the first simulation study with target coverage $\\alpha \\in \\{ 0.8, 0.9, 0.95 \\}$."</span></span>
<span id="cb18-1103"><a href="#cb18-1103" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 9.5</span></span>
<span id="cb18-1104"><a href="#cb18-1104" aria-hidden="true" tabindex="-1"></a><span class="in">simulation_one_plot(simulation_study1$results)</span></span>
<span id="cb18-1105"><a href="#cb18-1105" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1106"><a href="#cb18-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1107"><a href="#cb18-1107" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simulation_one_plot_joint_appendix}</span></span>
<span id="cb18-1108"><a href="#cb18-1108" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-simulation-one-joint</span></span>
<span id="cb18-1109"><a href="#cb18-1109" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Mean Interval Width vs Coverage Error for the first simulation study. The error bars represent the 10% to 90% quantiles of the metrics over the simulation datasets."</span></span>
<span id="cb18-1110"><a href="#cb18-1110" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 4</span></span>
<span id="cb18-1111"><a href="#cb18-1111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1112"><a href="#cb18-1112" aria-hidden="true" tabindex="-1"></a><span class="in">simulation_one_joint_plot(simulation_study1$results)</span></span>
<span id="cb18-1113"><a href="#cb18-1113" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1114"><a href="#cb18-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1115"><a href="#cb18-1115" aria-hidden="true" tabindex="-1"></a><span class="in">```{r simulation_two_plot_joint, echo=FALSE}</span></span>
<span id="cb18-1116"><a href="#cb18-1116" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-simulation-two-joint</span></span>
<span id="cb18-1117"><a href="#cb18-1117" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Mean interval width vs coverage error (top) and Mean Path Length vs. coverage error (bottom) for the second simulation study. The error bars represent the 10% to 90% quantiles of the metrics over the simulation datasets."</span></span>
<span id="cb18-1118"><a href="#cb18-1118" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-height: 6</span></span>
<span id="cb18-1119"><a href="#cb18-1119" aria-hidden="true" tabindex="-1"></a><span class="in">simulation_two_joint_plot(simulation_study2$results)</span></span>
<span id="cb18-1120"><a href="#cb18-1120" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.captionPrefix || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  




</body></html>